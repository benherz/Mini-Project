{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS405 Machine Learning Applications in Business and Economics Mini-Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">TBD: \n",
    "- What features to use? \n",
    "    - Construct new ones? \n",
    "    - Simply leave out all non-numeric features? \n",
    "    - Delivery-Delay might be interesting\n",
    "    - Delivery Delay\n",
    "\n",
    "- What is the goal of our model?\n",
    "    - Avoid false negatives? This way returning customers will not receive a voucher. \n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the realm of e-commerce, a common observation is that a significant proportion of customers engage in a single transaction and then cease further purchases. This phenomenon can be attributed to a multitude of factors. To mitigate this, e-commerce platforms employ a variety of strategies aimed at fostering customer loyalty. One such strategy involves the distribution of discount vouchers subsequent to the initial purchase, with the goal of incentivizing repeat transactions. However, indiscriminate distribution of these vouchers may not be an optimal strategy. This is because a segment of customers might have engaged in repeat purchases even in the absence of such incentives. Consequently, the redemption of these vouchers by such customers translates into a reduction in the retailer’s profit. Empirical analyses conducted by the media retailer have demonstrated that for 10% of non-buyers, the voucher instigates a purchase with an average order value of €20. Thus, if a voucher is dispatched to a customer who would not have actually made another purchase, the revenue increases by an average of €1.5. On the other hand, sending a voucher to a customer who would have made a purchase anyway results in a revenue loss equivalent to the voucher value of €5. For customers who don’t receive a voucher, there is no impact on revenues. Therefore, it is crucial to devise a more targeted approach for the distribution of these vouchers.\n",
    "\n",
    "## Task \n",
    "\n",
    "The task at hand involves constructing a predictive model that leverages various features associated with a customer’s initial order. The objective is to determine whether a €5.00 voucher should be issued to a specific customer. Detailed descriptions of these features can be found in the data dictionary.pdf file.\n",
    "The model should be designed to predict if a customer will place a subsequent order within a 90-day period following their initial purchase. This information is represented by the target90 variable in the dataset. The model’s performance is evaluated based on the expected revenue across all customers in a given dataset. This is computed by considering the model’s predictions in conjunction with the associated costs and revenues. It’s crucial to note that the model’s effectiveness is directly tied to its ability to maximize this expected revenue. Hence, the model should be optimized with this specific goal in mind.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier # Binary dependent variable\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "import joblib # to save trained model \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading in and getting an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_9964\\544976364.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"train.csv\", sep = \";\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customernumber</th>\n",
       "      <th>salutation</th>\n",
       "      <th>title</th>\n",
       "      <th>domain</th>\n",
       "      <th>newsletter</th>\n",
       "      <th>model</th>\n",
       "      <th>paymenttype</th>\n",
       "      <th>deliverytype</th>\n",
       "      <th>invoicepostcode</th>\n",
       "      <th>voucher</th>\n",
       "      <th>case</th>\n",
       "      <th>numberitems</th>\n",
       "      <th>gift</th>\n",
       "      <th>entry</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33389.298569</td>\n",
       "      <td>0.541569</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>7.517115</td>\n",
       "      <td>0.169483</td>\n",
       "      <td>1.646910</td>\n",
       "      <td>1.000987</td>\n",
       "      <td>0.201955</td>\n",
       "      <td>48.752282</td>\n",
       "      <td>0.162020</td>\n",
       "      <td>2.934378</td>\n",
       "      <td>2.019551</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.414642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19148.090449</td>\n",
       "      <td>0.657044</td>\n",
       "      <td>0.083192</td>\n",
       "      <td>3.683945</td>\n",
       "      <td>0.375184</td>\n",
       "      <td>0.825981</td>\n",
       "      <td>1.092677</td>\n",
       "      <td>0.401465</td>\n",
       "      <td>24.361425</td>\n",
       "      <td>0.368475</td>\n",
       "      <td>1.319270</td>\n",
       "      <td>1.726046</td>\n",
       "      <td>0.067404</td>\n",
       "      <td>0.492668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16802.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33552.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50034.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66251.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customernumber    salutation         title        domain    newsletter  \\\n",
       "count    32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean     33389.298569      0.541569      0.006969      7.517115      0.169483   \n",
       "std      19148.090449      0.657044      0.083192      3.683945      0.375184   \n",
       "min          1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      16802.750000      0.000000      0.000000      4.000000      0.000000   \n",
       "50%      33552.500000      0.000000      0.000000      9.000000      0.000000   \n",
       "75%      50034.250000      1.000000      0.000000     11.000000      0.000000   \n",
       "max      66251.000000      2.000000      1.000000     12.000000      1.000000   \n",
       "\n",
       "              model   paymenttype  deliverytype  invoicepostcode  \\\n",
       "count  32428.000000  32428.000000  32428.000000     32428.000000   \n",
       "mean       1.646910      1.000987      0.201955        48.752282   \n",
       "std        0.825981      1.092677      0.401465        24.361425   \n",
       "min        1.000000      0.000000      0.000000         0.000000   \n",
       "25%        1.000000      0.000000      0.000000        30.000000   \n",
       "50%        1.000000      1.000000      0.000000        47.000000   \n",
       "75%        2.000000      2.000000      0.000000        66.000000   \n",
       "max        3.000000      3.000000      1.000000        99.000000   \n",
       "\n",
       "            voucher          case   numberitems          gift         entry  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.162020      2.934378      2.019551      0.004564      0.414642   \n",
       "std        0.368475      1.319270      1.726046      0.067404      0.492668   \n",
       "min        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%        0.000000      2.000000      1.000000      0.000000      0.000000   \n",
       "50%        0.000000      3.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      4.000000      2.000000      0.000000      1.000000   \n",
       "max        1.000000      5.000000     50.000000      1.000000      1.000000   \n",
       "\n",
       "        points  \n",
       "count  32428.0  \n",
       "mean       0.0  \n",
       "std        0.0  \n",
       "min        0.0  \n",
       "25%        0.0  \n",
       "50%        0.0  \n",
       "75%        0.0  \n",
       "max        0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separator is ;\n",
    "data = pd.read_csv(\"train.csv\", sep = \";\")\n",
    "\n",
    "# Dataset is wide, print all rows and only first 15 columns\n",
    "data.describe().iloc[:,0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shippingcosts</th>\n",
       "      <th>weight</th>\n",
       "      <th>remi</th>\n",
       "      <th>cancel</th>\n",
       "      <th>used</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>w10</th>\n",
       "      <th>target90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.150611</td>\n",
       "      <td>637.920809</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>0.061613</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.902122</td>\n",
       "      <td>0.404342</td>\n",
       "      <td>0.276644</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>0.047027</td>\n",
       "      <td>0.180986</td>\n",
       "      <td>0.027908</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.164981</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>0.186598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.357674</td>\n",
       "      <td>724.358131</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>0.306833</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>1.654767</td>\n",
       "      <td>1.410395</td>\n",
       "      <td>1.353981</td>\n",
       "      <td>0.253596</td>\n",
       "      <td>0.434265</td>\n",
       "      <td>0.561751</td>\n",
       "      <td>0.299862</td>\n",
       "      <td>0.401782</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.836705</td>\n",
       "      <td>0.610509</td>\n",
       "      <td>0.389594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20076.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shippingcosts        weight          remi        cancel          used  \\\n",
       "count   32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean        0.150611    637.920809      0.059979      0.061613      0.068860   \n",
       "std         0.357674    724.358131      0.388740      0.306833      0.474444   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      3.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000    494.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000    920.000000      0.000000      0.000000      0.000000   \n",
       "max         1.000000  20076.000000     19.000000     17.000000     19.000000   \n",
       "\n",
       "                 w0            w1            w2            w3            w4  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.902122      0.404342      0.276644      0.018903      0.047027   \n",
       "std        1.654767      1.410395      1.353981      0.253596      0.434265   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       99.000000     84.000000     90.000000     15.000000     36.000000   \n",
       "\n",
       "                 w5            w6            w7            w8            w9  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.180986      0.027908      0.023128      0.000185      0.164981   \n",
       "std        0.561751      0.299862      0.401782      0.013601      0.836705   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       14.000000     27.000000     55.000000      1.000000     48.000000   \n",
       "\n",
       "                w10      target90  \n",
       "count  32428.000000  32428.000000  \n",
       "mean       0.092883      0.186598  \n",
       "std        0.610509      0.389594  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max       50.000000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second half of the columns\n",
    "# Dataset is wide, print all rows and only remaining columns\n",
    "data.describe().iloc[:,15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every column has a count of 32428 -> No missing values seem to be present. In the case of binary encoded variables, the mean directly reflects a percentage (if multiplied by 100). \\\n",
    "However, due to their datatype, some columns are not present in the .describe()-dataframe. Therefore, to fully detect all missing values, we loop over all columns in the as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 18.66% of customers in the data set repurchased in the next 90 days. This makes the data set imbalanced and we have to proceed with caution.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Only {np.round(data['target90'].mean()*100,2)}% of customers in the data set repurchased in the next 90 days. This makes the data set imbalanced and we have to proceed with caution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocessing for one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_9964\\501370038.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'web.de' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[i, \"domain\"] = \"web.de\"\n",
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_9964\\501370038.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Ms.' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[i, \"salutation\"] = \"Ms.\"\n",
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_9964\\501370038.py:49: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Transfer' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[i, \"paymenttype\"] = \"Transfer\"\n"
     ]
    }
   ],
   "source": [
    "# Domain\n",
    "for i in range(len(data[\"domain\"])):\n",
    "    value = data[\"domain\"].iloc[i]\n",
    "    if value == 0:\n",
    "        data.loc[i, \"domain\"] = \"aol.com\"\n",
    "    elif value == 1:\n",
    "        data.loc[i, \"domain\"] = \"arcor.de\"\n",
    "    elif value == 2:\n",
    "        data.loc[i, \"domain\"] = \"freenet.de\"\n",
    "    elif value == 3:\n",
    "        data.loc[i, \"domain\"] = \"gmail.com\"\n",
    "    elif value == 4:\n",
    "        data.loc[i, \"domain\"] = \"gmx.de\"\n",
    "    elif value == 5:\n",
    "        data.loc[i, \"domain\"] = \"hotmail.de\"\n",
    "    elif value == 6:\n",
    "        data.loc[i, \"domain\"] = \"online.de\"\n",
    "    elif value == 7:\n",
    "        data.loc[i, \"domain\"] = \"onlinehome.de\"\n",
    "    elif value == 8:\n",
    "        data.loc[i, \"domain\"] = \"t-online.de\"\n",
    "    elif value == 9:\n",
    "        data.loc[i, \"domain\"] = \"web.de\"\n",
    "    elif value == 10:\n",
    "        data.loc[i, \"domain\"] = \"yahoo.com\"\n",
    "    elif value == 11:\n",
    "        data.loc[i, \"domain\"] = \"yahoo.de\"\n",
    "    elif value == 12:\n",
    "        data.loc[i, \"domain\"] = \"others\"\n",
    "\n",
    "# Salutation\n",
    "for i in range(len(data[\"salutation\"])):\n",
    "    value = data[\"salutation\"].iloc[i]\n",
    "    if value == 0:\n",
    "        data.loc[i, \"salutation\"] = \"Ms.\"\n",
    "    elif value == 1:\n",
    "        data.loc[i, \"salutation\"] = \"Mr.\"\n",
    "    elif value == 2:\n",
    "        data.loc[i, \"salutation\"] = \"Company\"\n",
    "    \n",
    "# Payment-type\n",
    "for i in range(len(data[\"paymenttype\"])):\n",
    "    value = data[\"paymenttype\"].iloc[i]\n",
    "    if value == 0:\n",
    "        data.loc[i, \"paymenttype\"] = \"Invoice\"\n",
    "    elif value == 1:\n",
    "        data.loc[i, \"paymenttype\"] = \"Cash\"\n",
    "    elif value == 2:\n",
    "        data.loc[i, \"paymenttype\"] = \"Transfer\"\n",
    "    elif value == 3:\n",
    "        data.loc[i, \"paymenttype\"] = \"Credit\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dummy variables\n",
    "data = pd.get_dummies(data, columns=[\"domain\", \"salutation\", \"model\", \"paymenttype\"], dtype = \"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing delivery delay\n",
    "\n",
    "We expect a potential delay in the delivery to have a systematic influence on a customer's re-purchase probability. The longer this delay gets, the less likely an expected re-purchase will become. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_9964\\1525678194.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-1 days +00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[i, \"delay\"] = data[\"deliverydatereal\"][i] - data[\"deliverydatepromised\"][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Delay column: 5478\n"
     ]
    }
   ],
   "source": [
    "# Convert actual delivery date to datetime\n",
    "for i in range(len(data)):  \n",
    "    if data.loc[i, \"deliverydatereal\"].startswith(\"0000\"):  \n",
    "        data.loc[i, \"deliverydatereal\"] = np.nan\n",
    "    else:\n",
    "        data.loc[i, \"deliverydatereal\"] = pd.to_datetime(data.loc[i, \"deliverydatereal\"])\n",
    "\n",
    "# Convert promised delivery date to datetime\n",
    "for i in range(len(data)):\n",
    "    if data.loc[i, \"deliverydatepromised\"].startswith(\"0000\"): # disregard missing values\n",
    "        data.loc[i, \"deliverydatepromised\"] = np.nan\n",
    "    else:\n",
    "        try: # Exception had to be added because some dates were out of bounds (Year 4746)\n",
    "            data.loc[i, \"deliverydatepromised\"] = pd.to_datetime(data.loc[i, \"deliverydatepromised\"])\n",
    "        except pd.errors.OutOfBoundsDatetime:\n",
    "            data.loc[i, \"deliverydatepromised\"] = np.nan\n",
    "\n",
    "# Compute actual delay in timedelta format\n",
    "data[\"delay\"] = [0] * len(data)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if pd.notna(data[\"deliverydatereal\"][i]) and pd.notna(data[\"deliverydatepromised\"][i]):\n",
    "        data.loc[i, \"delay\"] = data[\"deliverydatereal\"][i] - data[\"deliverydatepromised\"][i]\n",
    "    else:\n",
    "        data.loc[i, \"delay\"] = np.nan\n",
    "\n",
    "# Get days of delay\n",
    "for i in range(len(data)):\n",
    "    if pd.notna(data[\"delay\"][i]):\n",
    "        data.loc[i, \"delay\"] = data[\"delay\"][i].days\n",
    "    else:\n",
    "        data.loc[i, \"delay\"] = np.nan\n",
    "\n",
    "missing_values = data[\"delay\"].isna().sum()\n",
    "print(f\"Number of missing values in Delay column: {missing_values}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, only few classifiers can work with NaNs. Since we have over 5000 missing values, different ways of imputing them could have a considerable impact on our model predictions. \\\n",
    "Therefore we disregard the Delivery Delay variable and stick to the original data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to evaluate model precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_train, y_train_pred, y_test, y_test_pred):\n",
    "\n",
    "    # Convert y_train & y_test to np.array, as predictions will also be np.array\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Initialize variables for training set\n",
    "    TP_train = 0\n",
    "    FP_train = 0\n",
    "    TN_train = 0\n",
    "    FN_train = 0\n",
    "\n",
    "    # Evaluate training set predictions\n",
    "    for i in range(len(y_train_pred)): \n",
    "        if y_train[i] == y_train_pred[i] == 1:\n",
    "            TP_train += 1\n",
    "        if y_train_pred[i] == 1 and y_train[i] != y_train_pred[i]:\n",
    "            FP_train += 1\n",
    "        if y_train[i] == y_train_pred[i] == 0:\n",
    "            TN_train += 1\n",
    "        if y_train_pred[i] == 0 and y_train[i] != y_train_pred[i]:\n",
    "            FN_train += 1\n",
    "\n",
    "    # Calculate training set metrics\n",
    "    accuracy_train = (TP_train + TN_train) / (TP_train + TN_train + FP_train + FN_train) if (TP_train + TN_train + FP_train + FN_train) != 0 else 0\n",
    "    precision_train = TP_train / (TP_train + FP_train) if (TP_train + FP_train) != 0 else 0\n",
    "    sensitivity_train = TP_train / (TP_train + FN_train) if (TP_train + FN_train) != 0 else 0\n",
    "    specificity_train = TN_train / (TN_train + FP_train) if (TN_train + FP_train) != 0 else 0\n",
    "\n",
    "    # Initialize variables for test set\n",
    "    TP_test = 0\n",
    "    FP_test = 0\n",
    "    TN_test = 0\n",
    "    FN_test = 0\n",
    "\n",
    "    # Evaluate test set predictions\n",
    "    for i in range(len(y_test_pred)): \n",
    "        if y_test[i] == y_test_pred[i] == 1:\n",
    "            TP_test += 1\n",
    "        if y_test_pred[i] == 1 and y_test[i] != y_test_pred[i]:\n",
    "            FP_test += 1\n",
    "        if y_test[i] == y_test_pred[i] == 0:\n",
    "            TN_test += 1\n",
    "        if y_test_pred[i] == 0 and y_test[i] != y_test_pred[i]:\n",
    "            FN_test += 1\n",
    "\n",
    "    # Calculate test set metrics\n",
    "    accuracy_test = (TP_test + TN_test) / (TP_test + TN_test + FP_test + FN_test) if (TP_test + TN_test + FP_test + FN_test) != 0 else 0\n",
    "    precision_test = TP_test / (TP_test + FP_test) if (TP_test + FP_test) != 0 else 0\n",
    "    sensitivity_test = TP_test / (TP_test + FN_test) if (TP_test + FN_test) != 0 else 0\n",
    "    specificity_test = TN_test / (TN_test + FP_test) if (TN_test + FP_test) != 0 else 0\n",
    "\n",
    "\n",
    "   # Collect results in a dataframe \n",
    "    results_df = pd.DataFrame({\n",
    "        'Set': ['Training', 'Test'],\n",
    "        'Accuracy': [accuracy_train, accuracy_test],\n",
    "        'Precision': [precision_train, precision_test],\n",
    "        'Sensitivity': [sensitivity_train, sensitivity_test],\n",
    "        'Specificity': [specificity_train, specificity_test],\n",
    "        'TP': [TP_train, TP_test],\n",
    "        'FP': [FP_train, FP_test],\n",
    "        'TN': [TN_train, TN_test],\n",
    "        'FN': [FN_train, FN_test]\n",
    "    })\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Constructing the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivpostcode 31036\n",
      "advertisingdatacode 25905\n",
      "deliverydatepromised 9\n",
      "deliverydatereal 5472\n",
      "delay 5478\n"
     ]
    }
   ],
   "source": [
    "# Function to check for NAs in every column\n",
    "def count_na(df):\n",
    "    for col in df.columns:          # Loop over all columns\n",
    "        n_na = df[col].isna().sum() # Count occurrences of missing values\n",
    "        if n_na > 0:                # Only give column and count if there actually are NAs\n",
    "            print(col, n_na)        # Print column name and number of NAs\n",
    "\n",
    "# Apply function\n",
    "count_na(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only seem to have missing values in the *delivpostcode* and the *advertisingdatacode* column. \\\n",
    "One possible approach of fixing the issue in the *delivpostcode* column would be to simply impute the values of the *invoicepostcode* column. However, these values do not necessarily have to match. \\\n",
    "For the *advertisingdatacode* column, we do not have a logical approach of dealing with these rather unique data type and its missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dependent variable -> label \n",
    "y = data[\"target90\"]\n",
    "\n",
    "# Construct explanatory variables -> features (invoicepostcode may be kept as a feature)\n",
    "x = data.drop([\"customernumber\", \"date\", \"datecreated\", \"invoicepostcode\", \"delivpostcode\", \"advertisingdatacode\",\n",
    "                       \"deliverydatepromised\", \"deliverydatereal\", \"target90\", \"delay\"], axis = 1)\n",
    "\n",
    "# Split data into training and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_na(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customernumber', 'date', 'datecreated', 'invoicepostcode', 'delivpostcode', 'advertisingdatacode', 'deliverydatepromised', 'deliverydatereal', 'target90', 'delay']\n"
     ]
    }
   ],
   "source": [
    "disregarded_columns = []\n",
    "for col in data.columns:\n",
    "    if col not in x.columns:\n",
    "        disregarded_columns.append(col)\n",
    "print(disregarded_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Customernumber**: We don't expect the customernumer assigned to an individual to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Date**: We don't expect the date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Datecreated**: We don't expect the date of account creation to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Invoicepostcode**: We dont't expect the postcode of the invoice to have a systematic influence on a customer's re-purchase probability. \n",
    "- **Delivpostcode**: Too many missing values.\n",
    "- **Advertisingdatacode**: Too many missing values.\n",
    "- **Deliverydatepromised**: We don't expect the promised delivery date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Deliverydatereal**: We don't expect the actual delivery date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Target90**: This is the label we want to predict, therefore we do not include it in the training process.\n",
    "- **Delay**: We did expect the delivery delay to have a systematic influence on a customer's re-purchase probability. However, there are too many missing values present. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First try of estimation with RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, n_estimators=20,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, n_estimators=20,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=20,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to check if we can actually predict the data set\n",
    "forest = RandomForestClassifier(n_estimators = 20, max_depth = 100, min_samples_split = 2, min_samples_leaf = 1, criterion = \"entropy\", bootstrap = True, random_state = 0)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model predictions for training set\n",
    "y_train_pred = forest.predict(x_train)\n",
    "# Get model predictions for holdout set\n",
    "y_test_pred = forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.964888</td>\n",
       "      <td>0.979467</td>\n",
       "      <td>0.830002</td>\n",
       "      <td>0.995988</td>\n",
       "      <td>3530</td>\n",
       "      <td>74</td>\n",
       "      <td>18372</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.789187</td>\n",
       "      <td>0.247505</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.952465</td>\n",
       "      <td>124</td>\n",
       "      <td>377</td>\n",
       "      <td>7554</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity    TP   FP     TN  \\\n",
       "0  Training  0.964888   0.979467     0.830002     0.995988  3530   74  18372   \n",
       "1      Test  0.789187   0.247505     0.068966     0.952465   124  377   7554   \n",
       "\n",
       "     FN  \n",
       "0   723  \n",
       "1  1674  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate accuracy of cross-validated model \n",
    "evaluate_model(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we heavily overfit to our training data. But it is nice to see, that we can actually predict our data precisely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First hyperparameter-tuning attempt with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                      &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: range(10, 30),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 50)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                      &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: range(10, 30),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 50)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'log_loss',\n",
       "                                                      'entropy'],\n",
       "                                        'max_depth': range(10, 30),\n",
       "                                        'min_samples_leaf': range(5, 20),\n",
       "                                        'min_samples_split': range(10, 20),\n",
       "                                        'n_estimators': range(30, 50)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "max_depth = range(10,30) \n",
    "min_samples_split = range(10,20)\n",
    "min_samples_leaf = range(5,20)\n",
    "n_estimators = range(30,50)\n",
    "criterion = ['gini', 'log_loss', 'entropy']\n",
    "#cv = range(4,10)\n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators, 'criterion': criterion}\n",
    "\n",
    "# Set up forest classifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv = RandomizedSearchCV(forest, param_dist, n_jobs = -1, verbose = 1, n_iter = 500, cv = 5, scoring = \"balanced_accuracy\") # suited for imbalanced data sets \n",
    "\n",
    "# Fit it to the data\n",
    "forest_cv.fit(x_train,y_train) # does it automatically use best parameters for prediction afterwards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 41,\n",
       " 'min_samples_split': 15,\n",
       " 'min_samples_leaf': 5,\n",
       " 'max_depth': 23,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=23, min_samples_leaf=5, min_samples_split=12,\n",
       "                       n_estimators=44, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=23, min_samples_leaf=5, min_samples_split=12,\n",
       "                       n_estimators=44, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=23, min_samples_leaf=5, min_samples_split=12,\n",
       "                       n_estimators=44, random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 44, min_samples_split = 12, min_samples_leaf = 5, max_depth = 23, criterion = \"gini\", random_state = 42)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.814309</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.009170</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>18445</td>\n",
       "      <td>4214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.815911</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7930</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity  TP  FP     TN  \\\n",
       "0  Training  0.814309   0.975000     0.009170     0.999946  39   1  18445   \n",
       "1      Test  0.815911   0.888889     0.004449     0.999874   8   1   7930   \n",
       "\n",
       "     FN  \n",
       "0  4214  \n",
       "1  1790  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = forest.predict(x_train)\n",
    "y_test_pred = forest.predict(x_test)\n",
    "evaluate_model(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.014343</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>18444</td>\n",
       "      <td>4192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.815192</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7927</td>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity  TP  FP     TN  \\\n",
       "0  Training  0.815234   0.968254     0.014343     0.999892  61   2  18444   \n",
       "1      Test  0.815192   0.500000     0.002225     0.999496   4   4   7927   \n",
       "\n",
       "     FN  \n",
       "0  4192  \n",
       "1  1794  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Model predictions for training set\n",
    "y_train_pred = forest_cv.predict(x_train)\n",
    "# Get model predictions for holdout set\n",
    "y_test_pred = forest_cv.predict(x_test)\n",
    "# Evaluate performance of cross-validated model\n",
    "evaluate_model(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second hyperparameter-tuning attempt around the best parameters from the first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;),\n",
       "                   n_iter=500, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(20, 26),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(2, 8),\n",
       "                                        &#x27;min_samples_split&#x27;: range(12, 18),\n",
       "                                        &#x27;n_estimators&#x27;: range(38, 44)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;),\n",
       "                   n_iter=500, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(20, 26),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(2, 8),\n",
       "                                        &#x27;min_samples_split&#x27;: range(12, 18),\n",
       "                                        &#x27;n_estimators&#x27;: range(38, 44)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(criterion='entropy'),\n",
       "                   n_iter=500, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(20, 26),\n",
       "                                        'min_samples_leaf': range(2, 8),\n",
       "                                        'min_samples_split': range(12, 18),\n",
       "                                        'n_estimators': range(38, 44)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab optimal parameters from previous CV\n",
    "best_depth = forest_cv.best_params_[\"max_depth\"]\n",
    "best_split = forest_cv.best_params_[\"min_samples_split\"]\n",
    "best_leaf = forest_cv.best_params_[\"min_samples_leaf\"]\n",
    "best_est = forest_cv.best_params_[\"n_estimators\"]\n",
    "\n",
    "\n",
    "# Set range around previous optimal parameters to search for even better parameters\n",
    "max_depth = range(best_depth - 3, best_depth + 3)\n",
    "min_samples_split = range(best_split - 3, best_split + 3)\n",
    "min_samples_leaf = range(best_leaf - 3, best_leaf + 3)\n",
    "n_estimators = range(best_est - 3, best_est + 3)\n",
    "\n",
    "# Collect in dicionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators}\n",
    "\n",
    "# Set up forest\n",
    "forest = RandomForestClassifier(criterion = forest_cv.best_params_[\"criterion\"])\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv2 = RandomizedSearchCV(forest, param_dist, n_jobs = -1, cv = 5,verbose = 1, n_iter = 500, scoring = \"balanced_accuracy\")\n",
    "# Fit it to the data\n",
    "forest_cv2.fit(x_train, y_train) # does it automatically use best parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.824133</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.061839</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>18444</td>\n",
       "      <td>3990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.815808</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.998487</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>7919</td>\n",
       "      <td>1780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity   TP  FP     TN  \\\n",
       "0  Training  0.824133   0.992453     0.061839     0.999892  263   2  18444   \n",
       "1      Test  0.815808   0.600000     0.010011     0.998487   18  12   7919   \n",
       "\n",
       "     FN  \n",
       "0  3990  \n",
       "1  1780  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict and evaluate second cv model\n",
    "# Training data\n",
    "y_train_pred_cv2 = forest_cv2.predict(x_train)\n",
    "# Test data\n",
    "y_test_pred_cv2 = forest_cv2.predict(x_test)\n",
    "# Evalute performance\n",
    "evaluate_model(y_train, y_train_pred_cv2, y_test, y_test_pred_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Random Forest Regression Feature Importances')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importance\n",
    "fig = plt.figure()\n",
    "ax = fig.gca() #get current axis\n",
    "ax.bar(range(x_train.shape[1]), forest_cv2.best_estimator_.feature_importances_)\n",
    "ax.set_xticks(np.arange(x_train.shape[1]))\n",
    "ax.set_xticklabels([f'{col}' for col in x_train.columns])\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Feature Importance')\n",
    "ax.set_title('Random Forest Regression Feature Importances')\n",
    "\n",
    "# Ugly ass graph but its working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.189702</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065349</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.056658</td>\n",
       "      <td>numberitems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.052096</td>\n",
       "      <td>w0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.037189</td>\n",
       "      <td>w1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.033586</td>\n",
       "      <td>remi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032117</td>\n",
       "      <td>newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.030200</td>\n",
       "      <td>w9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.029115</td>\n",
       "      <td>w2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.023473</td>\n",
       "      <td>domain_others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.022407</td>\n",
       "      <td>domain_web.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.022174</td>\n",
       "      <td>domain_gmx.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.021733</td>\n",
       "      <td>salutation_Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.021044</td>\n",
       "      <td>salutation_Ms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.019926</td>\n",
       "      <td>w10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.019323</td>\n",
       "      <td>domain_t-online.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019037</td>\n",
       "      <td>voucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.017455</td>\n",
       "      <td>paymenttype_Invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.016615</td>\n",
       "      <td>paymenttype_Transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.016230</td>\n",
       "      <td>cancel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015607</td>\n",
       "      <td>shippingcosts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.015262</td>\n",
       "      <td>paymenttype_Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.014380</td>\n",
       "      <td>used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.013989</td>\n",
       "      <td>salutation_Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.013843</td>\n",
       "      <td>model_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.013738</td>\n",
       "      <td>domain_yahoo.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.013093</td>\n",
       "      <td>model_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.012946</td>\n",
       "      <td>w5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012806</td>\n",
       "      <td>entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.012530</td>\n",
       "      <td>domain_hotmail.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.011820</td>\n",
       "      <td>domain_aol.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.011758</td>\n",
       "      <td>domain_arcor.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.011706</td>\n",
       "      <td>domain_freenet.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.011505</td>\n",
       "      <td>model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.011194</td>\n",
       "      <td>paymenttype_Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.009844</td>\n",
       "      <td>w4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009044</td>\n",
       "      <td>deliverytype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.008439</td>\n",
       "      <td>w6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.006877</td>\n",
       "      <td>domain_online.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.006560</td>\n",
       "      <td>w7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004979</td>\n",
       "      <td>w3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.004823</td>\n",
       "      <td>domain_gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002664</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001797</td>\n",
       "      <td>domain_yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001773</td>\n",
       "      <td>gift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001561</td>\n",
       "      <td>domain_onlinehome.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>w8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>points</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Importance               Feature\n",
       "10    0.189702                weight\n",
       "4     0.065349                  case\n",
       "5     0.056658           numberitems\n",
       "14    0.052096                    w0\n",
       "15    0.037189                    w1\n",
       "11    0.033586                  remi\n",
       "1     0.032117            newsletter\n",
       "23    0.030200                    w9\n",
       "16    0.029115                    w2\n",
       "33    0.023473         domain_others\n",
       "35    0.022407         domain_web.de\n",
       "29    0.022174         domain_gmx.de\n",
       "39    0.021733        salutation_Mr.\n",
       "40    0.021044        salutation_Ms.\n",
       "24    0.019926                   w10\n",
       "34    0.019323    domain_t-online.de\n",
       "3     0.019037               voucher\n",
       "46    0.017455   paymenttype_Invoice\n",
       "47    0.016615  paymenttype_Transfer\n",
       "12    0.016230                cancel\n",
       "9     0.015607         shippingcosts\n",
       "45    0.015262    paymenttype_Credit\n",
       "13    0.014380                  used\n",
       "38    0.013989    salutation_Company\n",
       "43    0.013843               model_3\n",
       "37    0.013738       domain_yahoo.de\n",
       "42    0.013093               model_2\n",
       "19    0.012946                    w5\n",
       "7     0.012806                 entry\n",
       "30    0.012530     domain_hotmail.de\n",
       "25    0.011820        domain_aol.com\n",
       "26    0.011758       domain_arcor.de\n",
       "27    0.011706     domain_freenet.de\n",
       "41    0.011505               model_1\n",
       "44    0.011194      paymenttype_Cash\n",
       "18    0.009844                    w4\n",
       "2     0.009044          deliverytype\n",
       "20    0.008439                    w6\n",
       "31    0.006877      domain_online.de\n",
       "21    0.006560                    w7\n",
       "17    0.004979                    w3\n",
       "28    0.004823      domain_gmail.com\n",
       "0     0.002664                 title\n",
       "36    0.001797      domain_yahoo.com\n",
       "6     0.001773                  gift\n",
       "32    0.001561  domain_onlinehome.de\n",
       "22    0.000034                    w8\n",
       "8     0.000000                points"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances with names \n",
    "importance = pd.DataFrame(forest_cv2.best_estimator_.feature_importances_)\n",
    "feature_names = pd.DataFrame(x_train.columns)\n",
    "feature_importances = pd.concat([importance, feature_names], axis = 1)\n",
    "\n",
    "# Name columns accordingly\n",
    "feature_importances.columns = [\"Importance\", \"Feature\"]\n",
    "feature_importances.sort_values(by = \"Importance\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now what to we do with this? Can we just leave out the worst 10 features for example? \n",
    "# Random forest not really useful in predicting true positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(n_estimators = 500, learning_rate = 0.8)\n",
    "ada = ada.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.814001</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.997452</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>18399</td>\n",
       "      <td>4175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.813239</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>0.995209</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>7893</td>\n",
       "      <td>1779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity  TP  FP     TN  \\\n",
       "0  Training  0.814001   0.624000     0.018340     0.997452  78  47  18399   \n",
       "1      Test  0.813239   0.333333     0.010567     0.995209  19  38   7893   \n",
       "\n",
       "     FN  \n",
       "0  4175  \n",
       "1  1779  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict and evaluate \n",
    "# Training data\n",
    "y_train_pred_ada = ada.predict(x_train)\n",
    "# Test data\n",
    "y_test_pred_ada = ada.predict(x_test)\n",
    "# Evalute performance\n",
    "evaluate_model(y_train, y_train_pred_ada, y_test, y_test_pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'max_depth' for estimator AdaBoostClassifier(n_estimators=36). Valid parameters are: ['algorithm', 'base_estimator', 'estimator', 'learning_rate', 'n_estimators', 'random_state'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 717, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 230, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'max_depth' for estimator AdaBoostClassifier(n_estimators=36). Valid parameters are: ['algorithm', 'base_estimator', 'estimator', 'learning_rate', 'n_estimators', 'random_state'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m ada_cv \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(ada, param_dist, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Fit it to the data\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mada_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'max_depth' for estimator AdaBoostClassifier(n_estimators=36). Valid parameters are: ['algorithm', 'base_estimator', 'estimator', 'learning_rate', 'n_estimators', 'random_state']."
     ]
    }
   ],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "max_depth = range(1,5) \n",
    "n_estimators = range(10,50)\n",
    "learning_rate = np.arange(0.5, 5, 0.25) # In Adaboost learning rate can go to infinity (weights of previous misclassifications)\n",
    "#cv = range(4,10)\n",
    "\n",
    "# What about depth of base estimator? \n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'max_depth': max_depth, 'n_estimators': n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up AdaBoost classifier\n",
    "ada = AdaBoostClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "ada_cv = RandomizedSearchCV(ada, param_dist, n_jobs = -1, verbose = 1, n_iter = 1000, cv = 5, scoring = 'balanced_accuracy')\n",
    "# Fit it to the data\n",
    "ada_cv.fit(x_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_ada = {\n",
    "    'n_estimators': range(50, 200),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8134636733686937\n",
      "Precision (Share of positives correctly specified): 0.625\n",
      "Sensitivity (Share of actual true values found): 0.0008263097008758883\n",
      "Specificity (Share of actual false values found): 0.9998862645486598\n",
      "TP: 5 FP: 3 TN: 26374 FN: 6046\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from AdaCV model\n",
    "y_train_pred_ada_cv = ada_cv.predict(x_train)\n",
    "# Evaluate accuracy of cross-validated model\n",
    "evaluate_model(y_train, y_train_pred_ada_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 700 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=700, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                        &#x27;max_depth&#x27;: range(1, 15),\n",
       "                                        &#x27;n_estimators&#x27;: range(20, 40)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=700, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                        &#x27;max_depth&#x27;: range(1, 15),\n",
       "                                        &#x27;n_estimators&#x27;: range(20, 40)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=700, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                        'max_depth': range(1, 15),\n",
       "                                        'n_estimators': range(20, 40)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup parameter distributions for hyperparameter tuning\n",
    "max_depth = range(1, 15)\n",
    "n_estimators = range(20,40)\n",
    "learning_rate = np.linspace(0.1, 0.9, 9)\n",
    "param_dist = {\"max_depth\": max_depth, \"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up GradientBoostingClassifier\n",
    "xgb = XGBClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "xgb_cv = RandomizedSearchCV(xgb, param_dist, n_jobs = -1, cv = 5, verbose = 1, n_iter = 700, scoring = 'balanced_accuracy')\n",
    "# Fit it to the data\n",
    "xgb_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 32, 'max_depth': 14, 'learning_rate': 0.8}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.943698</td>\n",
       "      <td>0.975031</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>0.995647</td>\n",
       "      <td>3124</td>\n",
       "      <td>80</td>\n",
       "      <td>18297</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.773461</td>\n",
       "      <td>0.232244</td>\n",
       "      <td>0.119144</td>\n",
       "      <td>0.914875</td>\n",
       "      <td>206</td>\n",
       "      <td>681</td>\n",
       "      <td>7319</td>\n",
       "      <td>1523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity    TP   FP     TN  \\\n",
       "0  Training  0.943698   0.975031     0.722814     0.995647  3124   80  18297   \n",
       "1      Test  0.773461   0.232244     0.119144     0.914875   206  681   7319   \n",
       "\n",
       "     FN  \n",
       "0  1198  \n",
       "1  1523  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions and evaluate model performance\n",
    "# Get predictions for training data\n",
    "y_train_pred_gbrt_cv = xgb_cv.predict(x_train)\n",
    "# Get predictions for test data\n",
    "y_test_pred_gbrt_cv = xgb_cv.predict(x_test)\n",
    "# Evaluate model performance\n",
    "evaluate_model(y_train, y_train_pred_gbrt_cv, y_test, y_test_pred_gbrt_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-wise save of the model\n",
    "# joblib.dump(gbrt, \"gbrt.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting With XGBoost\n",
    "\n",
    "XGBoost, which is short for “Extreme Gradient Boosting,” is a library that provides an efficient implementation of the gradient boosting algorithm.\n",
    "\n",
    "The main benefit of the XGBoost implementation is computational efficiency and often better model performance.\n",
    "\n",
    "For more on the benefits and capability of XGBoost, see the tutorial:\n",
    "\n",
    "\n",
    "https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
