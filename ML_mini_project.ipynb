{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS405 Machine Learning Applications in Business and Economics Mini-Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">TBD: \n",
    "- What features to use? \n",
    "    - Construct new ones? \n",
    "    - Simply leave out all non-numeric features? \n",
    "    - Delivery-Delay might be interesting\n",
    "    - Delivery Delay\n",
    "\n",
    "- What is the goal of our model?\n",
    "    - Avoid false negatives? This way returning customers will not receive a voucher. \n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the realm of e-commerce, a common observation is that a significant proportion of customers engage in a single transaction and then cease further purchases. This phenomenon can be attributed to a multitude of factors. To mitigate this, e-commerce platforms employ a variety of strategies aimed at fostering customer loyalty. One such strategy involves the distribution of discount vouchers subsequent to the initial purchase, with the goal of incentivizing repeat transactions. However, indiscriminate distribution of these vouchers may not be an optimal strategy. This is because a segment of customers might have engaged in repeat purchases even in the absence of such incentives. Consequently, the redemption of these vouchers by such customers translates into a reduction in the retailer’s profit. Empirical analyses conducted by the media retailer have demonstrated that for 10% of non-buyers, the voucher instigates a purchase with an average order value of €20. Thus, if a voucher is dispatched to a customer who would not have actually made another purchase, the revenue increases by an average of €1.5. On the other hand, sending a voucher to a customer who would have made a purchase anyway results in a revenue loss equivalent to the voucher value of €5. For customers who don’t receive a voucher, there is no impact on revenues. Therefore, it is crucial to devise a more targeted approach for the distribution of these vouchers.\n",
    "\n",
    "## Task \n",
    "\n",
    "The task at hand involves constructing a predictive model that leverages various features associated with a customer’s initial order. The objective is to determine whether a €5.00 voucher should be issued to a specific customer. Detailed descriptions of these features can be found in the data dictionary.pdf file.\n",
    "The model should be designed to predict if a customer will place a subsequent order within a 90-day period following their initial purchase. This information is represented by the target90 variable in the dataset. The model’s performance is evaluated based on the expected revenue across all customers in a given dataset. This is computed by considering the model’s predictions in conjunction with the associated costs and revenues. It’s crucial to note that the model’s effectiveness is directly tied to its ability to maximize this expected revenue. Hence, the model should be optimized with this specific goal in mind.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier # Binary dependent variable\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import joblib # to save trained model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading in and getting an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32428, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_19184\\2584168657.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(\"train.csv\", sep = \";\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customernumber</th>\n",
       "      <th>salutation</th>\n",
       "      <th>title</th>\n",
       "      <th>domain</th>\n",
       "      <th>newsletter</th>\n",
       "      <th>model</th>\n",
       "      <th>paymenttype</th>\n",
       "      <th>deliverytype</th>\n",
       "      <th>invoicepostcode</th>\n",
       "      <th>voucher</th>\n",
       "      <th>case</th>\n",
       "      <th>numberitems</th>\n",
       "      <th>gift</th>\n",
       "      <th>entry</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33389.298569</td>\n",
       "      <td>0.541569</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>7.517115</td>\n",
       "      <td>0.169483</td>\n",
       "      <td>1.646910</td>\n",
       "      <td>1.000987</td>\n",
       "      <td>0.201955</td>\n",
       "      <td>48.752282</td>\n",
       "      <td>0.162020</td>\n",
       "      <td>2.934378</td>\n",
       "      <td>2.019551</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.414642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19148.090449</td>\n",
       "      <td>0.657044</td>\n",
       "      <td>0.083192</td>\n",
       "      <td>3.683945</td>\n",
       "      <td>0.375184</td>\n",
       "      <td>0.825981</td>\n",
       "      <td>1.092677</td>\n",
       "      <td>0.401465</td>\n",
       "      <td>24.361425</td>\n",
       "      <td>0.368475</td>\n",
       "      <td>1.319270</td>\n",
       "      <td>1.726046</td>\n",
       "      <td>0.067404</td>\n",
       "      <td>0.492668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16802.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33552.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50034.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66251.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customernumber    salutation         title        domain    newsletter  \\\n",
       "count    32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean     33389.298569      0.541569      0.006969      7.517115      0.169483   \n",
       "std      19148.090449      0.657044      0.083192      3.683945      0.375184   \n",
       "min          1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      16802.750000      0.000000      0.000000      4.000000      0.000000   \n",
       "50%      33552.500000      0.000000      0.000000      9.000000      0.000000   \n",
       "75%      50034.250000      1.000000      0.000000     11.000000      0.000000   \n",
       "max      66251.000000      2.000000      1.000000     12.000000      1.000000   \n",
       "\n",
       "              model   paymenttype  deliverytype  invoicepostcode  \\\n",
       "count  32428.000000  32428.000000  32428.000000     32428.000000   \n",
       "mean       1.646910      1.000987      0.201955        48.752282   \n",
       "std        0.825981      1.092677      0.401465        24.361425   \n",
       "min        1.000000      0.000000      0.000000         0.000000   \n",
       "25%        1.000000      0.000000      0.000000        30.000000   \n",
       "50%        1.000000      1.000000      0.000000        47.000000   \n",
       "75%        2.000000      2.000000      0.000000        66.000000   \n",
       "max        3.000000      3.000000      1.000000        99.000000   \n",
       "\n",
       "            voucher          case   numberitems          gift         entry  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.162020      2.934378      2.019551      0.004564      0.414642   \n",
       "std        0.368475      1.319270      1.726046      0.067404      0.492668   \n",
       "min        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%        0.000000      2.000000      1.000000      0.000000      0.000000   \n",
       "50%        0.000000      3.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      4.000000      2.000000      0.000000      1.000000   \n",
       "max        1.000000      5.000000     50.000000      1.000000      1.000000   \n",
       "\n",
       "        points  \n",
       "count  32428.0  \n",
       "mean       0.0  \n",
       "std        0.0  \n",
       "min        0.0  \n",
       "25%        0.0  \n",
       "50%        0.0  \n",
       "75%        0.0  \n",
       "max        0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separator is ;\n",
    "train = pd.read_csv(\"train.csv\", sep = \";\")\n",
    "\n",
    "# Get number of rows and columns\n",
    "print(train.shape)\n",
    "\n",
    "# Dataset is wide, print all rows and only first 15 columns\n",
    "train.describe().iloc[:,0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shippingcosts</th>\n",
       "      <th>weight</th>\n",
       "      <th>remi</th>\n",
       "      <th>cancel</th>\n",
       "      <th>used</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>w10</th>\n",
       "      <th>target90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.150611</td>\n",
       "      <td>637.920809</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>0.061613</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.902122</td>\n",
       "      <td>0.404342</td>\n",
       "      <td>0.276644</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>0.047027</td>\n",
       "      <td>0.180986</td>\n",
       "      <td>0.027908</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.164981</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>0.186598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.357674</td>\n",
       "      <td>724.358131</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>0.306833</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>1.654767</td>\n",
       "      <td>1.410395</td>\n",
       "      <td>1.353981</td>\n",
       "      <td>0.253596</td>\n",
       "      <td>0.434265</td>\n",
       "      <td>0.561751</td>\n",
       "      <td>0.299862</td>\n",
       "      <td>0.401782</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.836705</td>\n",
       "      <td>0.610509</td>\n",
       "      <td>0.389594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20076.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shippingcosts        weight          remi        cancel          used  \\\n",
       "count   32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean        0.150611    637.920809      0.059979      0.061613      0.068860   \n",
       "std         0.357674    724.358131      0.388740      0.306833      0.474444   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      3.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000    494.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000    920.000000      0.000000      0.000000      0.000000   \n",
       "max         1.000000  20076.000000     19.000000     17.000000     19.000000   \n",
       "\n",
       "                 w0            w1            w2            w3            w4  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.902122      0.404342      0.276644      0.018903      0.047027   \n",
       "std        1.654767      1.410395      1.353981      0.253596      0.434265   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       99.000000     84.000000     90.000000     15.000000     36.000000   \n",
       "\n",
       "                 w5            w6            w7            w8            w9  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.180986      0.027908      0.023128      0.000185      0.164981   \n",
       "std        0.561751      0.299862      0.401782      0.013601      0.836705   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       14.000000     27.000000     55.000000      1.000000     48.000000   \n",
       "\n",
       "                w10      target90  \n",
       "count  32428.000000  32428.000000  \n",
       "mean       0.092883      0.186598  \n",
       "std        0.610509      0.389594  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max       50.000000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second half of the columns\n",
    "# Dataset is wide, print all rows and only remaining columns\n",
    "train.describe().iloc[:,15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every column has a count of 32428 -> No missing values seem to be present. In the case of binary encoded variables, the mean directly reflects a percentage (if multiplied by 100). \\\n",
    "However, due to their datatype, some columns are not present in the .describe()-dataframe. Therefore, to fully detect all missing values, we loop over all columns in the as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivpostcode 31036\n",
      "advertisingdatacode 25905\n"
     ]
    }
   ],
   "source": [
    "# Function to check for NAs in every column\n",
    "def count_na(df):\n",
    "    for col in df.columns:          # Loop over all columns\n",
    "        n_na = df[col].isna().sum() # Count occurrences of missing values\n",
    "        if n_na > 0:                # Only give column and count if there actually are NAs\n",
    "            print(col, n_na)        # Print column name and number of NAs\n",
    "\n",
    "# Apply function\n",
    "count_na(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only seem to have missing values in the *delivpostcode* and the *advertisingdatacode* column. \\\n",
    "One possible approach of fixing the issue in the *delivpostcode* column would be to simply impute the values of the *invoicepostcode* column. However, these values do not necessarily have to match. \\\n",
    "For the *advertisingdatacode* column, we do not have a logical approach of dealing with these rather unique data type and its missing values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing delivery delay\n",
    "\n",
    "We expect a potential delay in the delivery to have a systematic influence on a customer's re-purchase probability. The longer this delay gets, the less likely an expected re-purchase will become. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_19184\\2369885331.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-1 days +00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train.loc[i, \"delay\"] = train[\"deliverydatereal\"][i] - train[\"deliverydatepromised\"][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Delay column: 5478\n"
     ]
    }
   ],
   "source": [
    "# Convert actual delivery date to datetime\n",
    "for i in range(len(train)):  \n",
    "    if train.loc[i, \"deliverydatereal\"].startswith(\"0000\"):  \n",
    "        train.loc[i, \"deliverydatereal\"] = np.nan\n",
    "    else:\n",
    "        train.loc[i, \"deliverydatereal\"] = pd.to_datetime(train.loc[i, \"deliverydatereal\"])\n",
    "\n",
    "# Convert promised delivery date to datetime\n",
    "for i in range(len(train)):\n",
    "    if train.loc[i, \"deliverydatepromised\"].startswith(\"0000\"): # disregard missing values\n",
    "        train.loc[i, \"deliverydatepromised\"] = np.nan\n",
    "    else:\n",
    "        try: # Exception had to be added because some dates were out of bounds (Year 4746)\n",
    "            train.loc[i, \"deliverydatepromised\"] = pd.to_datetime(train.loc[i, \"deliverydatepromised\"])\n",
    "        except pd.errors.OutOfBoundsDatetime:\n",
    "            train.loc[i, \"deliverydatepromised\"] = np.nan\n",
    "\n",
    "# Compute actual delay in timedelta format\n",
    "train[\"delay\"] = [0] * len(train)\n",
    "\n",
    "for i in range(len(train)):\n",
    "    if pd.notna(train[\"deliverydatereal\"][i]) and pd.notna(train[\"deliverydatepromised\"][i]):\n",
    "        train.loc[i, \"delay\"] = train[\"deliverydatereal\"][i] - train[\"deliverydatepromised\"][i]\n",
    "    else:\n",
    "        train.loc[i, \"delay\"] = np.nan\n",
    "\n",
    "# Get days of delay\n",
    "for i in range(len(train)):\n",
    "    if pd.notna(train[\"delay\"][i]):\n",
    "        train.loc[i, \"delay\"] = train[\"delay\"][i].days\n",
    "    else:\n",
    "        train.loc[i, \"delay\"] = np.nan\n",
    "\n",
    "missing_values = train[\"delay\"].isna().sum()\n",
    "print(f\"Number of missing values in Delay column: {missing_values}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, only few classifiers can work with NaNs. Since we have over 5000 missing values, different ways of imputing them could have a considerable impact on our model predictions. \\\n",
    "Therefore we disregard the Delivery Delay variable and stick to the original data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to evaluate model precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only includes training data for now (handle division by 0)\n",
    "def evaluate_model(y_train, y_train_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_train_pred)): \n",
    "        if y_train[i]==y_train_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_train_pred[i]==1 and y_train[i]!=y_train_pred[i]:\n",
    "           FP += 1\n",
    "        if y_train[i]==y_train_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_train_pred[i]==0 and y_train[i]!=y_train_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) != 0 else 0\n",
    "    # Calculate precision\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    # Calculate sensitivity\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    # Calculate specificity\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "    # Print results\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision (Share of positives correctly specified):\", precision) # of all actual 1s, how many did we predict as 1\n",
    "    print(\"Sensitivity (Share of actual true values found):\", sensitivity) # of all our predictions with 1, how many were actually 1\n",
    "    print(\"Specificity (Share of actual false values found):\", specificity) # of all our predictions with 0, how many were actually 0\n",
    "    print(f\"TP: {TP}\", f\"FP: {FP}\", f\"TN: {TN}\", f\"FN: {FN}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Constructing the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct training data set to contain only numeric variables (as listed in .describe())\n",
    "x_train = train[train.describe().columns].drop(columns = [\"target90\", \"customernumber\"]) #customernumber maybe too \n",
    "#X_train = pd.concat([X_train, train[\"delay\"]])\n",
    "# X_train.columns = X_train.columns.astype(str)\n",
    "# Construct dependent variable\n",
    "y_train = train[\"target90\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customernumber', 'date', 'datecreated', 'delivpostcode', 'advertisingdatacode', 'deliverydatepromised', 'deliverydatereal', 'target90', 'delay']\n"
     ]
    }
   ],
   "source": [
    "disregarded_columns = []\n",
    "for col in train.columns:\n",
    "    if col not in x_train.describe().columns:\n",
    "        disregarded_columns.append(col)\n",
    "print(disregarded_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Customernumber**: We don't expect the customernumer assigned to an individual to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Date**: We don't expect the date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Datecreated**: We don't expect the date of account creation to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Delivpostcode**: Too many missing values.\n",
    "- **Advertisingdatacode**: Too many missing values.\n",
    "- **Deliverydatepromised**: We don't expect the promised delivery date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Deliverydatereal**: We don't expect the actual delivery date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Delay**: We did expect the delivery delay to have a systematic influence on a customer's re-purchase probability. However, there are too many missing values present. \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First try of estimation with RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, n_estimators=20,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, n_estimators=20,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=20,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to check if we can actually estimate the data set\n",
    "forest = RandomForestClassifier(n_estimators = 20, max_depth = 100, min_samples_split = 2, min_samples_leaf = 1, criterion = \"entropy\", bootstrap = True, random_state = 0)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model predictions\n",
    "y_train_pred = forest.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate accuracy of cross-validated model \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m evaluate_model(y_train, \u001b[43my_train_pred\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy of cross-validated model \n",
    "evaluate_model(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First hyperparameter-tuning attempt with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(10, 20),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 50)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(10, 20),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 50)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(10, 20),\n",
       "                                        'min_samples_leaf': range(5, 20),\n",
       "                                        'min_samples_split': range(10, 20),\n",
       "                                        'n_estimators': range(30, 50)},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "max_depth = range(10,20) \n",
    "min_samples_split = range(10,20)\n",
    "min_samples_leaf = range(5,20)\n",
    "n_estimators = range(30,50)\n",
    "#cv = range(4,10)\n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators}\n",
    "\n",
    "# Set up forest classifier\n",
    "forest = RandomForestClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv = RandomizedSearchCV(forest, param_dist, n_jobs = -1, verbose = 1, n_iter = 1000, scoring = 'accuracy', cv = 5)#, random_state = 0) # not same results though\n",
    "\n",
    "# Fit it to the data\n",
    "forest_cv.fit(x_train,y_train) # does it automatically use best parameters? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second hyperparameter-tuning attempt around the best parameters from the first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 256 is smaller than n_iter=1000. Running 256 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(15, 19),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(8, 12),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 14),\n",
       "                                        &#x27;n_estimators&#x27;: range(32, 36)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(15, 19),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(8, 12),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 14),\n",
       "                                        &#x27;n_estimators&#x27;: range(32, 36)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(15, 19),\n",
       "                                        'min_samples_leaf': range(8, 12),\n",
       "                                        'min_samples_split': range(10, 14),\n",
       "                                        'n_estimators': range(32, 36)},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab optimal parameters from previous CV\n",
    "best_depth = forest_cv.best_params_[\"max_depth\"]\n",
    "best_split = forest_cv.best_params_[\"min_samples_split\"]\n",
    "best_leaf = forest_cv.best_params_[\"min_samples_leaf\"]\n",
    "best_est = forest_cv.best_params_[\"n_estimators\"]\n",
    "\n",
    "\n",
    "# Set range around previous optimal parameters to search for even better parameters\n",
    "max_depth = range(best_depth - 2, best_depth + 2)\n",
    "min_samples_split = range(best_split - 2, best_split + 2)\n",
    "min_samples_leaf = range(best_leaf - 2, best_leaf + 2)\n",
    "n_estimators = range(best_est - 2, best_est + 2)\n",
    "\n",
    "\n",
    "# Collect in dicionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators}\n",
    "\n",
    "# Set up forest\n",
    "forest = RandomForestClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv2 = RandomizedSearchCV(forest, param_dist, n_jobs = -1, cv = 5,verbose = 1, n_iter = 1000, scoring = 'accuracy')\n",
    "# Fit it to the data\n",
    "forest_cv2.fit(x_train, y_train) # does it automatically use best parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8144813124460343\n",
      "Precision (Share of positives correctly specified): 0.9487179487179487\n",
      "Sensitivity (Share of actual true values found): 0.006114691786481574\n",
      "Specificity (Share of actual false values found): 0.9999241763657732\n",
      "TP: 37 FP: 2 TN: 26375 FN: 6014\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate first cv model\n",
    "y_train_pred_cv = forest_cv.predict(x_train)\n",
    "evaluate_model(y_train, y_train_pred_cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8153139262365857\n",
      "Precision (Share of positives correctly specified): 0.984375\n",
      "Sensitivity (Share of actual true values found): 0.010411502231036193\n",
      "Specificity (Share of actual false values found): 0.9999620881828866\n",
      "TP: 63 FP: 1 TN: 26376 FN: 5988\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate second cv model\n",
    "y_train_pred_cv2 = forest_cv2.predict(x_train)\n",
    "evaluate_model(y_train, y_train_pred_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Random Forest Regression Feature Importances')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABypElEQVR4nO3deVxU1f8/8NcMMMO+ySaKoIDighsqoiEuFO4buWVfwQWXNE3K0j6mkhlqLpRrm9iiuZRpWmGKa66JS5q7uaWAmAoiCsK8f3/4m5szoDIGgvZ6Ph73oXPuOfe+7zIzb849945KRAREREREpFCXdQBERERE5Q0TJCIiIiIjTJCIiIiIjDBBIiIiIjLCBImIiIjICBMkIiIiIiNMkIiIiIiMMEEiIiIiMsIEiYiIiMgIEyQqt6Kjo+Hj41PWYdB/zJYtW6BSqbBly5ayDoWIyhATJMLixYuhUqmUydzcHJUqVUJ0dDQuXbpU1uGVG8b76f5p7NixZR1ekd5//32sXr26WHXPnTtnsE1qtRrOzs5o164ddu3aVbqBEgCgZcuWDzzHjh8/XirrnD9/PhYvXlwqy/63WrZsiTp16pR1GI/t8uXLmDRpEg4ePFjWodBjMC/rAKj8ePfdd1G1alXcuXMHu3fvxuLFi/Hrr7/iyJEjsLS0LOvwyg39frpfef0Qf//99/Hiiy+ia9euxW7Tp08ftG/fHgUFBTh58iTmz5+PVq1a4bfffkNgYGDpBVtOtGjRArdv34ZGoymT9VeuXBnx8fGFyj09PUtlffPnz4eLiwuio6NLZfn/ZZcvX0ZcXBx8fHxQv379sg6HTMQEiRTt2rVDo0aNAACDBg2Ci4sLpk2bhh9++AE9e/Ys4+jKj/v3U0m6desWbGxsSny5pmrYsCFefvll5XVoaCjatWuHBQsWYP78+U80lrLYJ2q1ukz/IHBwcDDY/08jEcGdO3dgZWVV1qGUifz8fOh0urIOg/4lXmKjBwoNDQUAnDlzRinLy8vDhAkTEBQUBAcHB9jY2CA0NBSbN282aKu/XDNjxgx88skn8PX1hVarRePGjfHbb78VWtfq1atRp04dWFpaok6dOvj++++LjOnWrVt4/fXX4eXlBa1Wixo1amDGjBkQEYN6KpUKI0aMwMqVK1GrVi1YWVkhJCQEhw8fBgB8/PHH8PPzg6WlJVq2bIlz5879m11lYNOmTQgNDYWNjQ0cHR3RpUsXHDt2zKDOpEmToFKpcPToUbz00ktwcnLCc889p8z/+uuvERQUBCsrKzg7O6N37964ePGiwTJOnTqFyMhIeHh4wNLSEpUrV0bv3r2RmZmp7INbt27hiy++UC7TPE4vQVHnAQDcuHEDr732mnIs/Pz8MG3atEJfDH///Tf+7//+D/b29nB0dERUVBQOHToElUplcGknOjoatra2OHPmDNq3bw87Ozv07dsXAKDT6ZCQkIDatWvD0tIS7u7uGDJkCK5fv26wrn379iEiIgIuLi6wsrJC1apVMWDAAIM6y5YtQ1BQEOzs7GBvb4/AwEB8+OGHyvwHjUFauXKlckxcXFzw8ssvF7oErd+GS5cuoWvXrrC1tYWrqyveeOMNFBQUFH+nP0Rubi4mTpwIPz8/aLVaeHl54c0330Rubq5BvcTERLRu3Rpubm7QarWoVasWFixYYFDHx8cHf/zxB7Zu3aqcIy1btgTwzzlqTH+p+f73jI+PDzp27Ij169ejUaNGsLKywscffwyg+OdJcf3b97b+sl1KSgqaNWumnCcLFy4stK4rV65g4MCBcHd3h6WlJerVq4cvvvjCoM79n3UJCQnKZ938+fPRuHFjAED//v2V/as/57dv344ePXqgSpUqynEcPXo0bt++bbB8U84pnU6HDz/8EIGBgbC0tISrqyvatm2Lffv2GdQric+X/wL2INED6T9YnJyclLKsrCx89tln6NOnD2JiYnDz5k18/vnniIiIwN69ewt1Iy9duhQ3b97EkCFDoFKpMH36dHTv3h1//vknLCwsAAC//PILIiMjUatWLcTHx+Pvv/9G//79UblyZYNliQg6d+6MzZs3Y+DAgahfvz7Wr1+PMWPG4NKlS5g9e7ZB/e3bt+OHH37A8OHDAQDx8fHo2LEj3nzzTcyfPx+vvPIKrl+/junTp2PAgAHYtGlTsfZLZmYmrl69alDm4uICANi4cSPatWuHatWqYdKkSbh9+zbmzJmD5s2bY//+/YUGnffo0QP+/v54//33lSRvypQpeOedd9CzZ08MGjQIGRkZmDNnDlq0aIEDBw7A0dEReXl5iIiIQG5uLl599VV4eHjg0qVLWLduHW7cuAEHBwd89dVXGDRoEJo0aYLBgwcDAHx9fYu1jfcr6jzIyclBWFgYLl26hCFDhqBKlSrYuXMnxo0bh9TUVCQkJAC494HdqVMn7N27F8OGDUNAQADWrFmDqKioIteVn5+PiIgIPPfcc5gxYwasra0BAEOGDMHixYvRv39/jBw5EmfPnsXcuXNx4MAB7NixAxYWFrhy5QpeeOEFuLq6YuzYsXB0dMS5c+ewatUqZfkbNmxAnz590KZNG0ybNg0AcOzYMezYsQOjRo164D7Qr7tx48aIj49Heno6PvzwQ+zYsUM5JnoFBQWIiIhAcHAwZsyYgY0bN2LmzJnw9fXFsGHDHrm/CwoKCp1flpaWsLW1hU6nQ+fOnfHrr79i8ODBqFmzJg4fPozZs2fj5MmTBuPNFixYgNq1a6Nz584wNzfH2rVr8corr0Cn0ynviYSEBLz66quwtbXF//73PwCAu7v7I2MsyokTJ9CnTx8MGTIEMTExqFGjRrHPE1P92/f29evX0b59e/Ts2RN9+vTBihUrMGzYMGg0GiWhvn37Nlq2bInTp09jxIgRqFq1KlauXIno6GjcuHGj0PmSmJiIO3fuYPDgwdBqtejWrRtu3ryJCRMmYPDgwcofGs2aNQNwL+HOycnBsGHDUKFCBezduxdz5szBX3/9hZUrVxosu7jn1MCBA7F48WK0a9cOgwYNQn5+PrZv347du3crvd4l9fnynyD0n5eYmCgAZOPGjZKRkSEXL16Ub7/9VlxdXUWr1crFixeVuvn5+ZKbm2vQ/vr16+Lu7i4DBgxQys6ePSsApEKFCnLt2jWlfM2aNQJA1q5dq5TVr19fKlasKDdu3FDKfvnlFwEg3t7eStnq1asFgLz33nsG63/xxRdFpVLJ6dOnlTIAotVq5ezZs0rZxx9/LADEw8NDsrKylPJx48YJAIO6D9tPRU33b4ubm5v8/fffStmhQ4dErVZLv379lLKJEycKAOnTp4/BOs6dOydmZmYyZcoUg/LDhw+Lubm5Un7gwAEBICtXrnxozDY2NhIVFfXQOnr6YxYXFycZGRmSlpYm27dvl8aNGxda1+TJk8XGxkZOnjxpsIyxY8eKmZmZXLhwQUREvvvuOwEgCQkJSp2CggJp3bq1AJDExESlPCoqSgDI2LFjDZa5fft2ASBLliwxKE9KSjIo//777wWA/Pbbbw/cxlGjRom9vb3k5+c/sM7mzZsFgGzevFlERPLy8sTNzU3q1Kkjt2/fVuqtW7dOAMiECRMKbcO7775rsMwGDRpIUFDQA9epFxYWVuT5pT+GX331lajVatm+fbtBu4ULFwoA2bFjh1KWk5NTaPkRERFSrVo1g7LatWtLWFhYobr6c9SY/n1w//vF29tbAEhSUpJB3eKeJw8SFhYmtWvXNij7t+9t/T6eOXOmUpabm6u8d/Py8kREJCEhQQDI119/rdTLy8uTkJAQsbW1Vdajf9/Y29vLlStXDGL97bffCp3nekUdn/j4eFGpVHL+/HmlrLjn1KZNmwSAjBw5stBydTqdiJT858uzjpfYSBEeHg5XV1d4eXnhxRdfhI2NDX744QeDnhwzMzNl8KpOp8O1a9eQn5+PRo0aYf/+/YWW2atXL4OeB/1fUX/++ScAIDU1FQcPHkRUVJTBXyXPP/88atWqZbCsn376CWZmZhg5cqRB+euvvw4Rwc8//2xQ3qZNG4Mem+DgYABAZGQk7OzsCpXrY3qUefPmYcOGDQbT/dsSHR0NZ2dnpX7dunXx/PPP46effiq0rKFDhxq8XrVqFXQ6HXr27ImrV68qk4eHB/z9/ZVLmfp9tX79euTk5BQr7uKaOHEiXF1d4eHhgdDQUBw7dgwzZ87Eiy++qNRZuXIlQkND4eTkZBBneHg4CgoKsG3bNgBAUlISLCwsEBMTo7RVq9XKX/5FMe5lWblyJRwcHPD8888brCsoKAi2trbKPtH34qxbtw53794tctmOjo64deuWcsyKY9++fbhy5QpeeeUVg7FJHTp0QEBAAH788cdCbYyPa2hoaLHPLx8fn0Ln15tvvgng3r6oWbMmAgICDPZF69atAcDgUvf943/0vZ5hYWH4888/S+UySdWqVREREWFQVtzzxFT/9r1tbm6OIUOGKK81Gg2GDBmCK1euICUlBcC9zxsPDw/06dNHqWdhYYGRI0ciOzsbW7duNVhmZGQkXF1di70N9x+fW7du4erVq2jWrBlEBAcOHChU/1Hn1HfffQeVSoWJEycWaqu/VFoePl+eJrzERop58+ahevXqyMzMxKJFi7Bt2zZotdpC9b744gvMnDkTx48fN/giMr6zCwCqVKli8FqfLOnHjpw/fx4A4O/vX6htjRo1DJKu8+fPw9PT0+ADEABq1qxpsKwHrVv/pvfy8iqy3Hg8y4M0adKkyEHa+vXXqFGj0LyaNWti/fr1hQYdG++zU6dOQUSK3B8AlMuSVatWRWxsLGbNmoUlS5YgNDQUnTt3xssvv/yvu78HDx6MHj164M6dO9i0aRM++uijQmMdTp06hd9///2BXwhXrlwBcG+fVKxYUblUpufn51dkO3Nz80KXVk+dOoXMzEy4ubk9dF1hYWGIjIxEXFwcZs+ejZYtW6Jr16546aWXlPP4lVdewYoVK9CuXTtUqlQJL7zwAnr27Im2bds+cH887LgGBATg119/NSjTj/24n5OTU7HPLxsbG4SHhxc579SpUzh27Ngj9zsA7NixAxMnTsSuXbsKfcllZmaW+GWSot7/xT1PTPVv39uenp6FBv9Xr14dwL1Lyk2bNsX58+fh7+8PtdqwH+FBnzdFbf/DXLhwARMmTMAPP/xQKD7jBLY459SZM2fg6elp8MeZsfLw+fI0YYJEivu/+Lt27YrnnnsOL730Ek6cOAFbW1sA9wb3RUdHo2vXrhgzZgzc3NxgZmaG+Pj4QoN4gXs9TkURo0HVpeFB6y7LmIwZ3+Wj0+mgUqnw888/Fxmn/jgAwMyZMxEdHY01a9bgl19+wciRIxEfH4/du3cXSjJM4e/vr3xBd+zYEWZmZhg7dixatWqlnB86nQ7PP/+80rNhTP9lYyqtVlvoC0mn08HNzQ1Lliwpso3+i0OlUuHbb7/F7t27sXbtWqxfvx4DBgzAzJkzsXv3btja2sLNzQ0HDx7E+vXr8fPPP+Pnn39GYmIi+vXrV2jw7eN60PlVEnQ6HQIDAzFr1qwi5+sThDNnzqBNmzYICAjArFmz4OXlBY1Gg59++gmzZ88u1gDpogZoA3jgYPOi7lgrrfOkPL63Tbljr6CgAM8//zyuXbuGt956CwEBAbCxscGlS5cQHR1d6PiU1DlVHj5fniZMkKhI+qSnVatWmDt3rvIgxG+//RbVqlXDqlWrDD5Ai+rWLQ5vb28A9/6yMXbixIlCdTdu3IibN28a9CLpH6CnX1ZZ0a/fOG7gXowuLi6PvGXd19cXIoKqVasW68sjMDAQgYGBGD9+PHbu3InmzZtj4cKFeO+99wA8+EvOFP/73//w6aefYvz48UhKSlLizM7OfmBPh563tzc2b96MnJwcg16k06dPF3v9vr6+2LhxI5o3b16sL6GmTZuiadOmmDJlCpYuXYq+ffti2bJlGDRoEIB7l1M6deqETp06QafT4ZVXXsHHH3+Md955p8ierfuPq/5Slt6JEyee6Hnn6+uLQ4cOoU2bNg89tmvXrkVubi5++OEHg94W47tNgQefI/re3hs3bhgMQjfuOXlUvMU5T560y5cvF+rNPXnyJAAol+68vb3x+++/Q6fTGSTtpnzePGjfHj58GCdPnsQXX3yBfv36KeWmXPo15uvri/Xr1+PatWsP7EUq6c+XZx3HINEDtWzZEk2aNEFCQgLu3LkD4J+/ZO7/i2zPnj2P/aTlihUron79+vjiiy8MupU3bNiAo0ePGtTVP7xw7ty5BuWzZ8+GSqVCu3btHiuGknL/tty4cUMpP3LkCH755Re0b9/+kcvo3r07zMzMEBcXV+ivXhHB33//DeDe3YT5+fkG8wMDA6FWqw1u97axsTGI5XE4OjpiyJAhWL9+vfJE4J49e2LXrl1Yv359ofo3btxQYouIiMDdu3fx6aefKvN1Oh3mzZtX7PX37NkTBQUFmDx5cqF5+fn5yvZdv3690D7T31Wp3yf6/aenVqtRt25dgzrGGjVqBDc3NyxcuNCgzs8//4xjx46hQ4cOxd6Wf6tnz564dOmSwf7Uu337Nm7dugWg6PdpZmYmEhMTC7V70Dmiv+Px/nFC+sdGmBJvcc6TJy0/P195DAFw7/ElH3/8MVxdXREUFATg3udNWloali9fbtBuzpw5sLW1RVhY2CPXo0/AjPdvUcdHRAweN2GqyMhIiAji4uIKzdOvp6Q/X5517EGihxozZgx69OiBxYsXY+jQoejYsSNWrVqFbt26oUOHDjh79iwWLlyIWrVqITs7+7HWER8fjw4dOuC5557DgAEDcO3aNcyZMwe1a9c2WGanTp3QqlUr/O9//8O5c+dQr149/PLLL1izZg1ee+21x7qFvaR98MEHaNeuHUJCQjBw4EDlNn8HBwdMmjTpke19fX3x3nvvYdy4cTh37hy6du0KOzs7nD17Ft9//z0GDx6MN954A5s2bcKIESPQo0cPVK9eHfn5+fjqq69gZmaGyMhIZXlBQUHYuHEjZs2aBU9PT1StWlUZuGqKUaNGISEhAVOnTsWyZcswZswY/PDDD+jYsSOio6MRFBSEW7du4fDhw/j2229x7tw5uLi4oGvXrmjSpAlef/11nD59GgEBAfjhhx9w7do1AMXr4QoLC8OQIUMQHx+PgwcP4oUXXoCFhQVOnTqFlStX4sMPP8SLL76IL774AvPnz0e3bt3g6+uLmzdv4tNPP4W9vb2SnA4aNAjXrl1D69atUblyZZw/fx5z5sxB/fr1lbElxiwsLDBt2jT0798fYWFh6NOnj3Kbv4+PD0aPHm3y/nxc//d//4cVK1Zg6NCh2Lx5M5o3b46CggIcP34cK1asUJ5D9MILLyg9ZUOGDEF2djY+/fRTuLm5ITU11WCZQUFBWLBgAd577z34+fnBzc0NrVu3xgsvvIAqVapg4MCBGDNmDMzMzLBo0SK4urriwoULxYq3uOfJk+bp6Ylp06bh3LlzqF69OpYvX46DBw/ik08+UcbhDB48GB9//DGio6ORkpICHx8ffPvtt9ixYwcSEhIKjYUsiq+vLxwdHbFw4ULY2dnBxsYGwcHBCAgIgK+vL9544w1cunQJ9vb2+O6774o9Tq0orVq1wv/93//ho48+wqlTp9C2bVvodDps374drVq1wogRI0r88+WZ92RvmqPySH/bblG3RxcUFIivr6/4+vpKfn6+6HQ6ef/998Xb21u0Wq00aNBA1q1bJ1FRUQa35Otvff3ggw8KLROATJw40aDsu+++k5o1a4pWq5VatWrJqlWrCi1TROTmzZsyevRo8fT0FAsLC/H395cPPvhAuY31/nUMHz7coOxBMelv637ULa0P20/327hxozRv3lysrKzE3t5eOnXqJEePHjWoo7+FOiMjo8hlfPfdd/Lcc8+JjY2N2NjYSEBAgAwfPlxOnDghIiJ//vmnDBgwQHx9fcXS0lKcnZ2lVatWsnHjRoPlHD9+XFq0aCFWVlYGt4sX5WHHTEQkOjpazMzMlMcp3Lx5U8aNGyd+fn6i0WjExcVFmjVrJjNmzFBulRYRycjIkJdeekns7OzEwcFBoqOjZceOHQJAli1bptSLiooSGxubB8b3ySefSFBQkFhZWYmdnZ0EBgbKm2++KZcvXxYRkf3790ufPn2kSpUqotVqxc3NTTp27Cj79u1TlvHtt9/KCy+8IG5ubqLRaKRKlSoyZMgQSU1NVeoY3+avt3z5cmnQoIFotVpxdnaWvn37yl9//WVQ50Hb8KBb5o0VdVu7sby8PJk2bZrUrl1btFqtODk5SVBQkMTFxUlmZqZS74cffpC6deuKpaWl+Pj4yLRp02TRokWFbntPS0uTDh06iJ2dnQAwuOU/JSVFgoODlX01a9asB97m36FDhyLjLe55Utz98W/f2/pl7tu3T0JCQsTS0lK8vb1l7ty5hdafnp4u/fv3FxcXF9FoNBIYGFjolv1HvW/WrFkjtWrVEnNzc4Nb/o8ePSrh4eFia2srLi4uEhMTI4cOHSry8RfFPafy8/Plgw8+kICAANFoNOLq6irt2rWTlJQUg3ol9fnyrFOJlMHIVCL6T1u9ejW6deuGX3/9Fc2bNy/rcOg/pGXLlrh69SqOHDlS1qFQOccxSERUqox/OqGgoABz5syBvb09GjZsWEZRERE9HMcgEVGpevXVV3H79m2EhIQgNzcXq1atws6dO/H+++//Z3/MlIjKPyZIRFSqWrdujZkzZ2LdunW4c+cO/Pz8MGfOHIwYMaKsQyMieiCOQSIiIiIywjFIREREREaYIBEREREZ4Rikx6TT6XD58mXY2dmVyM85EBERUekTEdy8eROenp6FfvvxfkyQHtPly5cL/XI0ERERPR0uXrz40B/eZYL0mPSPmb948SLs7e3LOBoiIiIqjqysLHh5eT3y52KYID0m/WU1e3t7JkhERERPmUcNj+EgbSIiIiIjTJCIiIiIjDBBIiIiIjLCBImIiIjICBMkIiIiIiNMkIiIiIiMMEEiIiIiMsIEiYiIiMgIEyQiIiIiI0yQiIiIiIyUeYI0b948+Pj4wNLSEsHBwdi7d+8D6/7xxx+IjIyEj48PVCoVEhISCtXRzzOehg8frtRp2bJloflDhw4tjc0jIiKip1CZJkjLly9HbGwsJk6ciP3796NevXqIiIjAlStXiqyfk5ODatWqYerUqfDw8Ciyzm+//YbU1FRl2rBhAwCgR48eBvViYmIM6k2fPr1kN46IiIieWmWaIM2aNQsxMTHo378/atWqhYULF8La2hqLFi0qsn7jxo3xwQcfoHfv3tBqtUXWcXV1hYeHhzKtW7cOvr6+CAsLM6hnbW1tUI8/OEtERER6ZZYg5eXlISUlBeHh4f8Eo1YjPDwcu3btKrF1fP311xgwYEChX+1dsmQJXFxcUKdOHYwbNw45OTkPXVZubi6ysrIMJiIiIno2mZfViq9evYqCggK4u7sblLu7u+P48eMlso7Vq1fjxo0biI6ONih/6aWX4O3tDU9PT/z+++946623cOLECaxateqBy4qPj0dcXFyJxEVERETlW5klSE/C559/jnbt2sHT09OgfPDgwcr/AwMDUbFiRbRp0wZnzpyBr69vkcsaN24cYmNjlddZWVnw8vIqncCJqFzwGfujSfXPTe1QSpEQ0ZNWZgmSi4sLzMzMkJ6eblCenp7+wAHYpjh//jw2btz40F4hveDgYADA6dOnH5ggabXaB457IiIiomdLmY1B0mg0CAoKQnJyslKm0+mQnJyMkJCQf738xMREuLm5oUOHR/9Fd/DgQQBAxYoV//V6iYiI6OlXppfYYmNjERUVhUaNGqFJkyZISEjArVu30L9/fwBAv379UKlSJcTHxwO4N+j66NGjyv8vXbqEgwcPwtbWFn5+fspydTodEhMTERUVBXNzw008c+YMli5divbt26NChQr4/fffMXr0aLRo0QJ169Z9QltORERE5VmZJki9evVCRkYGJkyYgLS0NNSvXx9JSUnKwO0LFy5Arf6nk+vy5cto0KCB8nrGjBmYMWMGwsLCsGXLFqV848aNuHDhAgYMGFBonRqNBhs3blSSMS8vL0RGRmL8+PGlt6FERET0VFGJiJR1EE+jrKwsODg4IDMzk89QInpGcZA20bOnuN/fZf5TI0RERETlDRMkIiIiIiNMkIiIiIiMMEEiIiIiMsIEiYiIiMgIEyQiIiIiI0yQiIiIiIwwQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCIiIiIjDBBIiIiIjLCBImIiIjICBMkIiIiIiNMkIiIiIiMMEEiIiIiMsIEiYiIiMgIEyQiIiIiI0yQiIiIiIwwQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCIiIiIjDBBIiIiIjLCBImIiIjICBMkIiIiIiNMkIiIiIiMMEEiIiIiMsIEiYiIiMgIEyQiIiIiI0yQiIiIiIwwQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCIiIiIjDBBIiIiIjJiXtYBED2tfMb+aFL9c1M7lFIkRERU0tiDRERERGSECRIRERGRkTJPkObNmwcfHx9YWloiODgYe/fufWDdP/74A5GRkfDx8YFKpUJCQkKhOpMmTYJKpTKYAgICDOrcuXMHw4cPR4UKFWBra4vIyEikp6eX9KYRERHRU6pME6Tly5cjNjYWEydOxP79+1GvXj1ERETgypUrRdbPyclBtWrVMHXqVHh4eDxwubVr10Zqaqoy/frrrwbzR48ejbVr12LlypXYunUrLl++jO7du5fothEREdHTq0wTpFmzZiEmJgb9+/dHrVq1sHDhQlhbW2PRokVF1m/cuDE++OAD9O7dG1qt9oHLNTc3h4eHhzK5uLgo8zIzM/H5559j1qxZaN26NYKCgpCYmIidO3di9+7dJb6NRERE9PQpswQpLy8PKSkpCA8P/ycYtRrh4eHYtWvXv1r2qVOn4OnpiWrVqqFv3764cOGCMi8lJQV37941WG9AQACqVKnyr9dLREREz4YyS5CuXr2KgoICuLu7G5S7u7sjLS3tsZcbHByMxYsXIykpCQsWLMDZs2cRGhqKmzdvAgDS0tKg0Wjg6Oho0npzc3ORlZVlMBEREdGz6Zl7DlK7du2U/9etWxfBwcHw9vbGihUrMHDgwMdebnx8POLi4koiRCIiIirnyqwHycXFBWZmZoXuHktPT3/oAGxTOTo6onr16jh9+jQAwMPDA3l5ebhx44ZJ6x03bhwyMzOV6eLFiyUWIxEREZUvZZYgaTQaBAUFITk5WSnT6XRITk5GSEhIia0nOzsbZ86cQcWKFQEAQUFBsLCwMFjviRMncOHChYeuV6vVwt7e3mAiIiKiZ1OZXmKLjY1FVFQUGjVqhCZNmiAhIQG3bt1C//79AQD9+vVDpUqVEB8fD+DewO6jR48q/7906RIOHjwIW1tb+Pn5AQDeeOMNdOrUCd7e3rh8+TImTpwIMzMz9OnTBwDg4OCAgQMHIjY2Fs7OzrC3t8err76KkJAQNG3atAz2AhEREZU3ZZog9erVCxkZGZgwYQLS0tJQv359JCUlKQO3L1y4ALX6n06uy5cvo0GDBsrrGTNmYMaMGQgLC8OWLVsAAH/99Rf69OmDv//+G66urnjuueewe/duuLq6Ku1mz54NtVqNyMhI5ObmIiIiAvPnz38yG01ERETlnkpEpKyDeBplZWXBwcEBmZmZvNz2H8Ufq3328RgTPXuK+/1d5j81QkRERFTeMEEiIiIiMsIEiYiIiMgIEyQiIiIiI0yQiIiIiIwwQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCIiIiIjDBBIiIiIjLCBImIiIjICBMkIiIiIiNMkIiIiIiMMEEiIiIiMsIEiYiIiMgIEyQiIiIiI0yQiIiIiIwwQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCIiIiIjDBBIiIiIjLCBImIiIjICBMkIiIiIiNMkIiIiIiMMEEiIiIiMsIEiYiIiMgIEyQiIiIiI0yQiIiIiIwwQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCIiIiIjDBBIiIiIjLCBImIiIjICBMkIiIiIiNMkIiIiIiMMEEiIiIiMsIEiYiIiMgIEyQiIiIiI2WeIM2bNw8+Pj6wtLREcHAw9u7d+8C6f/zxByIjI+Hj4wOVSoWEhIRCdeLj49G4cWPY2dnBzc0NXbt2xYkTJwzqtGzZEiqVymAaOnRoSW8aERERPaXKNEFavnw5YmNjMXHiROzfvx/16tVDREQErly5UmT9nJwcVKtWDVOnToWHh0eRdbZu3Yrhw4dj9+7d2LBhA+7evYsXXngBt27dMqgXExOD1NRUZZo+fXqJbx8RERE9nczLcuWzZs1CTEwM+vfvDwBYuHAhfvzxRyxatAhjx44tVL9x48Zo3LgxABQ5HwCSkpIMXi9evBhubm5ISUlBixYtlHJra+sHJllERET031ZmPUh5eXlISUlBeHj4P8Go1QgPD8euXbtKbD2ZmZkAAGdnZ4PyJUuWwMXFBXXq1MG4ceOQk5Pz0OXk5uYiKyvLYCIiIqJn02MlSF999RWaN28OT09PnD9/HgCQkJCANWvWFHsZV69eRUFBAdzd3Q3K3d3dkZaW9jhhFaLT6fDaa6+hefPmqFOnjlL+0ksv4euvv8bmzZsxbtw4fPXVV3j55Zcfuqz4+Hg4ODgok5eXV4nESEREROWPyQnSggULEBsbi/bt2+PGjRsoKCgAADg6OhY5aLosDR8+HEeOHMGyZcsMygcPHoyIiAgEBgaib9+++PLLL/H999/jzJkzD1zWuHHjkJmZqUwXL14s7fCJiIiojJicIM2ZMweffvop/ve//8HMzEwpb9SoEQ4fPlzs5bi4uMDMzAzp6ekG5enp6SUyNmjEiBFYt24dNm/ejMqVKz+0bnBwMADg9OnTD6yj1Wphb29vMBEREdGzyeQE6ezZs2jQoEGhcq1WW+hOsYfRaDQICgpCcnKyUqbT6ZCcnIyQkBBTw1KICEaMGIHvv/8emzZtQtWqVR/Z5uDBgwCAihUrPvZ6iYiI6Nlh8l1sVatWxcGDB+Ht7W1QnpSUhJo1a5q0rNjYWERFRaFRo0Zo0qQJEhIScOvWLeWutn79+qFSpUqIj48HcG9g99GjR5X/X7p0CQcPHoStrS38/PwA3LustnTpUqxZswZ2dnbKeCYHBwdYWVnhzJkzWLp0Kdq3b48KFSrg999/x+jRo9GiRQvUrVvX1N1BREREzyCTE6TY2FgMHz4cd+7cgYhg7969+OabbxAfH4/PPvvMpGX16tULGRkZmDBhAtLS0lC/fn0kJSUpA7cvXLgAtfqfTq7Lly8b9F7NmDEDM2bMQFhYGLZs2QLg3hgp4N7DIO+XmJiI6OhoaDQabNy4UUnGvLy8EBkZifHjx5u6K4iIiOgZpRIRMbXRkiVLMGnSJGVQs6enJ+Li4jBw4MASD7C8ysrKgoODAzIzMzke6T/KZ+yPJtU/N7VDKUVCpYXHmOjZU9zv78d6UGTfvn3Rt29f5OTkIDs7G25ubo8dKBEREVF5Y3KCdPbsWeTn58Pf3x/W1tawtrYGAJw6dQoWFhbw8fEp6RiJiIiIniiT72KLjo7Gzp07C5Xv2bMH0dHRJRETERERUZkyOUE6cOAAmjdvXqi8adOmyu3yRERERE8zkxMklUqFmzdvFirPzMxUnqpNRERE9DQzOUFq0aIF4uPjDZKhgoICxMfH47nnnivR4IiIiIjKgsmDtKdNm4YWLVqgRo0aCA0NBQBs374dWVlZ2LRpU4kHSERERPSkmdyDVKtWLfz+++/o2bMnrly5gps3b6Jfv344fvw46tSpUxoxEhERET1Rj/UcJE9PT7z//vslHQsRERFRufBYCdKNGzewd+9eXLlyBTqdzmBev379SiQwIiIiorJicoK0du1a9O3bF9nZ2bC3t4dKpVLmqVQqJkhERET01DN5DNLrr7+OAQMGIDs7Gzdu3MD169eV6dq1a6URIxEREdETZXKCdOnSJYwcOVL5iREiIiKiZ43JCVJERAT27dtXGrEQERERlQsmj0Hq0KEDxowZg6NHjyIwMBAWFhYG8zt37lxiwRERERGVBZMTpJiYGADAu+++W2ieSqXiz40QERHRU8/kBMn4tn4iIiKiZ43JY5CIiIiInnWP9aDIW7duYevWrbhw4QLy8vIM5o0cObJEAiMiIiIqKyYnSAcOHED79u2Rk5ODW7duwdnZGVevXoW1tTXc3NyYIBEREdFTz+RLbKNHj0anTp1w/fp1WFlZYffu3Th//jyCgoIwY8aM0oiRiIiI6IkyOUE6ePAgXn/9dajVapiZmSE3NxdeXl6YPn063n777dKIkYiIiOiJMjlBsrCwgFp9r5mbmxsuXLgAAHBwcMDFixdLNjoiIiKiMmDyGKQGDRrgt99+g7+/P8LCwjBhwgRcvXoVX331FerUqVMaMRIRERE9USb3IL3//vuoWLEiAGDKlClwcnLCsGHDkJGRgY8//rjEAyQiIiJ60kzuQWrUqJHyfzc3NyQlJZVoQERERERlzeQepNatW+PGjRuFyrOystC6deuSiImIiIioTJmcIG3ZsqXQwyEB4M6dO9i+fXuJBEVERERUlop9ie33339X/n/06FGkpaUprwsKCpCUlIRKlSqVbHREREREZaDYCVL9+vWhUqmgUqmKvJRmZWWFOXPmlGhwRERERGWh2AnS2bNnISKoVq0a9u7dC1dXV2WeRqOBm5sbzMzMSiVIIiIioiep2AmSt7c37t69i6ioKFSoUAHe3t6lGRcRERFRmTFpkLaFhQW+//770oqFiIiIqFww+S62Ll26YPXq1aUQChEREVH5YPKDIv39/fHuu+9ix44dCAoKgo2NjcH8kSNHllhwRERERGXB5ATp888/h6OjI1JSUpCSkmIwT6VSMUEiIiKip57JCdLZs2dLIw4iIiKicsPkMUj3ExGISEnFQkRERFQuPFaC9OWXXyIwMBBWVlawsrJC3bp18dVXX5V0bERERERlwuQEadasWRg2bBjat2+PFStWYMWKFWjbti2GDh2K2bNnmxzAvHnz4OPjA0tLSwQHB2Pv3r0PrPvHH38gMjISPj4+UKlUSEhIeKxl3rlzB8OHD0eFChVga2uLyMhIpKenmxw7ERERPZtMTpDmzJmDBQsWYNq0aejcuTM6d+6M6dOnY/78+fjoo49MWtby5csRGxuLiRMnYv/+/ahXrx4iIiJw5cqVIuvn5OSgWrVqmDp1Kjw8PB57maNHj8batWuxcuVKbN26FZcvX0b37t1Nip2IiIieXSYnSKmpqWjWrFmh8mbNmiE1NdWkZc2aNQsxMTHo378/atWqhYULF8La2hqLFi0qsn7jxo3xwQcfoHfv3tBqtY+1zMzMTHz++eeYNWsWWrdujaCgICQmJmLnzp3YvXu3SfETERHRs8nkBMnPzw8rVqwoVL58+XL4+/sXezl5eXlISUlBeHj4P8Go1QgPD8euXbtMDavYy0xJScHdu3cN6gQEBKBKlSoPXW9ubi6ysrIMJiIiIno2mXybf1xcHHr16oVt27ahefPmAIAdO3YgOTm5yMTpQa5evYqCggK4u7sblLu7u+P48eOmhlXsZaalpUGj0cDR0bFQnbS0tAcuOz4+HnFxcY8VFxERET1dTO5BioyMxJ49e+Di4oLVq1dj9erVcHFxwd69e9GtW7fSiLFcGDduHDIzM5Xp4sWLZR0SERERlRKTe5AAICgoCF9//fW/WrGLiwvMzMwK3T2Wnp7+wAHYJbFMDw8P5OXl4caNGwa9SI9ar1arfeC4JyIiInq2PNZzkAoKCvDtt99i8uTJmDx5Mr777jvk5+ebtAyNRoOgoCAkJycrZTqdDsnJyQgJCXmcsIq1zKCgIFhYWBjUOXHiBC5cuPDY6yUiIqJni8k9SH/88Qc6d+6MtLQ01KhRAwAwbdo0uLq6Yu3atahTp06xlxUbG4uoqCg0atQITZo0QUJCAm7duoX+/fsDAPr164dKlSohPj4ewL1B2EePHlX+f+nSJRw8eBC2trbw8/Mr1jIdHBwwcOBAxMbGwtnZGfb29nj11VcREhKCpk2bmro7iIiI6BlkcoI0aNAg1K5dG/v27YOTkxMA4Pr164iOjsbgwYOxc+fOYi+rV69eyMjIwIQJE5CWlob69esjKSlJGWR94cIFqNX/dHJdvnwZDRo0UF7PmDEDM2bMQFhYGLZs2VKsZQLA7NmzoVarERkZidzcXERERGD+/Pmm7goiIiJ6RqnExB9Ts7Kywr59+1C7dm2D8iNHjqBx48a4fft2iQZYXmVlZcHBwQGZmZmwt7cv63CoDPiM/dGk+uemdiilSKi08BgTPXuK+/1t8hik6tWrF/mzHFeuXFEucxERERE9zUxOkOLj4zFy5Eh8++23+Ouvv/DXX3/h22+/xWuvvYZp06bxQYpERET01DN5DFLHjh0BAD179oRKpQIA6K/SderUSXmtUqlQUFBQUnESERERPTEmJ0ibN28ujTiIiIiIyg2TE6SwsLDSiIOIiIio3HisJ2nfuXMHv//+O65cuQKdTmcwr3PnziUSGBEREVFZMTlBSkpKQr9+/XD16tVC8zjuiIiIiJ4FJt/F9uqrr6JHjx5ITU2FTqczmJgcERER0bPA5AQpPT0dsbGxBk+mJiIiInqWmJwgvfjii8rPehARERE9i0wegzR37lz06NED27dvR2BgICwsLAzmjxw5ssSCIyIiIioLJidI33zzDX755RdYWlpiy5YtysMigXuDtJkgERER0dPO5ATpf//7H+Li4jB27Fio1SZfoSMiIiIq90zOcPLy8tCrVy8mR0RERPTMMjnLiYqKwvLly0sjFiIiIqJyweRLbAUFBZg+fTrWr1+PunXrFhqkPWvWrBILjoiIiKgsmJwgHT58GA0aNAAAHDlyxGDe/QO2iYiIiJ5WJidImzdvLo04iIiIiMoNjrQmIiIiMlLsHqTu3bsXq96qVaseOxgiIiKi8qDYCZKDg0NpxkFERERUbhQ7QUpMTCzNOIiIiIjKDY5BIiIiIjLCBImIiIjICBMkIiIiIiNMkIiIiIiMMEEiIiIiMvJYCdJXX32F5s2bw9PTE+fPnwcAJCQkYM2aNSUaHBEREVFZMPmnRhYsWIAJEybgtddew5QpU1BQUAAAcHR0REJCArp06VLiQdKT4zP2R5Pqn5vaoZQiISIiKjsm9yDNmTMHn376Kf73v//BzMxMKW/UqBEOHz5cosERERERlQWTE6SzZ8+iQYMGhcq1Wi1u3bpVIkERERERlSWTE6SqVavi4MGDhcqTkpJQs2bNkoiJiIiIqEyZPAYpNjYWw4cPx507dyAi2Lt3L7755hvEx8fjs88+K40YiYiIiJ4okxOkQYMGwcrKCuPHj0dOTg5eeukleHp64sMPP0Tv3r1LI0YiIiKiJ8qkBCk/Px9Lly5FREQE+vbti5ycHGRnZ8PNza204iMiIiJ64kwag2Rubo6hQ4fizp07AABra2smR0RERPTMMXmQdpMmTXDgwIHSiIWIiIioXDB5DNIrr7yC119/HX/99ReCgoJgY2NjML9u3bolFhwRERFRWTA5QdIPxB45cqRSplKpICJQqVTKk7WJiIiInlaP9aBI4+nPP/9U/n0c8+bNg4+PDywtLREcHIy9e/c+tP7KlSsREBAAS0tLBAYG4qeffjKYr1Kpipw++OADpY6Pj0+h+VOnTn2s+ImIiOjZYnIPkre3d4kGsHz5csTGxmLhwoUIDg5GQkICIiIicOLEiSIHgO/cuRN9+vRBfHw8OnbsiKVLl6Jr167Yv38/6tSpAwBITU01aPPzzz9j4MCBiIyMNCh/9913ERMTo7y2s7Mr0W0jIiKip5PJCdKXX3750Pn9+vUzaXmzZs1CTEwM+vfvDwBYuHAhfvzxRyxatAhjx44tVP/DDz9E27ZtMWbMGADA5MmTsWHDBsydOxcLFy4EAHh4eBi0WbNmDVq1aoVq1aoZlNvZ2RWqS0RERGRygjRq1CiD13fv3kVOTg40Gg2sra1NSpDy8vKQkpKCcePGKWVqtRrh4eHYtWtXkW127dqF2NhYg7KIiAisXr26yPrp6en48ccf8cUXXxSaN3XqVEyePBlVqlTBSy+9hNGjR8Pc3ORdQkRERM8Yk7OB69evFyo7deoUhg0bpvTqFNfVq1dRUFAAd3d3g3J3d3ccP368yDZpaWlF1k9LSyuy/hdffAE7Ozt0797doHzkyJFo2LAhnJ2dsXPnTowbNw6pqamYNWtWkcvJzc1Fbm6u8jorK+uR20dERERPpxLpLvH398fUqVPx8ssvPzCxKSuLFi1C3759YWlpaVB+fy9U3bp1odFoMGTIEMTHx0Or1RZaTnx8POLi4ko9XiIiIip7Jt/F9iDm5ua4fPmySW1cXFxgZmaG9PR0g/L09PQHjg3y8PAodv3t27fjxIkTGDRo0CNjCQ4ORn5+Ps6dO1fk/HHjxiEzM1OZLl68+MhlEhER0dPJ5B6kH374weC1iCA1NRVz585F8+bNTVqWRqNBUFAQkpOT0bVrVwCATqdDcnIyRowYUWSbkJAQJCcn47XXXlPKNmzYgJCQkEJ1P//8cwQFBaFevXqPjOXgwYNQq9UP/OkUrVZbZM8SERERPXtMTpD0iYyeSqWCq6srWrdujZkzZ5ocQGxsLKKiotCoUSM0adIECQkJuHXrlnJXW79+/VCpUiXEx8cDuDdIPCwsDDNnzkSHDh2wbNky7Nu3D5988onBcrOysrBy5coiY9q1axf27NmDVq1awc7ODrt27cLo0aPx8ssvw8nJyeRtICIiomeLyQmSTqcr0QB69eqFjIwMTJgwAWlpaahfvz6SkpKUgdgXLlyAWv3PlcBmzZph6dKlGD9+PN5++234+/tj9erVyjOQ9JYtWwYRQZ8+fQqtU6vVYtmyZZg0aRJyc3NRtWpVjB49utDdcURERPTfpBIRMaXBu+++izfeeAPW1tYG5bdv38YHH3yACRMmlGiA5VVWVhYcHByQmZkJe3v7sg6nxPiM/dGk+uemdiilSMo/7qtnH48x0bOnuN/fJg/SjouLQ3Z2dqHynJwc3uVFREREzwSTEyT9j9IaO3ToEJydnUskKCIiIqKyVOwxSE5OTsqPulavXt0gSSooKEB2djaGDh1aKkESERERPUnFTpASEhIgIhgwYADi4uLg4OCgzNNoNPDx8SnyVnsiIiKip02xE6SoqCgAQNWqVdGsWTNYWFiUWlBEREREZcnk2/zDwsKU/9+5cwd5eXkG85+lO7qIiIjov8nkQdo5OTkYMWIE3NzcYGNjAycnJ4OJiIiI6GlncoI0ZswYbNq0CQsWLIBWq8Vnn32GuLg4eHp64ssvvyyNGImIiIieKJMvsa1duxZffvklWrZsif79+yM0NBR+fn7w9vbGkiVL0Ldv39KIk4iIiOiJMbkH6dq1a6hWrRqAe+ONrl27BgB47rnnsG3btpKNjoiIiKgMmJwgVatWDWfPngUABAQEYMWKFQDu9Sw5OjqWaHBEREREZcHkBKl///44dOgQAGDs2LGYN28eLC0tMXr0aIwZM6bEAyQiIiJ60kwegzR69Gjl/+Hh4Th+/DhSUlLg5+eHunXrlmhwRERERGXB5ATpfnfu3IG3tze8vb1LKh4iIiKiMmfyJbaCggJMnjwZlSpVgq2tLf78808AwDvvvIPPP/+8xAMkIiIietJMTpCmTJmCxYsXY/r06dBoNEp5nTp18Nlnn5VocERERERlweQE6csvv8Qnn3yCvn37wszMTCmvV68ejh8/XqLBEREREZUFkxOkS5cuwc/Pr1C5TqfD3bt3SyQoIiIiorJkcoJUq1YtbN++vVD5t99+iwYNGpRIUERERERlyeS72CZMmICoqChcunQJOp0Oq1atwokTJ/Dll19i3bp1pREjERER0RNlcg9Sly5dsHbtWmzcuBE2NjaYMGECjh07hrVr1+L5558vjRiJiIiInqhi9yD9+eefqFq1KlQqFUJDQ7Fhw4bSjIuIiIiozBS7B8nf3x8ZGRnK6169eiE9Pb1UgiIiIiIqS8VOkETE4PVPP/2EW7dulXhARERERGXN5DFIRERERM+6YidIKpUKKpWqUBkRERHRs6bYg7RFBNHR0dBqtQDu/VDt0KFDYWNjY1Bv1apVJRshERER0RNW7AQpKirK4PXLL79c4sEQERERlQfFTpASExNLMw4iIiKicsPkJ2kTUdnzGfujSfXPTe1QSpEQET2bmCAREZUCU5NYgIksUXnC2/yJiIiIjDBBIiIiIjLCS2xE/zEcv0RE9GjsQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCIiIiIjDBBIiIiIjLCBImIiIjISLlIkObNmwcfHx9YWloiODgYe/fufWj9lStXIiAgAJaWlggMDMRPP/1kMD86Ohoqlcpgatu2rUGda9euoW/fvrC3t4ejoyMGDhyI7OzsEt82IiIievqUeYK0fPlyxMbGYuLEidi/fz/q1auHiIgIXLlypcj6O3fuRJ8+fTBw4EAcOHAAXbt2RdeuXXHkyBGDem3btkVqaqoyffPNNwbz+/btiz/++AMbNmzAunXrsG3bNgwePLjUtpOIiIieHmX+oMhZs2YhJiYG/fv3BwAsXLgQP/74IxYtWoSxY8cWqv/hhx+ibdu2GDNmDABg8uTJ2LBhA+bOnYuFCxcq9bRaLTw8PIpc57Fjx5CUlITffvsNjRo1AgDMmTMH7du3x4wZM+Dp6VnSm/mfwAcQEhHRs6JMe5Dy8vKQkpKC8PBwpUytViM8PBy7du0qss2uXbsM6gNAREREofpbtmyBm5sbatSogWHDhuHvv/82WIajo6OSHAFAeHg41Go19uzZU+R6c3NzkZWVZTARERHRs6lME6SrV6+ioKAA7u7uBuXu7u5IS0srsk1aWtoj67dt2xZffvklkpOTMW3aNGzduhXt2rVDQUGBsgw3NzeDZZibm8PZ2fmB642Pj4eDg4MyeXl5mby9RERE9HQo80tspaF3797K/wMDA1G3bl34+vpiy5YtaNOmzWMtc9y4cYiNjVVeZ2VlMUkiIiJ6RpVpD5KLiwvMzMyQnp5uUJ6env7A8UMeHh4m1QeAatWqwcXFBadPn1aWYTwIPD8/H9euXXvgcrRaLezt7Q0mIiIiejaVaYKk0WgQFBSE5ORkpUyn0yE5ORkhISFFtgkJCTGoDwAbNmx4YH0A+Ouvv/D333+jYsWKyjJu3LiBlJQUpc6mTZug0+kQHBz8bzaJiIiIngFlfpt/bGwsPv30U3zxxRc4duwYhg0bhlu3bil3tfXr1w/jxo1T6o8aNQpJSUmYOXMmjh8/jkmTJmHfvn0YMWIEACA7OxtjxozB7t27ce7cOSQnJ6NLly7w8/NDREQEAKBmzZpo27YtYmJisHfvXuzYsQMjRoxA7969eQcbERERlf0YpF69eiEjIwMTJkxAWloa6tevj6SkJGUg9oULF6BW/5PHNWvWDEuXLsX48ePx9ttvw9/fH6tXr0adOnUAAGZmZvj999/xxRdf4MaNG/D09MQLL7yAyZMnQ6vVKstZsmQJRowYgTZt2kCtViMyMhIfffTRk914IiIiKpfKPEECgBEjRig9QMa2bNlSqKxHjx7o0aNHkfWtrKywfv36R67T2dkZS5cuNSlOIiIi+m8o80tsREREROUNEyQiIiIiI0yQiIiIiIwwQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCIiIiIjDBBIiIiIjJSLh4USURE5YPP2B9Nqn9uaodSioSobLEHiYiIiMgIEyQiIiIiI0yQiIiIiIwwQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCIiIiIjDBBIiIiIjLCBImIiIjICJ+kXQ7xSbZERERliz1IREREREaYIBEREREZYYJEREREZIQJEhEREZERDtKmpx4HtROVD3wv0rOEPUhERERERpggERERERlhgkRERERkhAkSERERkREmSERERERGmCARERERGWGCRERERGSEz0Gi/zQ+t4WIiIrCHiQiIiIiI0yQiIiIiIwwQSIiIiIywgSJiIiIyAgHaVO5wMHSRERUnrAHiYiIiMgIEyQiIiIiI+UiQZo3bx58fHxgaWmJ4OBg7N2796H1V65ciYCAAFhaWiIwMBA//fSTMu/u3bt46623EBgYCBsbG3h6eqJfv364fPmywTJ8fHygUqkMpqlTp5bK9hEREdHTpcwTpOXLlyM2NhYTJ07E/v37Ua9ePURERODKlStF1t+5cyf69OmDgQMH4sCBA+jatSu6du2KI0eOAABycnKwf/9+vPPOO9i/fz9WrVqFEydOoHPnzoWW9e677yI1NVWZXn311VLdViIiIno6lHmCNGvWLMTExKB///6oVasWFi5cCGtrayxatKjI+h9++CHatm2LMWPGoGbNmpg8eTIaNmyIuXPnAgAcHBywYcMG9OzZEzVq1EDTpk0xd+5cpKSk4MKFCwbLsrOzg4eHhzLZ2NiU+vYSERFR+VemCVJeXh5SUlIQHh6ulKnVaoSHh2PXrl1Fttm1a5dBfQCIiIh4YH0AyMzMhEqlgqOjo0H51KlTUaFCBTRo0AAffPAB8vPzH7iM3NxcZGVlGUxERET0bCrT2/yvXr2KgoICuLu7G5S7u7vj+PHjRbZJS0srsn5aWlqR9e/cuYO33noLffr0gb29vVI+cuRINGzYEM7Ozti5cyfGjRuH1NRUzJo1q8jlxMfHIy4uzpTNIyIioqfUM/0cpLt376Jnz54QESxYsMBgXmxsrPL/unXrQqPRYMiQIYiPj4dWqy20rHHjxhm0ycrKgpeXV+kFT0RERGWmTBMkFxcXmJmZIT093aA8PT0dHh4eRbbx8PAoVn19cnT+/Hls2rTJoPeoKMHBwcjPz8e5c+dQo0aNQvO1Wm2RiRMRERE9e8p0DJJGo0FQUBCSk5OVMp1Oh+TkZISEhBTZJiQkxKA+AGzYsMGgvj45OnXqFDZu3IgKFSo8MpaDBw9CrVbDzc3tMbeGiIiInhVlfoktNjYWUVFRaNSoEZo0aYKEhATcunUL/fv3BwD069cPlSpVQnx8PABg1KhRCAsLw8yZM9GhQwcsW7YM+/btwyeffALgXnL04osvYv/+/Vi3bh0KCgqU8UnOzs7QaDTYtWsX9uzZg1atWsHOzg67du3C6NGj8fLLL8PJyalsdgQRERGVG2WeIPXq1QsZGRmYMGEC0tLSUL9+fSQlJSkDsS9cuAC1+p+OrmbNmmHp0qUYP3483n77bfj7+2P16tWoU6cOAODSpUv44YcfAAD169c3WNfmzZvRsmVLaLVaLFu2DJMmTUJubi6qVq2K0aNHG4wxIiIiov+uMk+QAGDEiBEYMWJEkfO2bNlSqKxHjx7o0aNHkfV9fHwgIg9dX8OGDbF7926T4yQiIqL/hjJ/UCQRERFReVMuepCIiEqLz9gfTap/bmqHUoqEiJ4m7EEiIiIiMsIEiYiIiMgIEyQiIiIiIxyDREREZY5jxai8YQ8SERERkREmSERERERGmCARERERGeEYJKIywPEWRETlG3uQiIiIiIywB4mIiIiK5b/U+80EiYieiP/SBysRPf14iY2IiIjICBMkIiIiIiO8xEZERPQYTL1sDPDS8dOEPUhERERERtiDRET0jOGAeKJ/jz1IREREREbYg0RERESl7mnr2WQPEhEREZERJkhERERERpggERERERlhgkRERERkhAkSERERkREmSERERERGmCARERERGeFzkIiIyqGn7ZkxRM8a9iARERERGWGCRERERGSEl9iIiOipxsuRVBrYg0RERERkhAkSERERkREmSERERERGOAaJiIj+szh+iR6EPUhERERERtiDREREVAbYe1W+sQeJiIiIyAh7kIiIiJ4y7H0qfeWiB2nevHnw8fGBpaUlgoODsXfv3ofWX7lyJQICAmBpaYnAwED89NNPBvNFBBMmTEDFihVhZWWF8PBwnDp1yqDOtWvX0LdvX9jb28PR0REDBw5EdnZ2iW8bERERPX3KPEFavnw5YmNjMXHiROzfvx/16tVDREQErly5UmT9nTt3ok+fPhg4cCAOHDiArl27omvXrjhy5IhSZ/r06fjoo4+wcOFC7NmzBzY2NoiIiMCdO3eUOn379sUff/yBDRs2YN26ddi2bRsGDx5c6ttLRERE5V+ZJ0izZs1CTEwM+vfvj1q1amHhwoWwtrbGokWLiqz/4Ycfom3bthgzZgxq1qyJyZMno2HDhpg7dy6Ae71HCQkJGD9+PLp06YK6deviyy+/xOXLl7F69WoAwLFjx5CUlITPPvsMwcHBeO655zBnzhwsW7YMly9fflKbTkREROVUmY5BysvLQ0pKCsaNG6eUqdVqhIeHY9euXUW22bVrF2JjYw3KIiIilOTn7NmzSEtLQ3h4uDLfwcEBwcHB2LVrF3r37o1du3bB0dERjRo1UuqEh4dDrVZjz5496NatWwlu5ZNl6nVpgNemiYiIjJVpgnT16lUUFBTA3d3doNzd3R3Hjx8vsk1aWlqR9dPS0pT5+rKH1XFzczOYb25uDmdnZ6WOsdzcXOTm5iqvMzMzAQBZWVkP3cbHocvNMan+/TGY2vbftmfbJ9+2LNddZ+J6k9oeiYsokfX+G0/LMS7LdbPtk2lblut+2t9PJUm/XBF5eEUpQ5cuXRIAsnPnToPyMWPGSJMmTYpsY2FhIUuXLjUomzdvnri5uYmIyI4dOwSAXL582aBOjx49pGfPniIiMmXKFKlevXqhZbu6usr8+fOLXO/EiRMFACdOnDhx4sTpGZguXrz40BylTHuQXFxcYGZmhvT0dIPy9PR0eHh4FNnGw8PjofX1/6anp6NixYoGderXr6/UMR4Enp+fj2vXrj1wvePGjTO4tKfT6XDt2jVUqFABKpWqGFv772RlZcHLywsXL16Evb39E23PtuW/bVmum22fTNuyXDfbmuZpjPtpbPu4RAQ3b96Ep6fnQ+uVaYKk0WgQFBSE5ORkdO3aFcC9xCM5ORkjRowosk1ISAiSk5Px2muvKWUbNmxASEgIAKBq1arw8PBAcnKykhBlZWVhz549GDZsmLKMGzduICUlBUFBQQCATZs2QafTITg4uMj1arVaaLVagzJHR8fH3PLHZ29v/69Oon/Tnm3Lf9uyXDfbPpm2Zblutn061v1fa/s4HBwcHlmnzB8UGRsbi6ioKDRq1AhNmjRBQkICbt26hf79+wMA+vXrh0qVKiE+Ph4AMGrUKISFhWHmzJno0KEDli1bhn379uGTTz4BAKhUKrz22mt477334O/vj6pVq+Kdd96Bp6enkoTVrFkTbdu2RUxMDBYuXIi7d+9ixIgR6N279yMzSiIiInr2lXmC1KtXL2RkZGDChAlIS0tD/fr1kZSUpAyyvnDhAtTqf55G0KxZMyxduhTjx4/H22+/DX9/f6xevRp16tRR6rz55pu4desWBg8ejBs3buC5555DUlISLC0tlTpLlizBiBEj0KZNG6jVakRGRuKjjz56chtORERE5ddDRyhRuXHnzh2ZOHGi3Llz54m3Z9vy37Ys1822T6ZtWa6bbZ+Odf/X2pY2lcij7nMjIiIi+m8p8ydpExEREZU3TJCIiIiIjDBBIiIiIjLCBOkJUalUyu/FlYYtW7ZApVLhxo0bAICWLVsaPCtK/9rHxwcJCQmlFkdRMS1ZsqTQvPvjM471YRYvXgxHR0elzaRJk5TnXT3MoEGDnsgDPUtLdHS08piKhzFlX+oZnzumxGB8PqWlpeH555+HjY0NNBrNI2M29XzUH/+HKe72mMrUWM+dOweVSoWDBw/+q/WW1vYAjz6virO/iZ5VTJDKqUd9MBl/ETZr1gypqak4cOAAVCoVLl++jAULFijzV61ahcmTJ5dixIU1a9YMAGBtbV1o3oPiKeoD+2FfNG+88QaSk5MfGUuTJk1gZ2dX5LwHfQGZmmyUdPL5JJPZ4vjwww+xePFi5XXLli3xwgsvYPDgwUrZ7NmzkZqaioMHD6J79+64evXqQ7/ce/TogUWLFhU7hl69euHkyZMPraN/L+gfBPc4SWNRfvvtN4NtLQn69/nDEn3j7Slrv//+O0JDQ2FpaQkvLy9Mnz69WO3u3LmD6OhoBAYGwtzcvFgJ//22bNmCLl26oGLFirCxsUH9+vWL/OOrKCdOnECrVq3g7u4OS0tLVKtWDePHj8fdu3dNiuH06dOws7MrdtKo/+wynnbv3l2s9iKCGTNmoHr16tBqtahUqRKmTJnyyHaTJk0qcr02NjbFWu/69evRtGlT2NnZwdXVFZGRkTh37lyx2gLAihUrUL9+fVhbW8Pb2xsffPBBoTrFPR+2bNmChg0bQqvVws/Pz+AzqLSV+XOQqGRoNBp4eHg88Ed+nZ2dn3BE92ICUGTPTUnFY2trC1tb22LFolarcffuXVhYWJi0jry8PGVbniUFBQXF6lXT1yvqC9ra2togAT5z5gyCgoLg7+9v8NyxB7GxsTF4ztmD6I+blZUVrKysHlpX/14oaa6urg+dX1rnSWltz+PIysrCCy+8gPDwcCxcuBCHDx/GgAED4Ojo+MjksaCgAFZWVhg5ciS+++47k9e9c+dO1K1bF2+99Rbc3d2xbt069OvXDw4ODujYseND21pYWKBfv35o2LAhHB0dcejQIcTExECn0+H9998v1vrv3r2LPn36IDQ0FDt37jQp9o0bN6J27drK6woVKhSr3ahRo/DLL79gxowZCAwMxLVr13Dt2rVHtnvjjTcwdOhQg7I2bdqgcePGj2x79uxZdOnSBbGxsViyZAkyMzMxevRodO/eHfv3739k+59//hl9+/bFnDlz8MILL+DYsWOIiYmBlZWVwS9kFOd8OHv2LDp06IChQ4diyZIlSE5OxqBBg1CxYkVEREQU2aZElfFjBp4qK1eulDp16oilpaU4OztLmzZtJDs7W/bu3Svh4eFSoUIFsbe3lxYtWkhKSopBWwDy/fffi4jI5s2bBYBcv35dmX/gwAEBIGfPnlXm3z9NnDhRRES+/PJLqVChQqH5zZo1e+iP8llYWIhWqxWVSiX+/v7SpUsX0Wq1BnW0Wq1YWloKAKlZs6bY29tLbGysMt/W1laioqLEyspK1Gq1dO7cWerXry8WFhaiUqkM1lW9enWxtrYWADJgwACpVq2a+Pj4CABRq9UG6zUzMxNbW9si4/b29i5UplKpJCQkRNRqtTRr1kwsLCwK1XFwcJBZs2YZrAOAaDQaqVSpktSqVUssLCyKbGtjYyN169YtVB4eHi6+vr7ywQcfSGJiopibm4tKpRJXV9ciY/fy8jJ4bW9vL19++aV8/PHHSpm5uXmR2/egY2g8T61WS6tWreTatWty584dcXNzK9SuU6dOotPpJDExUWxsbKRy5coG8/XHRX8+JiYmiq2trdSsWdMgTktLS6lTp46EhYUZzDNlUqvV4urqKoGBgUVuu/H5oVarxcLCQsaMGSO2trbK8XJ3dxdfX1/luA4dOlS8vb3F3t5eWrVqJQDkm2++KfL4mpubS+vWraVbt26i1WpFrVaLr6+vBAUFKcuzs7OTgIAA6dChg/Ie9fb2lo4dO4qvr69oNBqxsLAQW1tbMTMzEzMzM6levbrB8dO/v3r06KG8r/TzNRrNQ/fT6NGjZcKECeLu7i52dnZKO3Nzc4mPj1diKigokIoVK4qTk5NYWFiIvb29ODg4iEajkYoVK0p0dLT06NFDHBwcxNHRUXx9fcXd3V2sra2lSZMmEhERIcHBweLg4CD5+fmSmJgo7u7uAkD8/f1lxowZ4uDgIAMHDpS+ffvK/PnzxcnJSXJzc0VEZO3ataLVapUf/9Z/jr311ltKjPq294uKipIuXbrI2rVrlXWb0l6/bnNzc4mKinqstlqtVpo3b17stm+++aa8/PLLMmrUKAFQrJjPnj0rAOTAgQPKeou7vUePHhVzc3M5fvy4yW2NffTRRwJANm/e/Mi2K1euFHNzcykoKFDmvfPOOwJAbt++/dD2YWFhYmFhIZGRkQb1wsPDpXLlyqLT6R56Phh78803pXbt2gZlvXr1koiIiEJ1SwMvsRVTamoq+vTpgwEDBuDYsWPYsmULunfvrvzoXVRUFH799Vfs3r0b/v7+aN++PW7evPlY62rWrBkSEhJgb2+P1NRUpKam4o033gBw76+YhQsXokGDBujSpQuCgoJQqVIlnD59GgAMul/VajXWr1+POnXq4O7du2jSpAk8PDxw6dIlrFu3Dh4eHqhTpw6cnJyUNpGRkVCr1Thz5gxu3ryJxYsXKz002dnZ+OWXX9ChQwc0bdoUSUlJsLGxgYuLC15++WX4+voqPQK3b9+Gn58fgHuXEczNzXH9+nUAgIhApVIpPyZcUFCA27dvAzDsbWrUqBEyMzOV17GxscpPwezfvx8ajQb79+9Hfn4+HB0dlZ4hS0tLmJubG/y4sH65X331Fa5cuYKTJ09Cp9Ohb9++qFSpkrL81NRUODs749ixY9BqtWjdujUSExOhVquxceNGdOjQAYmJicjOzkZ+fj7MzMzg5+cHlUoFtVpt8Jd+amqqQc9LVlYWoqOjDS59mpmZAfint83Lywu+vr7KfBcXF0yYMAFmZmbIz89Xfg9Qf0x0Oh3S09NRUFCAESNGKD/CHBISgsjISADA2rVr8eGHH+LKlSu4desW/vrrLzg5OeGVV15BxYoV8ddffwG41/sDAFeuXEF2djZu376N1q1bw8XFBVWqVIGLiwv+/vtv7N+/H2FhYQgJCVH2+csvv4xVq1ahatWqAIDOnTujadOmynZUq1YN77//PnQ6HTIyMnD8+HEMHjxY2R6VSoXWrVvDmLOzM+7evYvjx4/Dzs7OYLt79OiBWrVqQaVS4bPPPsPXX3+NdevWKZdiQ0JCUFBQgEqVKkGtVsPX1xf29vYICAjAgQMHsGXLFri5uWHKlCmoV68eUlJS0K9fP/z8889o06YNTp48id9//12J5fr160hOTsY777yDw4cPQ61WIycnBy+//DI++eQTZf+1adMGiYmJynFfuXIlhgwZAmtra2g0GogIBg8ejPDwcDRs2FA5zmq1GjExMYiKisKXX36Jw4cPIz09HVWqVAEAzJo1CwUFBQaXlMeNG4crV66gRYsWyvyoqCicOnUK3377LZKSkmBnZ4ft27cjPDwcmZmZ0Gg02LdvH3r06IENGzbA0tISN2/exFdffYWBAweiSZMmcHJyQl5eHt577z0AwNatW9GyZUvs2rULLVq0UM7X0NBQ3L17FydPnsT169exdetWuLi4YMuWLUqM+rZFCQ0Nxc2bN3HgwAGlbnHbh4aGIj8/H/n5+Sa3rVSpEnJzc1G9evVitd20aRNWrlyJefPmKW1Miblz585wc3PDe++9V+ztXbt2LapVq4Z169ahatWqeOWVV5CVlaXUNWV7Dx8+DOCfz42HtQ0KCoJarUZiYiIKCgqQmZmptD9y5MhD23fv3h13795FTk6OQb0zZ87gr7/+wvnz5x96PhjbtWsXwsPDDcoiIiKwa9euYrX/155IGvYMSElJEQBy7ty5R9YtKCgQOzs7Wbt2rVIGFL8HSeTeX/EODg4PXEdYWJiMGjVKtm7dKgBk3LhxAkDWrl1r8FfqyZMnBYBYW1tLUFCQuLu7K3+9Dho0SOzt7eWTTz5R/rJesWKFODg4iI2NjQCQN998U3r16iU2NjZKL4Kfn5988skn8tZbb4mTk5O0bt1adDqd/PbbbwJAQkJClP/j//8lHRkZqbx+7733lN6cGjVqCACDXo2AgABRqVTyxhtvGPxV/fnnn8vQoUOVngWtViuurq7i7OwsAGT16tUSEhIiVlZW4u7ubtATUadOHQEgAwcOlP79+wsAadWqlYj889dVamqqiIhUqlRJVCqVNG3aVEaNGiUiIh07dhSVSiURERFiZmYmHTp0EADSv39/MTc3l7CwMPH09FTWZ2lpKWZmZtKlSxclDicnJ/Hz8zPYJg8PDwEgzZs3FwAyadIk0Wq1So/asGHDZPLkyeLp6SmOjo4CQIKCguTixYsCQBwdHcXe3l7Onz+v9H44OjqKTqcTEZHWrVuLhYWFuLm5SWhoqLLeS5cuiYjI9u3blR6P0aNHi4go9Xbs2CEWFhaycuVK2b59uwCQiIgIsba2llGjRhksT/++CAgIEGtra+nTp49EREQYbOuJEyfEwcFBOUdERDnXVCqVdOnSRQBI165dlTZJSUlKL12vXr2U8qlTp0peXp5YWVmJhYWFVKpUSaZNmyYiotS7fv26NGzYUOnhe/7552XKlCmi0WikVq1aSq/OyZMnxdLSUoKDg5X3V35+vtIbd/v2bcnKyhIA0qtXLxER+fnnn5XzSkTkk08+Ud5X+vf5vHnzlHj37NkjAJTz/dixYyIi8vnnnwsAqVu3rlSsWFGCgoIkNTVVAEiTJk1EpVLJmjVrlO2xt7eXKlWqiIhIVlaWaLVaqVy5skycOFFmzpwp1atXl7y8PBER+eqrr6RGjRqi0+mU8+Ps2bNiZWUl69evFxGRihUrir+/vzRs2FDq168v7du3l65duyr7qXv37koP1smTJ+X555+XwYMHG3wW1apVSwDI0aNHDdrevHlT/vrrL6Xt/e7vMWjYsKF88MEHIiLFbi8isnz5clGpVPL6668Xu21ISIjSs+fi4iLTp09/ZNurV6+Kl5eXbN26VUTufTar1epixZyRkSEzZ86U3bt3y969e+Wtt94SABIdHf3ItkOGDBGtVivBwcGybds22bx5s1hZWYmvr69J++r27dvi5OQklSpVKvZ+3rJli7i5uSmfKSEhIVKvXr1ita9SpYpYWFjIxo0bpUuXLjJ69GjlM0Z/Lj/sfLifv7+/vP/++wZlP/74owCQnJycQvVLGhOkYsrPz5c2bdqInZ2dvPjii/LJJ5/ItWvXREQkLS1NBg0aJH5+fmJvb6984M+bN09pX1IJ0r59+6Rjx46i1WrFwsJC+ZCfMWOGQYJkY2MjGo1G1qxZI+bm5lKhQgWpVauWODs7Kyer/uS/f9JoNKJSqZQv9W7dusmCBQukUqVKStKkP8FnzJghKpVKWZ7+X3Nzc+XyGgCpUKGCTJ8+XZycnJTkQT9P38bX11cp06/b+BJMZGSkvPnmm4ViLs7UunVrASCNGjVSvsjMzc3FxsZGiWf37t0iIsoXqv7yjo2NjfKh6u7uLp07d1YSGP2X4Mcffyze3t5iZWUlAJQv18WLF0tAQIAA9y77ValS5YGX0ABIz549lSQIgEyePFlefPHFQvv5/mWYm5vLunXrDJajj93MzEw55kVdrrx/6tatm4iIcslNv1+srKyU49m6dWtp0KCBjBo1Sho1amRwDO8/n9RqdaFLqT/99JOyX/7v//5PRO4lSPrzIioqSgBIYmKi0mbNmjXi6uoq7u7uYmVlpRy7efPmyXfffScajUZq1qwpXbt2Vb50XnnlFeX9NXr0aLGxsREzMzOpUKGCHDt2TOrVqyd9+vRR9t3IkSMFgHKs9ZN+e44ePaokOOPHjxcRkYSEBLG0tJRBgwaJiMjo0aOVS9+WlpYG54x+26Ojo5V99eqrr8qCBQuUhNnMzExJBHU6nQD3Lo2am5uLi4uLAJCvvvpKnJycxNnZWUREialmzZoyceJEuXDhgnh5eUnlypVl0KBBSnJuHAtw748W/eeUp6enjB49Wuzt7WXSpEkG+2nIkCFiZWUlnp6eIiJFJkj9+vUTAPLHH38YtP35559lyZIlStv73f+FOHr0aOnQoYPodLpit9+0aZNYW1tLRESESW0vXLggf/zxhyxdulRsbGwkICDgkW27detmcCkpMTFRNBqNyTHr1axZU5ycnB7ZNiYmRoB7f1jo9e3bV0mwi7vepUuXirm5uQwZMqRYMaempoq/v7+MGTNG9u/fL1u3bpWwsDDx8vIqVvvXXntNqlWrppxz9vb2ymXbuLi4R54P9yvrBImX2IrJzMwMGzZswM8//4xatWphzpw5qFGjBs6ePYuoqCgcPHgQH374IXbu3ImDBw+iQoUKyMvLK3JZ+kGpct+vvBTnbopbt24hIiIC9vb2qFmzJnr37o1Zs2YBgNLNrFfU4FsRgU6nUwa5NmnSBO7u7njjjTdgY2MDf39/DB06FPv27YNOp4NKpcK2bdvQsmVLODo6Ktvj6ekJT09PxMXFAbh3R5q1tbVyecnFxQXff/+9QSwWFhbKwMQffvgBAFCxYkXUrVsXAJQfJ1apVGjUqBEAoEuXLgbxJycnQ6fTAYByaUatVivb89lnn+GLL76Ah4cHhg4dimrVqilt9fs8OzsbQ4YMAQB07doVBw8exGeffQYAyuUhEYFarUZQUBBeeuklHDx4ECkpKbC2tkZ6ejpatGiB7OxsAMBPP/0ErVarxFOU3r17K/+/cuWKwSDxadOmKfsMAPbu3WvQ1szMDNnZ2fDy8oK3tzcAIDg4GN999x26desGe3t76HQ6ZGdnK5frWrRogbFjx6JJkyZQq9XKpZ7c3FxlH69fvx4bN27Exo0bleMYHx8P4N7dJRqNBitWrAAAJCUl4dChQ+jWrZvBXTAFBQUAgGHDhmHZsmUYNmwYzMzMoFarsXTpUjRv3lypm5KSghYtWiivzc0L3x+ij/9++uNtZWWF8+fPo0mTJgCA1157DWPGjEHt2rULDYy+/9xv2bIlbt++rZyDAQEBaNmyJe7cuQPg3mXc1NRUAPfuGjx48KAytW7dGm3atIGvr+8DB4bfvz/0sc6aNQsHDx7EjBkzAACvv/46WrRogcTERNSrVw/Avcuew4YNQ+XKlQHcuxzo7u6OvLw8JX5ra2vUrFkTo0ePVpZz8+ZN5XNDH5P+ve/l5YUTJ05g/vz5sLKywoYNG2BtbY3ffvsN06ZNg5mZmXLcd+3ahYMHD6Jr164IDAxEy5YtkZ2djbS0NIP9dPr0aRQUFCAsLAwA4OHhgfT0dIN94O/vDwC4evWqQdstW7Zg69atStsHadmyJX799VccOnSoWO23bt2KTp06Yfbs2XjllVdMauvl5YVatWqhT58+GDx4MI4fP479+/c/tO2mTZswY8YMmJubw9zcHAMHDkReXh5+/PFHxMXFmbzNoaGhuHHjxiNjrlixIszNzZVLesA/n4lbtmwp9no/++wzdOzYEe3bty/Wvpo3bx4cHBwwffp0NGjQAC1atMDXX3+NixcvYuvWrY9s36pVK/z999/YsWMH3NzckJGRoVxuP3369CPPh/sVdb6lp6fD3t7+kTdrlAQmSCZQqVRo3rw54uLicODAAWg0Gnz//ffYsWMHRo4cifbt26N27drQarW4evXqA5ejvxtG/8EMoNAt7BqNRvkC0jt+/Dj+/vtvTJ06Fa6urnBwcFC+bM+ePQsAyuucnByICGrWrIn8/HwlAdNoNMp4n+rVq+Pq1atwd3eHmZkZ/vrrL4SGhqJhw4ZwcHCAiChvBEdHR2UZYWFhOH78OG7evAlfX194eXkhJycHb731FoB7z8L5888/C223/g4K/W3dVatWVcZX6L8cRQQZGRlQq9XK2CD9l2lubq6ynQUFBbCxsYGtra3SNjc3F/369cPQoUOxc+dOXLx4sVAMDRs2xNGjR5Xt9fPzUxKj+8cD6XQ6iAjs7Ozg5+eH2rVro2fPnnBycsJPP/2kLC8pKQnVq1fHjh07AEDZt1lZWdBqtdixYwdiYmKUmO/cuQMfHx+lvX77vby8ANy7LVir1eLEiRNKm4YNG+LGjRtKgmpmZoZu3bqhSpUqyjnSoEED5f9nzpzBlClT8Ouvv6Jbt264cOECXF1dlfWKCKysrNCmTRu0adNGiVmfpPr4+ECn06Fly5awsLBARkYG/Pz8YG9vj4KCAuU2e/2tzjdu3ECvXr0wZ84cVKtWDSKCCxcuGNzd5u3tXeQtxiqVCnl5ebCwsFASbH0Crd+PV69eRfXq1eHq6opOnToBAAICAvDnn3+iQYMGEBGkpKSgZs2ahZYfGhoKnU4HnU6nfDC3bNkSf/zxBwCgf//+WLFiBczNzXH69Gn4+fkp58TJkydha2sLjUYDf39/qFQqnDp1CgBQo0YN3LlzRxlrUbNmTSVpdnNzg5+fn5K4iYiy7fp/27VrB61WC41GA5VKBXt7eyWBvZ9arVYel7Fu3Trk5+cr54H+TsHz588r9a2srNCpUyd89NFHGDt2LLKzs5GRkYF27dopdw21adMGDRo0UI6ppaUlQkNDISJYu3atwX46ePAg8vPzlTEjISEh2LZtm8EfdH///TcA4PPPPzdou2XLFmzZsuWR403045Bmz579yPZbtmxBhw4dMG3aNAwePNiktsb0iV1CQsJD2+qTSf307rvvwtbWFmq1GidOnDB5vbdv34aIPDLm5s2bIz8/XxnbBkB5j6xfv75Y6z179iw2b96MgQMHFntf5eTkFLqzVP/ZmJOT88j2+vV89NFHaNWqFTQaDW7cuAFbW1vs2bOn2OOPgHvnm/FjXDZs2ICQkJBiL+NfKfU+qmfE7t27ZcqUKfLbb7/J+fPnZcWKFaLRaOSnn36SBg0ayPPPPy9Hjx6V3bt3S2hoqFhZWcns2bOV9rjvElteXp54eXlJjx495OTJk7Ju3TplbIL+EtuOHTsEgGzcuFEyMjLk1q1bcuXKFdFoNDJmzBjp1auX+Pv7S9WqVZXLWMC9cTi47zLV2rVrpV27dmJmZibe3t7i4eGh3IXm5eUlAQEB4uTkJCqVSjw8PGTr1q3y9ttvS6VKlQT4Z8xFWFiY0j0/adIkWbhwoQCQ6tWry+TJk8Xc3Fzs7e2VSxX6O3qAe9f6Z8+erbTRT02aNFEuMei7YPWXYOzs7KR3794CQGrXri0ApFq1aso4HCsrK2nTpo2ynfpLIuHh4dKkSZNCl3zCw8MFgBw6dEisrKyUO9CGDx8ukydPFuDe3UZXrlyRKlWqSFBQkNja2oqvr69s27ZN1q9fL/3791eWqV+vpaWlTJs2TRmfpd8H+ngtLCykffv2Bts9bdo05VJLy5YtDWLV32Wor9uoUSPljjn9JU4zMzNp1aqVVKhQQbnclpGRIb169VKWGxoaKiNGjFAuU86aNUveffddZbm2trYyfvx4GTBggNIVvmzZMhERpd7w4cOlW7duUrlyZZk8ebJUrVpVKlasKHZ2dvLaa69JTEyMcmfVmDFjZMuWLcpx9/f3l6ZNmyrre+655yQ1NVW5fFm7dm05fvy4Mr7F3t5eOQ73Hzf9GK2YmBhZvXq1wSVWCwsLGT58uDg7O4utra1kZGSIiMjw4cOVS2wiolwOfe+99yQjI0MyMjKU/bR+/Xo5cuSIcvmxffv28v3330vfvn3FyspKqlatqryHHRwcxMrKSr744gs5ceKEaLVacXZ2lkOHDsnGjRuVfV2/fn2ZP3++VKxYUYlz+vTpMmTIEOVSsv5yon4sm36/6bdD//7w8vKSRYsWCQB54403lEuX27Ztk99//125fNu1a1eZNm2ajBs3TuLi4uTMmTPy1ltviUqlkubNm8u2bdukS5cu4uHhIe3atZMdO3bInj17pGHDhsrYK/151717dzl58qRMnTpV2df6O6lu3Lgh7u7u8n//939y5MgRWbZsmVhbW4uXl5eYmZnJggULRETk77//Vu4g1LcVEfnjjz/kwIED0qlTJ2nZsqUcOHBADhw4IPXr139ke/1ltXHjxklqaqoyBQYGPrLt119/LcuXL5ejR4/KmTNnZPny5eLp6SlOTk7Fivt++uEPxYl58eLFsnTpUjl27JgcO3ZMpkyZImq1WqpUqfLItgUFBdKwYUNp0aKF7N+/X/bt2yfBwcFiZ2dX7JjHjx8vnp6eyp1vxYk5OTlZVCqVxMXFycmTJyUlJUUiIiLE29tb6tat+8j2GRkZUrlyZTEzM5O3335bRo4cKVqtVnl/FOd80Pvzzz/F2tpaxowZI8eOHZN58+aJmZmZJCUlFXlsShoTpGI6evSoREREiKurq3Jb65w5c0REZP/+/dKoUSOxtLQUf39/WblypXh7ez8wQRIR+fXXXyUwMFAsLS0lNDRUVq5caZAgiYgMHTpUSXz0t/kvXbpUfHx8lFuM9WMy9Lelu7m5iZOTk/IFrv/yMzMzE7VarXwB9+rVSxkvo5/Mzc3Fy8tL+vbtK/Xq1RMAyhshLCxM+YK2tbUVJycn6dKlizK+5f5xMY6OjvLDDz8USpASExMNxibpl6VPcPRflPqBvPqpRYsWhW67b968uYwaNUq6d+/+yFum70+QRET27t0r5ubmYmFhoeyT+x+DYGNjIzNmzJDhw4cbjN144YUXlPEgDRo0EODeWJpq1aqJubl5oXEeVapUEXNzcyUZ0ydA9evXl5kzZz403qLGhxnvl/un69evS3Z2dqH9C0A6duxocJu//tjqJ/1Yo19//VVE/rnN//nnn1cST30iVKdOHWnSpImMHTtWTpw4UeSt+ra2thIaGqrMc3Z2Fmtra1GpVMq6atSoIfb29spt//ePqdInuMC9MXEJCQkyefJkqVmzpsH6KlasKGZmZqLVamXTpk3K+8Y4QdI/AkN/fM6ePWuQaDs7O0unTp2kffv2yn63sLAQBwcHCQwMVJbr7e0t7du3F29vb7GwsBCNRiN2dnai0WgkICBA5syZoxxjlUqlLKtevXpSuXJlg210d3eXkJAQ5f1d1PFu3ry5WFtbK8e0UaNGMnDgQLG2thZ7e3slefLw8BAHBwcxMzMTjUajjC9q2rSprFixQvr16ycuLi6i0WjE0dFReVxCxYoVpUqVKsrNCvrb1/XjvTp16iSenp6iUqkMPgsPHTokzz33nGi1WqlUqZJMnTpVaasffC4iUq9ePfHw8DBo+6BxcMVpr08qjSf9H3MPa7ts2TJp2LCh2Nraio2NjdSqVUvef/995Vx5VNz30ydIxYl58eLFUrNmTeWYNWnSRFauXFns/XXp0iXp3r272Nrairu7u0RHR8uQIUOK1bagoEAqV64sb7/9tlJW3PV+88030qBBA7GxsRFXV1fp3LmzHDt2rFjtMzIylD9sLC0tpU2bNrJ7926Tzof7bd68WerXry8ajUaqVasmiYmJhQ9KKWGCRMWiv2vu39q2bZtYWFhIWlravw+qDJw9e1bUarVER0cLgCK3wzgZFvnn+VX658fcvzwABn81lWfZ2dni4OAgn3322WO1f9R5VNS+u59+f5mbm5fqOVRQUCDVq1dXBmUXx6+//ioA5PTp06UWFxE9OXySNj0Rubm5yMjIwKRJk9CjRw9lvMvT4u7du/j7778xbtw4NGzYEHv27IGFhcUjtyMnJwepqamYOnUqhgwZ8tQ9kfvAgQM4fvw4mjRpgszMTLz77rsACg+gfxJyc3OVcXvPP/98iZ5D58+fxy+//IKwsDDk5uZi7ty5OHv2LF566aUHtvn+++9ha2sLf39/nD59GqNGjULz5s0NnmNFRE8vDtKmJ+Kbb76Bt7c3bty4UezfbipPduzYgYoVK2LLli1ISUlBTk5Ose6imD59OgICAuDh4YFx48Y9gUhL3owZM1CvXj2Eh4fj1q1b2L59u3LX3ZP0zTffKHfGlcRvq91PrVZj8eLFaNy4MZo3b47Dhw9j48aNRQ781rt58yaGDx+OgIAAREdHo3HjxlizZk2JxkVEZUclct+95kRERETEHiQiIiIiY0yQiIiIiIwwQSIiIiIywgSJiIiIyAgTJCIiIiIjTJCI6KkTHR0NlUpVaDp9+vS/XvbixYuV35kjov8uPiiSiJ5Kbdu2RWJiokGZ/oegy4u7d+8qPyBNRE8X9iAR0VNJq9XCw8PDYDIzM8OaNWvQsGFDWFpaolq1aoiLi0N+fr7SbtasWQgMDISNjQ28vLzwyiuvIDs7G8C9X4vv378/MjMzlV6pSZMmAQBUKhVWr15tEIOjoyMWL14MADh37hxUKhWWL1+OsLAwWFpaYsmSJQCAzz77DDVr1oSlpSUCAgIwf/78Ut8/RPTvsAeJiJ4Z27dvR79+/fDRRx8hNDQUZ86cweDBgwEAEydOBHDvqdkfffQRqlatij///BOvvPIK3nzzTcyfPx/NmjVDQkICJkyYgBMnTgAAbG1tTYph7NixmDlzJho0aKAkSRMmTMDcuXPRoEEDHDhwADExMbCxsUFUVFTJ7gAiKjFMkIjoqbRu3TqD5KVdu3a4fv06xo4dqyQe1apVw+TJk/Hmm28qCdL9P1Pi4+OD9957D0OHDsX8+fOh0Wjg4OAAlUoFDw+Px4rrtddeQ/fu3ZXXEydOxMyZM5WyqlWr4ujRo/j444+ZIBGVY0yQiOip1KpVKyxYsEB5bWNjg7p162LHjh2YMmWKUl5QUIA7d+4gJycH1tbW2LhxI+Lj43H8+HFkZWUhPz/fYP6/1ahRI+X/t27dwpkzZzBw4EDExMQo5fn5+XBwcPjX6yKi0sMEiYieSjY2NvDz8zMoy87ORlxcnEEPjp6lpSXOnTuHjh07YtiwYZgyZQqcnZ3x66+/YuDAgcjLy3togqRSqWD805V3794tMq774wGATz/9FMHBwQb1zMzMHr2RRFRmmCAR0TOjYcOGOHHiRKHESS8lJQU6nQ4zZ86EWn3vHpUVK1YY1NFoNCgoKCjU1tXVFampqcrrU6dOIScn56HxuLu7w9PTE3/++Sf69u1r6uYQURligkREz4wJEyagY8eOqFKlCl588UWo1WocOnQIR44cwXvvvQc/Pz/cvXsXc+bMQadOnbBjxw4sXLjQYBk+Pj7Izs5GcnIy6tWrB2tra1hbW6N169aYO3cuQkJCUFBQgLfeeqtYt/DHxcVh5MiRcHBwQNu2bZGbm4t9+/bh+vXriI2NLa1dQUT/Em/zJ6JnRkREBNatW4dffvkFjRs3RtOmTTF79mx4e3sDAOrVq4dZs2Zh2rRpqFOnDpYsWYL4+HiDZTRr1gxDhw5Fr1694OrqiunTpwMAZs6cCS8vL4SGhuKll17CG2+8UawxS4MGDcJnn32GxMREBAYGIiwsDIsXL0bVqlVLfgcQUYlRifFFdSIiIqL/OPYgERERERlhgkRERERkhAkSERERkREmSERERERGmCARERERGWGCRERERGSECRIRERGRESZIREREREaYIBEREREZYYJEREREZIQJEhEREZERJkhERERERv4fMr8RCy5yxfsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importance\n",
    "fig = plt.figure()\n",
    "ax = fig.gca() #get current axis\n",
    "ax.bar(range(x_train.shape[1]), forest_cv2.best_estimator_.feature_importances_)\n",
    "ax.set_xticks(np.arange(x_train.shape[1]))\n",
    "ax.set_xticklabels([f'{col}' for col in x_train.columns])\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Feature Importance')\n",
    "ax.set_title('Random Forest Regression Feature Importances')\n",
    "\n",
    "# Ugly ass graph but its working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.174805</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.153718</td>\n",
       "      <td>invoicepostcode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082974</td>\n",
       "      <td>domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.057713</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.057109</td>\n",
       "      <td>remi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.055253</td>\n",
       "      <td>numberitems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050959</td>\n",
       "      <td>newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.042634</td>\n",
       "      <td>w0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037588</td>\n",
       "      <td>salutation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.035076</td>\n",
       "      <td>w1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.035023</td>\n",
       "      <td>paymenttype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.031171</td>\n",
       "      <td>deliverytype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028719</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.021115</td>\n",
       "      <td>shippingcosts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.019361</td>\n",
       "      <td>w2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.017273</td>\n",
       "      <td>voucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.016473</td>\n",
       "      <td>w9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015568</td>\n",
       "      <td>entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.014436</td>\n",
       "      <td>w5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.013330</td>\n",
       "      <td>used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.012051</td>\n",
       "      <td>w10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.008181</td>\n",
       "      <td>cancel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.007038</td>\n",
       "      <td>w3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004961</td>\n",
       "      <td>w4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003785</td>\n",
       "      <td>w6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.002628</td>\n",
       "      <td>w7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000713</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000345</td>\n",
       "      <td>gift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>w8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Importance          Feature\n",
       "15    0.174805           weight\n",
       "7     0.153718  invoicepostcode\n",
       "2     0.082974           domain\n",
       "9     0.057713             case\n",
       "16    0.057109             remi\n",
       "10    0.055253      numberitems\n",
       "3     0.050959       newsletter\n",
       "19    0.042634               w0\n",
       "0     0.037588       salutation\n",
       "20    0.035076               w1\n",
       "5     0.035023      paymenttype\n",
       "6     0.031171     deliverytype\n",
       "4     0.028719            model\n",
       "14    0.021115    shippingcosts\n",
       "21    0.019361               w2\n",
       "8     0.017273          voucher\n",
       "28    0.016473               w9\n",
       "12    0.015568            entry\n",
       "24    0.014436               w5\n",
       "18    0.013330             used\n",
       "29    0.012051              w10\n",
       "17    0.008181           cancel\n",
       "22    0.007038               w3\n",
       "23    0.004961               w4\n",
       "25    0.003785               w6\n",
       "26    0.002628               w7\n",
       "1     0.000713            title\n",
       "11    0.000345             gift\n",
       "13    0.000000           points\n",
       "27    0.000000               w8"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances with names \n",
    "importance = pd.DataFrame(forest_cv2.best_estimator_.feature_importances_)\n",
    "feature_names = pd.DataFrame(x_train.columns)\n",
    "feature_importances = pd.concat([importance, feature_names], axis = 1)\n",
    "\n",
    "# Name columns accordingly\n",
    "feature_importances.columns = [\"Importance\", \"Feature\"]\n",
    "feature_importances.sort_values(by = \"Importance\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now what to we do with this? Can we just leave out the worst 10 features for example? \n",
    "# Random forest not really useful in predicting true positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(n_estimators = 5000, learning_rate = 0.8)\n",
    "ada = ada.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8150363883064019\n",
      "Precision (Share of positives correctly specified): 0.6177777777777778\n",
      "Sensitivity (Share of actual true values found): 0.022971409684349693\n",
      "Specificity (Share of actual false values found): 0.9967395837282481\n",
      "TP: 139 FP: 86 TN: 26291 FN: 5912\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_ada = ada.predict(x_train)\n",
    "evaluate_model(y_train, y_train_pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 720 is smaller than n_iter=1000. Running 720 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        'n_estimators': range(10, 50)},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "max_depth = range(1,5) \n",
    "n_estimators = range(10,50)\n",
    "learning_rate = np.arange(0.5, 5, 0.25) # In Adaboost learning rate can go to infinity (weights of previous misclassifications)\n",
    "#cv = range(4,10)\n",
    "\n",
    "# What about depth of base estimator? \n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'n_estimators': n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up AdaBoost classifier\n",
    "ada = AdaBoostClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "ada_cv = RandomizedSearchCV(ada, param_dist, n_jobs = -1, verbose = 1, n_iter = 1000, scoring = 'accuracy', cv = 5)\n",
    "# Fit it to the data\n",
    "ada_cv.fit(x_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8134636733686937\n",
      "Precision (Share of positives correctly specified): 0.625\n",
      "Sensitivity (Share of actual true values found): 0.0008263097008758883\n",
      "Specificity (Share of actual false values found): 0.9998862645486598\n",
      "TP: 5 FP: 3 TN: 26374 FN: 6046\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from AdaCV model\n",
    "y_train_pred_ada_cv = ada_cv.predict(x_train)\n",
    "# Evaluate accuracy of cross-validated model\n",
    "evaluate_model(y_train, y_train_pred_ada_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.5, max_depth=10, n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.5, max_depth=10, n_estimators=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.5, max_depth=10, n_estimators=50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(max_depth = 10, n_estimators = 50, learning_rate = 0.5)\n",
    "gbrt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbrt.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test-wise save of the model\n",
    "joblib.dump(gbrt, \"gbrt.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9692241272973973\n",
      "Precision (Share of positives correctly specified): 0.994519475435506\n",
      "Sensitivity (Share of actual true values found): 0.8396959180300777\n",
      "Specificity (Share of actual false values found): 0.998938469120825\n",
      "TP: 5081 FP: 28 TN: 26349 FN: 970\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for initial values\n",
    "y_train_pred_gbrt = gbrt.predict(x_train)\n",
    "# Evaluate model predictions\n",
    "evaluate_model(y_train, y_train_pred_gbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.4, 0.5, 0.6, 0.7, 0.8]),\n",
       "                                        &#x27;max_depth&#x27;: range(8, 15),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 40)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.4, 0.5, 0.6, 0.7, 0.8]),\n",
       "                                        &#x27;max_depth&#x27;: range(8, 15),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 40)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': array([0.4, 0.5, 0.6, 0.7, 0.8]),\n",
       "                                        'max_depth': range(8, 15),\n",
       "                                        'n_estimators': range(30, 40)},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup parameter distributions for hyperparameter tuning\n",
    "max_depth = range(8, 15)\n",
    "n_estimators = range(30,40)\n",
    "learning_rate = np.arange(0.4, 0.9, 0.1) # so far it always outputs first value in list as best parameter\n",
    "param_dist = {\"max_depth\": max_depth, \"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "gbrt_cv = RandomizedSearchCV(gbrt, param_dist, n_jobs = -1, cv = 5, verbose = 1, n_iter = 100, scoring = 'accuracy')\n",
    "# Fit it to the data\n",
    "gbrt_cv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 31, 'max_depth': 8, 'learning_rate': 0.4}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8668126310595782\n",
      "Precision (Share of positives correctly specified): 0.9816462736373749\n",
      "Sensitivity (Share of actual true values found): 0.29168732440918854\n",
      "Specificity (Share of actual false values found): 0.998748910035258\n",
      "TP: 1765 FP: 33 TN: 26344 FN: 4286\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_gbrt_cv = gbrt_cv.predict(x_train)\n",
    "\n",
    "evaluate_model(y_train, y_train_pred_gbrt_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
