{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS405 Machine Learning Applications in Business and Economics Mini-Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">TBD: \n",
    "- What features to use? \n",
    "    - Construct new ones? \n",
    "    - Simply leave out all non-numeric features? \n",
    "    - Delivery-Delay might be interesting\n",
    "    - Delivery Delay\n",
    "\n",
    "- What is the goal of our model?\n",
    "    - Avoid false negatives? This way returning customers will not receive a voucher. \n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the realm of e-commerce, a common observation is that a significant proportion of customers engage in a single transaction and then cease further purchases. This phenomenon can be attributed to a multitude of factors. To mitigate this, e-commerce platforms employ a variety of strategies aimed at fostering customer loyalty. One such strategy involves the distribution of discount vouchers subsequent to the initial purchase, with the goal of incentivizing repeat transactions. However, indiscriminate distribution of these vouchers may not be an optimal strategy. This is because a segment of customers might have engaged in repeat purchases even in the absence of such incentives. Consequently, the redemption of these vouchers by such customers translates into a reduction in the retailer’s profit. Empirical analyses conducted by the media retailer have demonstrated that for 10% of non-buyers, the voucher instigates a purchase with an average order value of €20. Thus, if a voucher is dispatched to a customer who would not have actually made another purchase, the revenue increases by an average of €1.5. On the other hand, sending a voucher to a customer who would have made a purchase anyway results in a revenue loss equivalent to the voucher value of €5. For customers who don’t receive a voucher, there is no impact on revenues. Therefore, it is crucial to devise a more targeted approach for the distribution of these vouchers.\n",
    "\n",
    "## Task \n",
    "\n",
    "The task at hand involves constructing a predictive model that leverages various features associated with a customer’s initial order. The objective is to determine whether a €5.00 voucher should be issued to a specific customer. Detailed descriptions of these features can be found in the data dictionary.pdf file.\n",
    "The model should be designed to predict if a customer will place a subsequent order within a 90-day period following their initial purchase. This information is represented by the target90 variable in the dataset. The model’s performance is evaluated based on the expected revenue across all customers in a given dataset. This is computed by considering the model’s predictions in conjunction with the associated costs and revenues. It’s crucial to note that the model’s effectiveness is directly tied to its ability to maximize this expected revenue. Hence, the model should be optimized with this specific goal in mind.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier # Binary dependent variable\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "import joblib # to save trained model \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading in and getting an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_17720\\544976364.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"train.csv\", sep = \";\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customernumber</th>\n",
       "      <th>salutation</th>\n",
       "      <th>title</th>\n",
       "      <th>domain</th>\n",
       "      <th>newsletter</th>\n",
       "      <th>model</th>\n",
       "      <th>paymenttype</th>\n",
       "      <th>deliverytype</th>\n",
       "      <th>invoicepostcode</th>\n",
       "      <th>voucher</th>\n",
       "      <th>case</th>\n",
       "      <th>numberitems</th>\n",
       "      <th>gift</th>\n",
       "      <th>entry</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33389.298569</td>\n",
       "      <td>0.541569</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>7.517115</td>\n",
       "      <td>0.169483</td>\n",
       "      <td>1.646910</td>\n",
       "      <td>1.000987</td>\n",
       "      <td>0.201955</td>\n",
       "      <td>48.752282</td>\n",
       "      <td>0.162020</td>\n",
       "      <td>2.934378</td>\n",
       "      <td>2.019551</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.414642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19148.090449</td>\n",
       "      <td>0.657044</td>\n",
       "      <td>0.083192</td>\n",
       "      <td>3.683945</td>\n",
       "      <td>0.375184</td>\n",
       "      <td>0.825981</td>\n",
       "      <td>1.092677</td>\n",
       "      <td>0.401465</td>\n",
       "      <td>24.361425</td>\n",
       "      <td>0.368475</td>\n",
       "      <td>1.319270</td>\n",
       "      <td>1.726046</td>\n",
       "      <td>0.067404</td>\n",
       "      <td>0.492668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16802.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33552.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50034.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66251.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customernumber    salutation         title        domain    newsletter  \\\n",
       "count    32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean     33389.298569      0.541569      0.006969      7.517115      0.169483   \n",
       "std      19148.090449      0.657044      0.083192      3.683945      0.375184   \n",
       "min          1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      16802.750000      0.000000      0.000000      4.000000      0.000000   \n",
       "50%      33552.500000      0.000000      0.000000      9.000000      0.000000   \n",
       "75%      50034.250000      1.000000      0.000000     11.000000      0.000000   \n",
       "max      66251.000000      2.000000      1.000000     12.000000      1.000000   \n",
       "\n",
       "              model   paymenttype  deliverytype  invoicepostcode  \\\n",
       "count  32428.000000  32428.000000  32428.000000     32428.000000   \n",
       "mean       1.646910      1.000987      0.201955        48.752282   \n",
       "std        0.825981      1.092677      0.401465        24.361425   \n",
       "min        1.000000      0.000000      0.000000         0.000000   \n",
       "25%        1.000000      0.000000      0.000000        30.000000   \n",
       "50%        1.000000      1.000000      0.000000        47.000000   \n",
       "75%        2.000000      2.000000      0.000000        66.000000   \n",
       "max        3.000000      3.000000      1.000000        99.000000   \n",
       "\n",
       "            voucher          case   numberitems          gift         entry  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.162020      2.934378      2.019551      0.004564      0.414642   \n",
       "std        0.368475      1.319270      1.726046      0.067404      0.492668   \n",
       "min        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%        0.000000      2.000000      1.000000      0.000000      0.000000   \n",
       "50%        0.000000      3.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      4.000000      2.000000      0.000000      1.000000   \n",
       "max        1.000000      5.000000     50.000000      1.000000      1.000000   \n",
       "\n",
       "        points  \n",
       "count  32428.0  \n",
       "mean       0.0  \n",
       "std        0.0  \n",
       "min        0.0  \n",
       "25%        0.0  \n",
       "50%        0.0  \n",
       "75%        0.0  \n",
       "max        0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separator is ;\n",
    "data = pd.read_csv(\"train.csv\", sep = \";\")\n",
    "\n",
    "# Dataset is wide, print all rows and only first 15 columns\n",
    "data.describe().iloc[:,0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shippingcosts</th>\n",
       "      <th>weight</th>\n",
       "      <th>remi</th>\n",
       "      <th>cancel</th>\n",
       "      <th>used</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>w10</th>\n",
       "      <th>target90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.150611</td>\n",
       "      <td>637.920809</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>0.061613</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.902122</td>\n",
       "      <td>0.404342</td>\n",
       "      <td>0.276644</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>0.047027</td>\n",
       "      <td>0.180986</td>\n",
       "      <td>0.027908</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.164981</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>0.186598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.357674</td>\n",
       "      <td>724.358131</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>0.306833</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>1.654767</td>\n",
       "      <td>1.410395</td>\n",
       "      <td>1.353981</td>\n",
       "      <td>0.253596</td>\n",
       "      <td>0.434265</td>\n",
       "      <td>0.561751</td>\n",
       "      <td>0.299862</td>\n",
       "      <td>0.401782</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.836705</td>\n",
       "      <td>0.610509</td>\n",
       "      <td>0.389594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20076.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shippingcosts        weight          remi        cancel          used  \\\n",
       "count   32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean        0.150611    637.920809      0.059979      0.061613      0.068860   \n",
       "std         0.357674    724.358131      0.388740      0.306833      0.474444   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      3.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000    494.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000    920.000000      0.000000      0.000000      0.000000   \n",
       "max         1.000000  20076.000000     19.000000     17.000000     19.000000   \n",
       "\n",
       "                 w0            w1            w2            w3            w4  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.902122      0.404342      0.276644      0.018903      0.047027   \n",
       "std        1.654767      1.410395      1.353981      0.253596      0.434265   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       99.000000     84.000000     90.000000     15.000000     36.000000   \n",
       "\n",
       "                 w5            w6            w7            w8            w9  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.180986      0.027908      0.023128      0.000185      0.164981   \n",
       "std        0.561751      0.299862      0.401782      0.013601      0.836705   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       14.000000     27.000000     55.000000      1.000000     48.000000   \n",
       "\n",
       "                w10      target90  \n",
       "count  32428.000000  32428.000000  \n",
       "mean       0.092883      0.186598  \n",
       "std        0.610509      0.389594  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max       50.000000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second half of the columns\n",
    "# Dataset is wide, print all rows and only remaining columns\n",
    "data.describe().iloc[:,15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every column has a count of 32428 -> No missing values seem to be present. In the case of binary encoded variables, the mean directly reflects a percentage (if multiplied by 100). \\\n",
    "However, due to their datatype, some columns are not present in the .describe()-dataframe. Therefore, to fully detect all missing values, we loop over all columns in the as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 18.66% of customers in the data set repurchased in the next 90 days. This makes the data set imbalanced and we have to proceed with caution.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Only {np.round(data['target90'].mean()*100,2)}% of customers in the data set repurchased in the next 90 days. This makes the data set imbalanced and we have to proceed with caution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocessing for one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_17720\\501370038.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'web.de' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[i, \"domain\"] = \"web.de\"\n",
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_17720\\501370038.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Ms.' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[i, \"salutation\"] = \"Ms.\"\n",
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_17720\\501370038.py:49: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Transfer' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[i, \"paymenttype\"] = \"Transfer\"\n"
     ]
    }
   ],
   "source": [
    "# Domain\n",
    "for i in range(len(data[\"domain\"])):\n",
    "    value = data[\"domain\"].iloc[i]\n",
    "    if value == 0:\n",
    "        data.loc[i, \"domain\"] = \"aol.com\"\n",
    "    elif value == 1:\n",
    "        data.loc[i, \"domain\"] = \"arcor.de\"\n",
    "    elif value == 2:\n",
    "        data.loc[i, \"domain\"] = \"freenet.de\"\n",
    "    elif value == 3:\n",
    "        data.loc[i, \"domain\"] = \"gmail.com\"\n",
    "    elif value == 4:\n",
    "        data.loc[i, \"domain\"] = \"gmx.de\"\n",
    "    elif value == 5:\n",
    "        data.loc[i, \"domain\"] = \"hotmail.de\"\n",
    "    elif value == 6:\n",
    "        data.loc[i, \"domain\"] = \"online.de\"\n",
    "    elif value == 7:\n",
    "        data.loc[i, \"domain\"] = \"onlinehome.de\"\n",
    "    elif value == 8:\n",
    "        data.loc[i, \"domain\"] = \"t-online.de\"\n",
    "    elif value == 9:\n",
    "        data.loc[i, \"domain\"] = \"web.de\"\n",
    "    elif value == 10:\n",
    "        data.loc[i, \"domain\"] = \"yahoo.com\"\n",
    "    elif value == 11:\n",
    "        data.loc[i, \"domain\"] = \"yahoo.de\"\n",
    "    elif value == 12:\n",
    "        data.loc[i, \"domain\"] = \"others\"\n",
    "\n",
    "# Salutation\n",
    "for i in range(len(data[\"salutation\"])):\n",
    "    value = data[\"salutation\"].iloc[i]\n",
    "    if value == 0:\n",
    "        data.loc[i, \"salutation\"] = \"Ms.\"\n",
    "    elif value == 1:\n",
    "        data.loc[i, \"salutation\"] = \"Mr.\"\n",
    "    elif value == 2:\n",
    "        data.loc[i, \"salutation\"] = \"Company\"\n",
    "    \n",
    "# Payment-type\n",
    "for i in range(len(data[\"paymenttype\"])):\n",
    "    value = data[\"paymenttype\"].iloc[i]\n",
    "    if value == 0:\n",
    "        data.loc[i, \"paymenttype\"] = \"Invoice\"\n",
    "    elif value == 1:\n",
    "        data.loc[i, \"paymenttype\"] = \"Cash\"\n",
    "    elif value == 2:\n",
    "        data.loc[i, \"paymenttype\"] = \"Transfer\"\n",
    "    elif value == 3:\n",
    "        data.loc[i, \"paymenttype\"] = \"Credit\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dummy variables\n",
    "data = pd.get_dummies(data, columns=[\"domain\", \"salutation\", \"model\", \"paymenttype\"], dtype = \"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing delivery delay\n",
    "\n",
    "We expect a potential delay in the delivery to have a systematic influence on a customer's re-purchase probability. The longer this delay gets, the less likely an expected re-purchase will become. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_17720\\1525678194.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-1 days +00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[i, \"delay\"] = data[\"deliverydatereal\"][i] - data[\"deliverydatepromised\"][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Delay column: 5478\n"
     ]
    }
   ],
   "source": [
    "# Convert actual delivery date to datetime\n",
    "for i in range(len(data)):  \n",
    "    if data.loc[i, \"deliverydatereal\"].startswith(\"0000\"):  \n",
    "        data.loc[i, \"deliverydatereal\"] = np.nan\n",
    "    else:\n",
    "        data.loc[i, \"deliverydatereal\"] = pd.to_datetime(data.loc[i, \"deliverydatereal\"])\n",
    "\n",
    "# Convert promised delivery date to datetime\n",
    "for i in range(len(data)):\n",
    "    if data.loc[i, \"deliverydatepromised\"].startswith(\"0000\"): # disregard missing values\n",
    "        data.loc[i, \"deliverydatepromised\"] = np.nan\n",
    "    else:\n",
    "        try: # Exception had to be added because some dates were out of bounds (Year 4746)\n",
    "            data.loc[i, \"deliverydatepromised\"] = pd.to_datetime(data.loc[i, \"deliverydatepromised\"])\n",
    "        except pd.errors.OutOfBoundsDatetime:\n",
    "            data.loc[i, \"deliverydatepromised\"] = np.nan\n",
    "\n",
    "# Compute actual delay in timedelta format\n",
    "data[\"delay\"] = [0] * len(data)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if pd.notna(data[\"deliverydatereal\"][i]) and pd.notna(data[\"deliverydatepromised\"][i]):\n",
    "        data.loc[i, \"delay\"] = data[\"deliverydatereal\"][i] - data[\"deliverydatepromised\"][i]\n",
    "    else:\n",
    "        data.loc[i, \"delay\"] = np.nan\n",
    "\n",
    "# Get days of delay\n",
    "for i in range(len(data)):\n",
    "    if pd.notna(data[\"delay\"][i]):\n",
    "        data.loc[i, \"delay\"] = data[\"delay\"][i].days\n",
    "    else:\n",
    "        data.loc[i, \"delay\"] = np.nan\n",
    "\n",
    "missing_values = data[\"delay\"].isna().sum()\n",
    "print(f\"Number of missing values in Delay column: {missing_values}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, only few classifiers can work with NaNs. Since we have over 5000 missing values, different ways of imputing them could have a considerable impact on our model predictions. \\\n",
    "Therefore we disregard the Delivery Delay variable and stick to the original data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to evaluate model precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_train, y_train_pred, y_test, y_test_pred):\n",
    "\n",
    "    # Convert y_train & y_test to np.array, as predictions will also be np.array\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Initialize variables for training set\n",
    "    TP_train = 0\n",
    "    FP_train = 0\n",
    "    TN_train = 0\n",
    "    FN_train = 0\n",
    "\n",
    "    # Evaluate training set predictions\n",
    "    for i in range(len(y_train_pred)): \n",
    "        if y_train[i] == y_train_pred[i] == 1:\n",
    "            TP_train += 1\n",
    "        if y_train_pred[i] == 1 and y_train[i] != y_train_pred[i]:\n",
    "            FP_train += 1\n",
    "        if y_train[i] == y_train_pred[i] == 0:\n",
    "            TN_train += 1\n",
    "        if y_train_pred[i] == 0 and y_train[i] != y_train_pred[i]:\n",
    "            FN_train += 1\n",
    "\n",
    "    # Calculate training set metrics\n",
    "    accuracy_train = (TP_train + TN_train) / (TP_train + TN_train + FP_train + FN_train) if (TP_train + TN_train + FP_train + FN_train) != 0 else 0\n",
    "    precision_train = TP_train / (TP_train + FP_train) if (TP_train + FP_train) != 0 else 0\n",
    "    sensitivity_train = TP_train / (TP_train + FN_train) if (TP_train + FN_train) != 0 else 0\n",
    "    specificity_train = TN_train / (TN_train + FP_train) if (TN_train + FP_train) != 0 else 0\n",
    "\n",
    "    # Initialize variables for test set\n",
    "    TP_test = 0\n",
    "    FP_test = 0\n",
    "    TN_test = 0\n",
    "    FN_test = 0\n",
    "\n",
    "    # Evaluate test set predictions\n",
    "    for i in range(len(y_test_pred)): \n",
    "        if y_test[i] == y_test_pred[i] == 1:\n",
    "            TP_test += 1\n",
    "        if y_test_pred[i] == 1 and y_test[i] != y_test_pred[i]:\n",
    "            FP_test += 1\n",
    "        if y_test[i] == y_test_pred[i] == 0:\n",
    "            TN_test += 1\n",
    "        if y_test_pred[i] == 0 and y_test[i] != y_test_pred[i]:\n",
    "            FN_test += 1\n",
    "\n",
    "    # Calculate test set metrics\n",
    "    accuracy_test = (TP_test + TN_test) / (TP_test + TN_test + FP_test + FN_test) if (TP_test + TN_test + FP_test + FN_test) != 0 else 0\n",
    "    precision_test = TP_test / (TP_test + FP_test) if (TP_test + FP_test) != 0 else 0\n",
    "    sensitivity_test = TP_test / (TP_test + FN_test) if (TP_test + FN_test) != 0 else 0\n",
    "    specificity_test = TN_test / (TN_test + FP_test) if (TN_test + FP_test) != 0 else 0\n",
    "\n",
    "\n",
    "   # Collect results in a dataframe \n",
    "    results_df = pd.DataFrame({\n",
    "        'Set': ['Training', 'Test'],\n",
    "        'Accuracy': [accuracy_train, accuracy_test],\n",
    "        'Precision': [precision_train, precision_test],\n",
    "        'Sensitivity': [sensitivity_train, sensitivity_test],\n",
    "        'Specificity': [specificity_train, specificity_test],\n",
    "        'TP': [TP_train, TP_test],\n",
    "        'FP': [FP_train, FP_test],\n",
    "        'TN': [TN_train, TN_test],\n",
    "        'FN': [FN_train, FN_test]\n",
    "    })\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Constructing the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivpostcode 31036\n",
      "advertisingdatacode 25905\n",
      "deliverydatepromised 9\n",
      "deliverydatereal 5472\n",
      "delay 5478\n"
     ]
    }
   ],
   "source": [
    "# Function to check for NAs in every column\n",
    "def count_na(df):\n",
    "    for col in df.columns:          # Loop over all columns\n",
    "        n_na = df[col].isna().sum() # Count occurrences of missing values\n",
    "        if n_na > 0:                # Only give column and count if there actually are NAs\n",
    "            print(col, n_na)        # Print column name and number of NAs\n",
    "\n",
    "# Apply function\n",
    "count_na(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only seem to have missing values in the *delivpostcode* and the *advertisingdatacode* column. \\\n",
    "One possible approach of fixing the issue in the *delivpostcode* column would be to simply impute the values of the *invoicepostcode* column. However, these values do not necessarily have to match. \\\n",
    "For the *advertisingdatacode* column, we do not have a logical approach of dealing with these rather unique data type and its missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dependent variable -> label \n",
    "y = data[\"target90\"]\n",
    "\n",
    "# Construct explanatory variables -> features (invoicepostcode may be kept as a feature)\n",
    "x = data.drop([\"customernumber\", \"date\", \"datecreated\", \"invoicepostcode\", \"delivpostcode\", \"advertisingdatacode\",\n",
    "                       \"deliverydatepromised\", \"deliverydatereal\", \"target90\", \"delay\"], axis = 1)\n",
    "\n",
    "# Split data into training and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_na(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customernumber', 'date', 'datecreated', 'invoicepostcode', 'delivpostcode', 'advertisingdatacode', 'deliverydatepromised', 'deliverydatereal', 'target90', 'delay']\n"
     ]
    }
   ],
   "source": [
    "disregarded_columns = []\n",
    "for col in data.columns:\n",
    "    if col not in x.columns:\n",
    "        disregarded_columns.append(col)\n",
    "print(disregarded_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Customernumber**: We don't expect the customernumer assigned to an individual to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Date**: We don't expect the date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Datecreated**: We don't expect the date of account creation to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Invoicepostcode**: We dont't expect the postcode of the invoice to have a systematic influence on a customer's re-purchase probability. \n",
    "- **Delivpostcode**: Too many missing values.\n",
    "- **Advertisingdatacode**: Too many missing values.\n",
    "- **Deliverydatepromised**: We don't expect the promised delivery date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Deliverydatereal**: We don't expect the actual delivery date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Target90**: This is the label we want to predict, therefore we do not include it in the training process.\n",
    "- **Delay**: We did expect the delivery delay to have a systematic influence on a customer's re-purchase probability. However, there are too many missing values present. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First try of estimation with RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=100, n_estimators=20, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=100, n_estimators=20, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=100, n_estimators=20, random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to check if we can actually predict the data set\n",
    "forest = RandomForestClassifier(n_estimators = 20, max_depth = 100, min_samples_split = 2, min_samples_leaf = 1, criterion = \"gini\", bootstrap = True, random_state = 0)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model predictions for training set\n",
    "y_train_pred = forest.predict(x_train)\n",
    "# Get model predictions for holdout set\n",
    "y_test_pred = forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.964932</td>\n",
       "      <td>0.977298</td>\n",
       "      <td>0.833644</td>\n",
       "      <td>0.995492</td>\n",
       "      <td>3573</td>\n",
       "      <td>83</td>\n",
       "      <td>18330</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.786206</td>\n",
       "      <td>0.229846</td>\n",
       "      <td>0.075921</td>\n",
       "      <td>0.943621</td>\n",
       "      <td>134</td>\n",
       "      <td>449</td>\n",
       "      <td>7515</td>\n",
       "      <td>1631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity    TP   FP     TN  \\\n",
       "0  Training  0.964932   0.977298     0.833644     0.995492  3573   83  18330   \n",
       "1      Test  0.786206   0.229846     0.075921     0.943621   134  449   7515   \n",
       "\n",
       "     FN  \n",
       "0   713  \n",
       "1  1631  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate accuracy of cross-validated model \n",
    "evaluate_model(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we heavily overfit to our training data. But it is nice to see, that we can actually predict our data precisely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First hyperparameter-tuning attempt with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                      &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: range(10, 30),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(80, 150)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                      &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: range(10, 30),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(80, 150)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'log_loss',\n",
       "                                                      'entropy'],\n",
       "                                        'max_depth': range(10, 30),\n",
       "                                        'min_samples_leaf': range(5, 20),\n",
       "                                        'min_samples_split': range(10, 20),\n",
       "                                        'n_estimators': range(80, 150)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "max_depth = range(10,30) \n",
    "min_samples_split = range(10,20)\n",
    "min_samples_leaf = range(5,20)\n",
    "n_estimators = range(80,150)\n",
    "criterion = ['gini', 'log_loss', 'entropy']\n",
    "#cv = range(4,10)\n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators, 'criterion': criterion}\n",
    "\n",
    "# Set up forest classifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv = RandomizedSearchCV(forest, param_dist, n_jobs = -1, verbose = 1, n_iter = 2000, cv = 5, scoring = \"balanced_accuracy\") # suited for imbalanced data sets \n",
    "\n",
    "# Fit it to the data\n",
    "forest_cv.fit(x_train,y_train) # does it automatically use best parameters for prediction afterwards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.813560</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.012599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>18413</td>\n",
       "      <td>4232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.818789</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7963</td>\n",
       "      <td>1762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity  TP  FP     TN  \\\n",
       "0  Training  0.813560       1.00     0.012599     1.000000  54   0  18413   \n",
       "1      Test  0.818789       0.75     0.001700     0.999874   3   1   7963   \n",
       "\n",
       "     FN  \n",
       "0  4232  \n",
       "1  1762  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Model predictions for training set\n",
    "y_train_pred = forest_cv.predict(x_train)\n",
    "# Get model predictions for holdout set\n",
    "y_test_pred = forest_cv.predict(x_test)\n",
    "# Evaluate performance of cross-validated model\n",
    "evaluate_model(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second hyperparameter-tuning attempt around the best parameters from the first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=500,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(19, 25),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(2, 8),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 16),\n",
       "                                        &#x27;n_estimators&#x27;: range(96, 106)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=500,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(19, 25),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(2, 8),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 16),\n",
       "                                        &#x27;n_estimators&#x27;: range(96, 106)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=500,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(19, 25),\n",
       "                                        'min_samples_leaf': range(2, 8),\n",
       "                                        'min_samples_split': range(10, 16),\n",
       "                                        'n_estimators': range(96, 106)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab optimal parameters from previous CV\n",
    "best_depth = forest_cv.best_params_[\"max_depth\"]\n",
    "best_split = forest_cv.best_params_[\"min_samples_split\"]\n",
    "best_leaf = forest_cv.best_params_[\"min_samples_leaf\"]\n",
    "best_est = forest_cv.best_params_[\"n_estimators\"]\n",
    "\n",
    "\n",
    "# Set range around previous optimal parameters to search for even better parameters\n",
    "max_depth = range(best_depth - 3, best_depth + 3)\n",
    "min_samples_split = range(best_split - 3, best_split + 3)\n",
    "min_samples_leaf = range(best_leaf - 3, best_leaf + 3)\n",
    "n_estimators = range(best_est - 5, best_est + 5)\n",
    "\n",
    "# Collect in dicionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators}\n",
    "\n",
    "# Set up forest\n",
    "forest = RandomForestClassifier(criterion = forest_cv.best_params_[\"criterion\"])\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv2 = RandomizedSearchCV(forest, param_dist, n_jobs = -1, cv = 5,verbose = 1, n_iter = 500, scoring = \"balanced_accuracy\")\n",
    "# Fit it to the data\n",
    "forest_cv2.fit(x_train, y_train) # does it automatically use best parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.823649</td>\n",
       "      <td>0.996491</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>18412</td>\n",
       "      <td>4002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.818378</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.011898</td>\n",
       "      <td>0.997112</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>7941</td>\n",
       "      <td>1744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity   TP  FP     TN  \\\n",
       "0  Training  0.823649   0.996491     0.066262     0.999946  284   1  18412   \n",
       "1      Test  0.818378   0.477273     0.011898     0.997112   21  23   7941   \n",
       "\n",
       "     FN  \n",
       "0  4002  \n",
       "1  1744  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict and evaluate second cv model\n",
    "# Training data\n",
    "y_train_pred_cv2 = forest_cv2.predict(x_train)\n",
    "# Test data\n",
    "y_test_pred_cv2 = forest_cv2.predict(x_test)\n",
    "# Evalute performance\n",
    "evaluate_model(y_train, y_train_pred_cv2, y_test, y_test_pred_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Random Forest Regression Feature Importances')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importance\n",
    "fig = plt.figure()\n",
    "ax = fig.gca() #get current axis\n",
    "ax.bar(range(x_train.shape[1]), forest_cv2.best_estimator_.feature_importances_)\n",
    "ax.set_xticks(np.arange(x_train.shape[1]))\n",
    "ax.set_xticklabels([f'{col}' for col in x_train.columns])\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Feature Importance')\n",
    "ax.set_title('Random Forest Regression Feature Importances')\n",
    "\n",
    "# Ugly ass graph but its working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.186981</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063185</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.057520</td>\n",
       "      <td>numberitems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.052517</td>\n",
       "      <td>w0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.043981</td>\n",
       "      <td>remi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.042361</td>\n",
       "      <td>w1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035176</td>\n",
       "      <td>newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.032430</td>\n",
       "      <td>w2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.026625</td>\n",
       "      <td>w9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.023699</td>\n",
       "      <td>domain_others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Importance        Feature\n",
       "10    0.186981         weight\n",
       "4     0.063185           case\n",
       "5     0.057520    numberitems\n",
       "14    0.052517             w0\n",
       "11    0.043981           remi\n",
       "15    0.042361             w1\n",
       "1     0.035176     newsletter\n",
       "16    0.032430             w2\n",
       "23    0.026625             w9\n",
       "33    0.023699  domain_others"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances with names \n",
    "importance = pd.DataFrame(forest_cv2.best_estimator_.feature_importances_)\n",
    "feature_names = pd.DataFrame(x_train.columns)\n",
    "feature_importances = pd.concat([importance, feature_names], axis = 1)\n",
    "\n",
    "# Name columns accordingly\n",
    "feature_importances.columns = [\"Importance\", \"Feature\"]\n",
    "rf_features = feature_importances.sort_values(by = \"Importance\", ascending = False)\n",
    "rf_features[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9729"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will now train a Random Forest again, but only regard the top 10 features above\n",
    "# Select top 10 features\n",
    "selected_features = rf_features[0:10][\"Feature\"]\n",
    "# Create training subset containing only those features\n",
    "x_train_rf = x_train[selected_features]\n",
    "# Create test subset containing the same features\n",
    "x_test_rf = x_test[selected_features]\n",
    "\n",
    "# y_train, as well as y_test of course remain unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=2000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                      &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: range(10, 30),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(80, 150)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=2000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                      &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: range(10, 30),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(80, 150)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=2000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'log_loss',\n",
       "                                                      'entropy'],\n",
       "                                        'max_depth': range(10, 30),\n",
       "                                        'min_samples_leaf': range(5, 20),\n",
       "                                        'min_samples_split': range(10, 20),\n",
       "                                        'n_estimators': range(80, 150)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct RandomizedSearchCV once more\n",
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "max_depth = range(10,30) \n",
    "min_samples_split = range(10,20)\n",
    "min_samples_leaf = range(5,20)\n",
    "n_estimators = range(80,150)\n",
    "criterion = ['gini', 'log_loss', 'entropy']\n",
    "#cv = range(4,10)\n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators, 'criterion': criterion}\n",
    "\n",
    "# Set up forest classifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv_new = RandomizedSearchCV(forest, param_dist, n_jobs = -1, verbose = 1, n_iter = 2000, cv = 5, scoring = \"balanced_accuracy\") # suited for imbalanced data sets \n",
    "\n",
    "# Fit it to the data\n",
    "forest_cv_new.fit(x_train_rf, y_train) # does it automatically use best parameters for prediction afterwards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.816291</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>129</td>\n",
       "      <td>13</td>\n",
       "      <td>18400</td>\n",
       "      <td>4157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.817864</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>0.996861</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>7939</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity   TP  FP     TN  \\\n",
       "0  Training  0.816291   0.908451     0.030098     0.999294  129  13  18400   \n",
       "1      Test  0.817864   0.418605     0.010198     0.996861   18  25   7939   \n",
       "\n",
       "     FN  \n",
       "0  4157  \n",
       "1  1747  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for training set\n",
    "y_train_pred = forest_cv_new.predict(x_train_rf)\n",
    "# Get predictions for test set\n",
    "y_test_pred = forest_cv_new.predict(x_test_rf)\n",
    "# Evaluate performance of cross-validated model with fewer features\n",
    "evaluate_model(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;algorithm&#x27;: [&#x27;SAMME&#x27;, &#x27;SAMME.R&#x27;],\n",
       "                                        &#x27;estimator&#x27;: [DecisionTreeClassifier(max_depth=1),\n",
       "                                                      DecisionTreeClassifier(max_depth=2),\n",
       "                                                      DecisionTreeClassifier(max_depth=3)],\n",
       "                                        &#x27;learning_rate&#x27;: array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;algorithm&#x27;: [&#x27;SAMME&#x27;, &#x27;SAMME.R&#x27;],\n",
       "                                        &#x27;estimator&#x27;: [DecisionTreeClassifier(max_depth=1),\n",
       "                                                      DecisionTreeClassifier(max_depth=2),\n",
       "                                                      DecisionTreeClassifier(max_depth=3)],\n",
       "                                        &#x27;learning_rate&#x27;: array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'algorithm': ['SAMME', 'SAMME.R'],\n",
       "                                        'estimator': [DecisionTreeClassifier(max_depth=1),\n",
       "                                                      DecisionTreeClassifier(max_depth=2),\n",
       "                                                      DecisionTreeClassifier(max_depth=3)],\n",
       "                                        'learning_rate': array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        'n_estimators': range(10, 50)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "n_estimators = range(10,50)\n",
    "learning_rate = np.arange(0.5, 5, 0.25) # In Adaboost learning rate can go to infinity (weights of previous misclassifications)\n",
    "estimator = [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3)] \n",
    "algorithm = ['SAMME', 'SAMME.R']\n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'n_estimators': n_estimators, \"learning_rate\": learning_rate, \"estimator\": estimator, \"algorithm\": algorithm}\n",
    "\n",
    "# Set up AdaBoost classifier\n",
    "ada = AdaBoostClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "ada_cv = RandomizedSearchCV(ada, param_dist, n_jobs = -1, verbose = 1, n_iter = 1000, cv = 5, scoring = 'balanced_accuracy')\n",
    "# Fit it to the data\n",
    "ada_cv.fit(x_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.809199</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.058796</td>\n",
       "      <td>0.98387</td>\n",
       "      <td>252</td>\n",
       "      <td>297</td>\n",
       "      <td>18116</td>\n",
       "      <td>4034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.811286</td>\n",
       "      <td>0.357430</td>\n",
       "      <td>0.050425</td>\n",
       "      <td>0.97991</td>\n",
       "      <td>89</td>\n",
       "      <td>160</td>\n",
       "      <td>7804</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity   TP   FP     TN  \\\n",
       "0  Training  0.809199   0.459016     0.058796      0.98387  252  297  18116   \n",
       "1      Test  0.811286   0.357430     0.050425      0.97991   89  160   7804   \n",
       "\n",
       "     FN  \n",
       "0  4034  \n",
       "1  1676  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for training data\n",
    "y_train_pred_ada_cv = ada_cv.predict(x_train)\n",
    "\n",
    "# Get predictions for test data\n",
    "y_test_pred_ada_cv = ada_cv.predict(x_test)\n",
    "\n",
    "# Evaluate performance\n",
    "evaluate_model(y_train, y_train_pred_ada_cv, y_test, y_test_pred_ada_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.239586</td>\n",
       "      <td>numberitems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.208857</td>\n",
       "      <td>used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.124434</td>\n",
       "      <td>w7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.124434</td>\n",
       "      <td>w4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.054794</td>\n",
       "      <td>remi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.049217</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.042212</td>\n",
       "      <td>paymenttype_Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029428</td>\n",
       "      <td>deliverytype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.025641</td>\n",
       "      <td>w3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.021062</td>\n",
       "      <td>w1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Importance           Feature\n",
       "5     0.239586       numberitems\n",
       "13    0.208857              used\n",
       "21    0.124434                w7\n",
       "18    0.124434                w4\n",
       "11    0.054794              remi\n",
       "10    0.049217            weight\n",
       "44    0.042212  paymenttype_Cash\n",
       "2     0.029428      deliverytype\n",
       "17    0.025641                w3\n",
       "15    0.021062                w1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances with names \n",
    "importance = pd.DataFrame(ada_cv.best_estimator_.feature_importances_)\n",
    "feature_names = pd.DataFrame(x_train.columns)\n",
    "feature_importances = pd.concat([importance, feature_names], axis = 1)\n",
    "\n",
    "# Name columns accordingly\n",
    "feature_importances.columns = [\"Importance\", \"Feature\"]\n",
    "ada_features = feature_importances.sort_values(by = \"Importance\", ascending = False)\n",
    "ada_features[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now train a Random Forest again, but only regard the top 10 features above\n",
    "# Select top 10 features\n",
    "selected_features_ada = ada_features[0:10][\"Feature\"]\n",
    "# Create training subset containing only those features\n",
    "x_train_ada = x_train[selected_features_ada]\n",
    "# Create test subset containing the same features\n",
    "x_test_ada = x_test[selected_features_ada]\n",
    "\n",
    "# y_train, as well as y_test of course remain unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;algorithm&#x27;: [&#x27;SAMME&#x27;, &#x27;SAMME.R&#x27;],\n",
       "                                        &#x27;estimator&#x27;: [DecisionTreeClassifier(max_depth=1),\n",
       "                                                      DecisionTreeClassifier(max_depth=2),\n",
       "                                                      DecisionTreeClassifier(max_depth=3)],\n",
       "                                        &#x27;learning_rate&#x27;: array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;algorithm&#x27;: [&#x27;SAMME&#x27;, &#x27;SAMME.R&#x27;],\n",
       "                                        &#x27;estimator&#x27;: [DecisionTreeClassifier(max_depth=1),\n",
       "                                                      DecisionTreeClassifier(max_depth=2),\n",
       "                                                      DecisionTreeClassifier(max_depth=3)],\n",
       "                                        &#x27;learning_rate&#x27;: array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'algorithm': ['SAMME', 'SAMME.R'],\n",
       "                                        'estimator': [DecisionTreeClassifier(max_depth=1),\n",
       "                                                      DecisionTreeClassifier(max_depth=2),\n",
       "                                                      DecisionTreeClassifier(max_depth=3)],\n",
       "                                        'learning_rate': array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        'n_estimators': range(10, 50)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "n_estimators = range(10,50)\n",
    "learning_rate = np.arange(0.5, 5, 0.25) # In Adaboost learning rate can go to infinity (weights of previous misclassifications)\n",
    "estimator = [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3)] \n",
    "algorithm = ['SAMME', 'SAMME.R']\n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'n_estimators': n_estimators, \"learning_rate\": learning_rate, \"estimator\": estimator, \"algorithm\": algorithm}\n",
    "\n",
    "# Set up AdaBoost classifier\n",
    "ada = AdaBoostClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "ada_cv_new = RandomizedSearchCV(ada, param_dist, n_jobs = -1, verbose = 1, n_iter = 1000, cv = 5, scoring = 'balanced_accuracy')\n",
    "# Fit it to the data\n",
    "ada_cv_new.fit(x_train_ada, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.594167</td>\n",
       "      <td>0.233095</td>\n",
       "      <td>0.501867</td>\n",
       "      <td>0.615652</td>\n",
       "      <td>2151</td>\n",
       "      <td>7077</td>\n",
       "      <td>11336</td>\n",
       "      <td>2135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.590194</td>\n",
       "      <td>0.220292</td>\n",
       "      <td>0.495751</td>\n",
       "      <td>0.611125</td>\n",
       "      <td>875</td>\n",
       "      <td>3097</td>\n",
       "      <td>4867</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity    TP    FP     TN  \\\n",
       "0  Training  0.594167   0.233095     0.501867     0.615652  2151  7077  11336   \n",
       "1      Test  0.590194   0.220292     0.495751     0.611125   875  3097   4867   \n",
       "\n",
       "     FN  \n",
       "0  2135  \n",
       "1   890  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for training data\n",
    "y_train_pred_ada_cv_new = ada_cv_new.predict(x_train_ada)\n",
    "# Get predictions for test data\n",
    "y_test_pred_ada_cv_new = ada_cv_new.predict(x_test_ada)\n",
    "# Evaluate performance\n",
    "evaluate_model(y_train, y_train_pred_ada_cv_new, y_test, y_test_pred_ada_cv_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.1   , 0.2125, 0.325 , 0.4375, 0.55  , 0.6625, 0.775 , 0.8875,\n",
       "       1.    ]),\n",
       "                                        &#x27;max_depth&#x27;: range(1, 4),\n",
       "                                        &#x27;n_estimators&#x27;: range(20, 80)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.1   , 0.2125, 0.325 , 0.4375, 0.55  , 0.6625, 0.775 , 0.8875,\n",
       "       1.    ]),\n",
       "                                        &#x27;max_depth&#x27;: range(1, 4),\n",
       "                                        &#x27;n_estimators&#x27;: range(20, 80)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': array([0.1   , 0.2125, 0.325 , 0.4375, 0.55  , 0.6625, 0.775 , 0.8875,\n",
       "       1.    ]),\n",
       "                                        'max_depth': range(1, 4),\n",
       "                                        'n_estimators': range(20, 80)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup parameter distributions for hyperparameter tuning\n",
    "max_depth = range(1, 4)\n",
    "n_estimators = range(20,80)\n",
    "learning_rate = np.linspace(0.1, 1, 9)\n",
    "param_dist = {\"max_depth\": max_depth, \"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up GradientBoostingClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "xgb_cv = RandomizedSearchCV(xgb, param_dist, n_jobs = -1, cv = 5, verbose = 1, n_iter = 1000, scoring = 'balanced_accuracy')\n",
    "\n",
    "# Fit it to the data\n",
    "xgb_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.819375</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>0.079095</td>\n",
       "      <td>0.991691</td>\n",
       "      <td>339</td>\n",
       "      <td>153</td>\n",
       "      <td>18260</td>\n",
       "      <td>3947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.812108</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.040793</td>\n",
       "      <td>0.983049</td>\n",
       "      <td>72</td>\n",
       "      <td>135</td>\n",
       "      <td>7829</td>\n",
       "      <td>1693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity   TP   FP     TN  \\\n",
       "0  Training  0.819375   0.689024     0.079095     0.991691  339  153  18260   \n",
       "1      Test  0.812108   0.347826     0.040793     0.983049   72  135   7829   \n",
       "\n",
       "     FN  \n",
       "0  3947  \n",
       "1  1693  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions and evaluate model performance\n",
    "# Get predictions for training data\n",
    "y_train_pred_xgb_cv = xgb_cv.predict(x_train)\n",
    "# Get predictions for test data\n",
    "y_test_pred_xgb_cv = xgb_cv.predict(x_test)\n",
    "# Evaluate model performance\n",
    "evaluate_model(y_train, y_train_pred_xgb_cv, y_test, y_test_pred_xgb_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083757</td>\n",
       "      <td>deliverytype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.083390</td>\n",
       "      <td>shippingcosts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.079912</td>\n",
       "      <td>remi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069195</td>\n",
       "      <td>newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.039509</td>\n",
       "      <td>model_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031989</td>\n",
       "      <td>voucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.030186</td>\n",
       "      <td>salutation_Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.027950</td>\n",
       "      <td>domain_hotmail.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.026811</td>\n",
       "      <td>domain_t-online.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.025946</td>\n",
       "      <td>w3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Importance             Feature\n",
       "2     0.083757        deliverytype\n",
       "9     0.083390       shippingcosts\n",
       "11    0.079912                remi\n",
       "1     0.069195          newsletter\n",
       "43    0.039509             model_3\n",
       "3     0.031989             voucher\n",
       "38    0.030186  salutation_Company\n",
       "30    0.027950   domain_hotmail.de\n",
       "34    0.026811  domain_t-online.de\n",
       "17    0.025946                  w3"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances with names \n",
    "importance = pd.DataFrame(xgb_cv.best_estimator_.feature_importances_)\n",
    "feature_names = pd.DataFrame(x_train.columns)\n",
    "feature_importances = pd.concat([importance, feature_names], axis = 1)\n",
    "\n",
    "# Name columns accordingly\n",
    "feature_importances.columns = [\"Importance\", \"Feature\"]\n",
    "xgb_features = feature_importances.sort_values(by = \"Importance\", ascending = False)\n",
    "xgb_features[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now train a Random Forest again, but only regard the top 10 features above\n",
    "# Select top 10 features\n",
    "selected_features_xgb = xgb_features[0:10][\"Feature\"]\n",
    "# Create training subset containing only those features\n",
    "x_train_xgb = x_train[selected_features_xgb]\n",
    "# Create test subset containing the same features\n",
    "x_test_xgb = x_test[selected_features_xgb]\n",
    "\n",
    "# y_train, as well as y_test of course remain unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.1   , 0.2125, 0.325 , 0.4375, 0.55  , 0.6625, 0.775 , 0.8875,\n",
       "       1.    ]),\n",
       "                                        &#x27;max_depth&#x27;: range(1, 4),\n",
       "                                        &#x27;n_estimators&#x27;: range(20, 80)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.1   , 0.2125, 0.325 , 0.4375, 0.55  , 0.6625, 0.775 , 0.8875,\n",
       "       1.    ]),\n",
       "                                        &#x27;max_depth&#x27;: range(1, 4),\n",
       "                                        &#x27;n_estimators&#x27;: range(20, 80)},\n",
       "                   scoring=&#x27;balanced_accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': array([0.1   , 0.2125, 0.325 , 0.4375, 0.55  , 0.6625, 0.775 , 0.8875,\n",
       "       1.    ]),\n",
       "                                        'max_depth': range(1, 4),\n",
       "                                        'n_estimators': range(20, 80)},\n",
       "                   scoring='balanced_accuracy', verbose=1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup parameter distributions for hyperparameter tuning\n",
    "max_depth = range(1, 4)\n",
    "n_estimators = range(20,80)\n",
    "learning_rate = np.linspace(0.1, 1, 9)\n",
    "param_dist = {\"max_depth\": max_depth, \"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up GradientBoostingClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "xgb_cv_new = RandomizedSearchCV(xgb, param_dist, n_jobs = -1, cv = 5, verbose = 1, n_iter = 1000, scoring = 'balanced_accuracy')\n",
    "\n",
    "# Fit it to the data\n",
    "xgb_cv_new.fit(x_train_xgb, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>0.813560</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.020065</td>\n",
       "      <td>0.998262</td>\n",
       "      <td>86</td>\n",
       "      <td>32</td>\n",
       "      <td>18381</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.816733</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>0.995480</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>7928</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Set  Accuracy  Precision  Sensitivity  Specificity  TP  FP     TN  \\\n",
       "0  Training  0.813560   0.728814     0.020065     0.998262  86  32  18381   \n",
       "1      Test  0.816733   0.333333     0.010198     0.995480  18  36   7928   \n",
       "\n",
       "     FN  \n",
       "0  4200  \n",
       "1  1747  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions and evaluate model performance\n",
    "# Get predictions for training data\n",
    "y_train_pred_xgb_new = xgb_cv_new.predict(x_train_xgb)\n",
    "# Get predictions for test data\n",
    "y_test_pred_xgb_new = xgb_cv_new.predict(x_test_xgb)\n",
    "# Evaluate model performance\n",
    "evaluate_model(y_train, y_train_pred_xgb_new, y_test, y_test_pred_xgb_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-wise save of the model\n",
    "# joblib.dump(xgb, \"xgb.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting With XGBoost\n",
    "\n",
    "XGBoost, which is short for “Extreme Gradient Boosting,” is a library that provides an efficient implementation of the gradient boosting algorithm.\n",
    "\n",
    "The main benefit of the XGBoost implementation is computational efficiency and often better model performance.\n",
    "\n",
    "For more on the benefits and capability of XGBoost, see the tutorial:\n",
    "\n",
    "\n",
    "https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
