{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS405 Machine Learning Applications in Business and Economics Mini-Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">TBD: \n",
    "- What features to use? \n",
    "    - Construct new ones? \n",
    "    - Simply leave out all non-numeric features? \n",
    "    - Delivery-Delay might be interesting\n",
    "    - Delivery Delay\n",
    "\n",
    "- What is the goal of our model?\n",
    "    - Avoid false negatives? This way returning customers will not receive a voucher. \n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the realm of e-commerce, a common observation is that a significant proportion of customers engage in a single transaction and then cease further purchases. This phenomenon can be attributed to a multitude of factors. To mitigate this, e-commerce platforms employ a variety of strategies aimed at fostering customer loyalty. One such strategy involves the distribution of discount vouchers subsequent to the initial purchase, with the goal of incentivizing repeat transactions. However, indiscriminate distribution of these vouchers may not be an optimal strategy. This is because a segment of customers might have engaged in repeat purchases even in the absence of such incentives. Consequently, the redemption of these vouchers by such customers translates into a reduction in the retailer’s profit. Empirical analyses conducted by the media retailer have demonstrated that for 10% of non-buyers, the voucher instigates a purchase with an average order value of €20. Thus, if a voucher is dispatched to a customer who would not have actually made another purchase, the revenue increases by an average of €1.5. On the other hand, sending a voucher to a customer who would have made a purchase anyway results in a revenue loss equivalent to the voucher value of €5. For customers who don’t receive a voucher, there is no impact on revenues. Therefore, it is crucial to devise a more targeted approach for the distribution of these vouchers.\n",
    "\n",
    "## Task \n",
    "\n",
    "The task at hand involves constructing a predictive model that leverages various features associated with a customer’s initial order. The objective is to determine whether a €5.00 voucher should be issued to a specific customer. Detailed descriptions of these features can be found in the data dictionary.pdf file.\n",
    "The model should be designed to predict if a customer will place a subsequent order within a 90-day period following their initial purchase. This information is represented by the target90 variable in the dataset. The model’s performance is evaluated based on the expected revenue across all customers in a given dataset. This is computed by considering the model’s predictions in conjunction with the associated costs and revenues. It’s crucial to note that the model’s effectiveness is directly tied to its ability to maximize this expected revenue. Hence, the model should be optimized with this specific goal in mind.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier # Binary dependent variable\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import joblib # to save trained model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading in and getting an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_16100\\3775084309.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(\"train.csv\", sep = \";\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customernumber</th>\n",
       "      <th>salutation</th>\n",
       "      <th>title</th>\n",
       "      <th>domain</th>\n",
       "      <th>newsletter</th>\n",
       "      <th>model</th>\n",
       "      <th>paymenttype</th>\n",
       "      <th>deliverytype</th>\n",
       "      <th>invoicepostcode</th>\n",
       "      <th>voucher</th>\n",
       "      <th>case</th>\n",
       "      <th>numberitems</th>\n",
       "      <th>gift</th>\n",
       "      <th>entry</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33389.298569</td>\n",
       "      <td>0.541569</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>7.517115</td>\n",
       "      <td>0.169483</td>\n",
       "      <td>1.646910</td>\n",
       "      <td>1.000987</td>\n",
       "      <td>0.201955</td>\n",
       "      <td>48.752282</td>\n",
       "      <td>0.162020</td>\n",
       "      <td>2.934378</td>\n",
       "      <td>2.019551</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.414642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19148.090449</td>\n",
       "      <td>0.657044</td>\n",
       "      <td>0.083192</td>\n",
       "      <td>3.683945</td>\n",
       "      <td>0.375184</td>\n",
       "      <td>0.825981</td>\n",
       "      <td>1.092677</td>\n",
       "      <td>0.401465</td>\n",
       "      <td>24.361425</td>\n",
       "      <td>0.368475</td>\n",
       "      <td>1.319270</td>\n",
       "      <td>1.726046</td>\n",
       "      <td>0.067404</td>\n",
       "      <td>0.492668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16802.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33552.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50034.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66251.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customernumber    salutation         title        domain    newsletter  \\\n",
       "count    32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean     33389.298569      0.541569      0.006969      7.517115      0.169483   \n",
       "std      19148.090449      0.657044      0.083192      3.683945      0.375184   \n",
       "min          1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      16802.750000      0.000000      0.000000      4.000000      0.000000   \n",
       "50%      33552.500000      0.000000      0.000000      9.000000      0.000000   \n",
       "75%      50034.250000      1.000000      0.000000     11.000000      0.000000   \n",
       "max      66251.000000      2.000000      1.000000     12.000000      1.000000   \n",
       "\n",
       "              model   paymenttype  deliverytype  invoicepostcode  \\\n",
       "count  32428.000000  32428.000000  32428.000000     32428.000000   \n",
       "mean       1.646910      1.000987      0.201955        48.752282   \n",
       "std        0.825981      1.092677      0.401465        24.361425   \n",
       "min        1.000000      0.000000      0.000000         0.000000   \n",
       "25%        1.000000      0.000000      0.000000        30.000000   \n",
       "50%        1.000000      1.000000      0.000000        47.000000   \n",
       "75%        2.000000      2.000000      0.000000        66.000000   \n",
       "max        3.000000      3.000000      1.000000        99.000000   \n",
       "\n",
       "            voucher          case   numberitems          gift         entry  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.162020      2.934378      2.019551      0.004564      0.414642   \n",
       "std        0.368475      1.319270      1.726046      0.067404      0.492668   \n",
       "min        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%        0.000000      2.000000      1.000000      0.000000      0.000000   \n",
       "50%        0.000000      3.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      4.000000      2.000000      0.000000      1.000000   \n",
       "max        1.000000      5.000000     50.000000      1.000000      1.000000   \n",
       "\n",
       "        points  \n",
       "count  32428.0  \n",
       "mean       0.0  \n",
       "std        0.0  \n",
       "min        0.0  \n",
       "25%        0.0  \n",
       "50%        0.0  \n",
       "75%        0.0  \n",
       "max        0.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separator is ;\n",
    "train = pd.read_csv(\"train.csv\", sep = \";\")\n",
    "\n",
    "# Dataset is wide, print all rows and only first 15 columns\n",
    "train.describe().iloc[:,0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shippingcosts</th>\n",
       "      <th>weight</th>\n",
       "      <th>remi</th>\n",
       "      <th>cancel</th>\n",
       "      <th>used</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>w10</th>\n",
       "      <th>target90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "      <td>32428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.150611</td>\n",
       "      <td>637.920809</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>0.061613</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.902122</td>\n",
       "      <td>0.404342</td>\n",
       "      <td>0.276644</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>0.047027</td>\n",
       "      <td>0.180986</td>\n",
       "      <td>0.027908</td>\n",
       "      <td>0.023128</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.164981</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>0.186598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.357674</td>\n",
       "      <td>724.358131</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>0.306833</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>1.654767</td>\n",
       "      <td>1.410395</td>\n",
       "      <td>1.353981</td>\n",
       "      <td>0.253596</td>\n",
       "      <td>0.434265</td>\n",
       "      <td>0.561751</td>\n",
       "      <td>0.299862</td>\n",
       "      <td>0.401782</td>\n",
       "      <td>0.013601</td>\n",
       "      <td>0.836705</td>\n",
       "      <td>0.610509</td>\n",
       "      <td>0.389594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20076.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       shippingcosts        weight          remi        cancel          used  \\\n",
       "count   32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean        0.150611    637.920809      0.059979      0.061613      0.068860   \n",
       "std         0.357674    724.358131      0.388740      0.306833      0.474444   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      3.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000    494.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000    920.000000      0.000000      0.000000      0.000000   \n",
       "max         1.000000  20076.000000     19.000000     17.000000     19.000000   \n",
       "\n",
       "                 w0            w1            w2            w3            w4  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.902122      0.404342      0.276644      0.018903      0.047027   \n",
       "std        1.654767      1.410395      1.353981      0.253596      0.434265   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       99.000000     84.000000     90.000000     15.000000     36.000000   \n",
       "\n",
       "                 w5            w6            w7            w8            w9  \\\n",
       "count  32428.000000  32428.000000  32428.000000  32428.000000  32428.000000   \n",
       "mean       0.180986      0.027908      0.023128      0.000185      0.164981   \n",
       "std        0.561751      0.299862      0.401782      0.013601      0.836705   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       14.000000     27.000000     55.000000      1.000000     48.000000   \n",
       "\n",
       "                w10      target90  \n",
       "count  32428.000000  32428.000000  \n",
       "mean       0.092883      0.186598  \n",
       "std        0.610509      0.389594  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max       50.000000      1.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second half of the columns\n",
    "# Dataset is wide, print all rows and only remaining columns\n",
    "train.describe().iloc[:,15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every column has a count of 32428 -> No missing values seem to be present. In the case of binary encoded variables, the mean directly reflects a percentage (if multiplied by 100). \\\n",
    "However, due to their datatype, some columns are not present in the .describe()-dataframe. Therefore, to fully detect all missing values, we loop over all columns in the as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivpostcode 31036\n",
      "advertisingdatacode 25905\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train[\"domain\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only seem to have missing values in the *delivpostcode* and the *advertisingdatacode* column. \\\n",
    "One possible approach of fixing the issue in the *delivpostcode* column would be to simply impute the values of the *invoicepostcode* column. However, these values do not necessarily have to match. \\\n",
    "For the *advertisingdatacode* column, we do not have a logical approach of dealing with these rather unique data type and its missing values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocessing for one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_16100\\2154899247.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'web.de' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train.loc[i, \"domain\"] = \"web.de\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_16100\\2154899247.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Ms.' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train.loc[i, \"salutation\"] = \"Ms.\"\n",
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_16100\\2154899247.py:49: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Transfer' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train.loc[i, \"paymenttype\"] = \"Transfer\"\n"
     ]
    }
   ],
   "source": [
    "# Domain\n",
    "for i in range(len(train[\"domain\"])):\n",
    "    value = train[\"domain\"].iloc[i]\n",
    "    if value == 0:\n",
    "        train.loc[i, \"domain\"] = \"aol.com\"\n",
    "    elif value == 1:\n",
    "        train.loc[i, \"domain\"] = \"arcor.de\"\n",
    "    elif value == 2:\n",
    "        train.loc[i, \"domain\"] = \"freenet.de\"\n",
    "    elif value == 3:\n",
    "        train.loc[i, \"domain\"] = \"gmail.com\"\n",
    "    elif value == 4:\n",
    "        train.loc[i, \"domain\"] = \"gmx.de\"\n",
    "    elif value == 5:\n",
    "        train.loc[i, \"domain\"] = \"hotmail.de\"\n",
    "    elif value == 6:\n",
    "        train.loc[i, \"domain\"] = \"online.de\"\n",
    "    elif value == 7:\n",
    "        train.loc[i, \"domain\"] = \"onlinehome.de\"\n",
    "    elif value == 8:\n",
    "        train.loc[i, \"domain\"] = \"t-online.de\"\n",
    "    elif value == 9:\n",
    "        train.loc[i, \"domain\"] = \"web.de\"\n",
    "    elif value == 10:\n",
    "        train.loc[i, \"domain\"] = \"yahoo.com\"\n",
    "    elif value == 11:\n",
    "        train.loc[i, \"domain\"] = \"yahoo.de\"\n",
    "    elif value == 12:\n",
    "        train.loc[i, \"domain\"] = \"others\"\n",
    "\n",
    "# Salutation\n",
    "for i in range(len(train[\"salutation\"])):\n",
    "    value = train[\"salutation\"].iloc[i]\n",
    "    if value == 0:\n",
    "        train.loc[i, \"salutation\"] = \"Ms.\"\n",
    "    elif value == 1:\n",
    "        train.loc[i, \"salutation\"] = \"Mr.\"\n",
    "    elif value == 2:\n",
    "        train.loc[i, \"salutation\"] = \"Company\"\n",
    "    \n",
    "# Payment-type\n",
    "for i in range(len(train[\"paymenttype\"])):\n",
    "    value = train[\"paymenttype\"].iloc[i]\n",
    "    if value == 0:\n",
    "        train.loc[i, \"paymenttype\"] = \"Invoice\"\n",
    "    elif value == 1:\n",
    "        train.loc[i, \"paymenttype\"] = \"Cash\"\n",
    "    elif value == 2:\n",
    "        train.loc[i, \"paymenttype\"] = \"Transfer\"\n",
    "    elif value == 3:\n",
    "        train.loc[i, \"paymenttype\"] = \"Credit\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dummy variables\n",
    "train = pd.get_dummies(train, columns=[\"domain\", \"salutation\", \"model\", \"paymenttype\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing delivery delay\n",
    "\n",
    "We expect a potential delay in the delivery to have a systematic influence on a customer's re-purchase probability. The longer this delay gets, the less likely an expected re-purchase will become. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_16100\\2369885331.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-1 days +00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train.loc[i, \"delay\"] = train[\"deliverydatereal\"][i] - train[\"deliverydatepromised\"][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Delay column: 5478\n"
     ]
    }
   ],
   "source": [
    "# Convert actual delivery date to datetime\n",
    "for i in range(len(train)):  \n",
    "    if train.loc[i, \"deliverydatereal\"].startswith(\"0000\"):  \n",
    "        train.loc[i, \"deliverydatereal\"] = np.nan\n",
    "    else:\n",
    "        train.loc[i, \"deliverydatereal\"] = pd.to_datetime(train.loc[i, \"deliverydatereal\"])\n",
    "\n",
    "# Convert promised delivery date to datetime\n",
    "for i in range(len(train)):\n",
    "    if train.loc[i, \"deliverydatepromised\"].startswith(\"0000\"): # disregard missing values\n",
    "        train.loc[i, \"deliverydatepromised\"] = np.nan\n",
    "    else:\n",
    "        try: # Exception had to be added because some dates were out of bounds (Year 4746)\n",
    "            train.loc[i, \"deliverydatepromised\"] = pd.to_datetime(train.loc[i, \"deliverydatepromised\"])\n",
    "        except pd.errors.OutOfBoundsDatetime:\n",
    "            train.loc[i, \"deliverydatepromised\"] = np.nan\n",
    "\n",
    "# Compute actual delay in timedelta format\n",
    "train[\"delay\"] = [0] * len(train)\n",
    "\n",
    "for i in range(len(train)):\n",
    "    if pd.notna(train[\"deliverydatereal\"][i]) and pd.notna(train[\"deliverydatepromised\"][i]):\n",
    "        train.loc[i, \"delay\"] = train[\"deliverydatereal\"][i] - train[\"deliverydatepromised\"][i]\n",
    "    else:\n",
    "        train.loc[i, \"delay\"] = np.nan\n",
    "\n",
    "# Get days of delay\n",
    "for i in range(len(train)):\n",
    "    if pd.notna(train[\"delay\"][i]):\n",
    "        train.loc[i, \"delay\"] = train[\"delay\"][i].days\n",
    "    else:\n",
    "        train.loc[i, \"delay\"] = np.nan\n",
    "\n",
    "missing_values = train[\"delay\"].isna().sum()\n",
    "print(f\"Number of missing values in Delay column: {missing_values}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, only few classifiers can work with NaNs. Since we have over 5000 missing values, different ways of imputing them could have a considerable impact on our model predictions. \\\n",
    "Therefore we disregard the Delivery Delay variable and stick to the original data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to evaluate model precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only includes training data for now (handle division by 0)\n",
    "def evaluate_model(y_train, y_train_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_train_pred)): \n",
    "        if y_train[i]==y_train_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_train_pred[i]==1 and y_train[i]!=y_train_pred[i]:\n",
    "           FP += 1\n",
    "        if y_train[i]==y_train_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_train_pred[i]==0 and y_train[i]!=y_train_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) != 0 else 0\n",
    "    # Calculate precision\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    # Calculate sensitivity\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    # Calculate specificity\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "    # Print results\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision (Share of positives correctly specified):\", precision) # of all actual 1s, how many did we predict as 1\n",
    "    print(\"Sensitivity (Share of actual true values found):\", sensitivity) # of all our predictions with 1, how many were actually 1\n",
    "    print(\"Specificity (Share of actual false values found):\", specificity) # of all our predictions with 0, how many were actually 0\n",
    "    print(f\"TP: {TP}\", f\"FP: {FP}\", f\"TN: {TN}\", f\"FN: {FN}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Constructing the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customernumber', 'date', 'title', 'datecreated', 'newsletter',\n",
       "       'deliverytype', 'invoicepostcode', 'delivpostcode', 'voucher',\n",
       "       'advertisingdatacode', 'case', 'numberitems', 'gift', 'entry', 'points',\n",
       "       'shippingcosts', 'deliverydatepromised', 'deliverydatereal', 'weight',\n",
       "       'remi', 'cancel', 'used', 'w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6',\n",
       "       'w7', 'w8', 'w9', 'w10', 'target90', 'domain_aol.com',\n",
       "       'domain_arcor.de', 'domain_freenet.de', 'domain_gmail.com',\n",
       "       'domain_gmx.de', 'domain_hotmail.de', 'domain_online.de',\n",
       "       'domain_onlinehome.de', 'domain_others', 'domain_t-online.de',\n",
       "       'domain_web.de', 'domain_yahoo.com', 'domain_yahoo.de',\n",
       "       'salutation_Company', 'salutation_Mr.', 'salutation_Ms.', 'model_1',\n",
       "       'model_2', 'model_3', 'paymenttype_Cash', 'paymenttype_Credit',\n",
       "       'paymenttype_Invoice', 'paymenttype_Transfer', 'delay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivpostcode 31036\n",
      "advertisingdatacode 25905\n",
      "deliverydatepromised 9\n",
      "deliverydatereal 5472\n",
      "delay 5478\n"
     ]
    }
   ],
   "source": [
    "# Function to check for NAs in every column\n",
    "def count_na(df):\n",
    "    for col in df.columns:          # Loop over all columns\n",
    "        n_na = df[col].isna().sum() # Count occurrences of missing values\n",
    "        if n_na > 0:                # Only give column and count if there actually are NAs\n",
    "            print(col, n_na)        # Print column name and number of NAs\n",
    "\n",
    "# Apply function\n",
    "count_na(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dependent variable -> label \n",
    "y_train = train[\"target90\"]\n",
    "\n",
    "# Construct explanatory variables -> features (invoicepostcode may be kept as a feature)\n",
    "x_train = train.drop([\"customernumber\", \"date\", \"datecreated\", \"invoicepostcode\", \"delivpostcode\", \"advertisingdatacode\",\n",
    "                       \"deliverydatepromised\", \"deliverydatereal\", \"target90\", \"delay\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_na(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customernumber', 'date', 'datecreated', 'invoicepostcode', 'delivpostcode', 'advertisingdatacode', 'deliverydatepromised', 'deliverydatereal', 'target90']\n"
     ]
    }
   ],
   "source": [
    "disregarded_columns = []\n",
    "for col in train.columns:\n",
    "    if col not in x_train.columns:\n",
    "        disregarded_columns.append(col)\n",
    "print(disregarded_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Customernumber**: We don't expect the customernumer assigned to an individual to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Date**: We don't expect the date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Datecreated**: We don't expect the date of account creation to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Invoicepostcode**: We dont't expect the postcode of the invoice to have a systematic influence on a customer's re-purchase probability. \n",
    "- **Delivpostcode**: Too many missing values.\n",
    "- **Advertisingdatacode**: Too many missing values.\n",
    "- **Deliverydatepromised**: We don't expect the promised delivery date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Deliverydatereal**: We don't expect the actual delivery date to have a systematic influence on a customer's re-purchase probability.\n",
    "- **Delay**: We did expect the delivery delay to have a systematic influence on a customer's re-purchase probability. However, there are too many missing values present. \n",
    "- **Target90**: This is the label we want to predict, therefore we do not include it in the training process.\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First try of estimation with RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, n_estimators=20,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, n_estimators=20,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=20,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to check if we can actually estimate the data set\n",
    "forest = RandomForestClassifier(n_estimators = 20, max_depth = 100, min_samples_split = 2, min_samples_leaf = 1, criterion = \"entropy\", bootstrap = True, random_state = 0)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model predictions\n",
    "y_train_pred = forest.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9631182928333539\n",
      "Precision (Share of positives correctly specified): 0.9787024255570893\n",
      "Sensitivity (Share of actual true values found): 0.8201950090894067\n",
      "Specificity (Share of actual false values found): 0.9959055237517535\n",
      "TP: 4963 FP: 108 TN: 26269 FN: 1088\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy of cross-validated model \n",
    "evaluate_model(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we heavily overfit to our training data. But it is nice to see, that we can actually predict our data precisely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First hyperparameter-tuning attempt with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(10, 20),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 50)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(10, 20),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(5, 20),\n",
       "                                        &#x27;min_samples_split&#x27;: range(10, 20),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 50)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=1000,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(10, 20),\n",
       "                                        'min_samples_leaf': range(5, 20),\n",
       "                                        'min_samples_split': range(10, 20),\n",
       "                                        'n_estimators': range(30, 50)},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "max_depth = range(10,20) \n",
    "min_samples_split = range(10,20)\n",
    "min_samples_leaf = range(5,20)\n",
    "n_estimators = range(30,50)\n",
    "#cv = range(4,10)\n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators}\n",
    "\n",
    "# Set up forest classifier\n",
    "forest = RandomForestClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv = RandomizedSearchCV(forest, param_dist, n_jobs = -1, verbose = 1, n_iter = 1000, scoring = 'accuracy', cv = 5)#, random_state = 0) # not same results though\n",
    "\n",
    "# Fit it to the data\n",
    "forest_cv.fit(x_train,y_train) # does it automatically use best parameters? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second hyperparameter-tuning attempt around the best parameters from the first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 256 is smaller than n_iter=500. Running 256 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=500,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(15, 19),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(3, 7),\n",
       "                                        &#x27;min_samples_split&#x27;: range(8, 12),\n",
       "                                        &#x27;n_estimators&#x27;: range(31, 35)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=500,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(15, 19),\n",
       "                                        &#x27;min_samples_leaf&#x27;: range(3, 7),\n",
       "                                        &#x27;min_samples_split&#x27;: range(8, 12),\n",
       "                                        &#x27;n_estimators&#x27;: range(31, 35)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=500,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(15, 19),\n",
       "                                        'min_samples_leaf': range(3, 7),\n",
       "                                        'min_samples_split': range(8, 12),\n",
       "                                        'n_estimators': range(31, 35)},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab optimal parameters from previous CV\n",
    "best_depth = forest_cv.best_params_[\"max_depth\"]\n",
    "best_split = forest_cv.best_params_[\"min_samples_split\"]\n",
    "best_leaf = forest_cv.best_params_[\"min_samples_leaf\"]\n",
    "best_est = forest_cv.best_params_[\"n_estimators\"]\n",
    "\n",
    "\n",
    "# Set range around previous optimal parameters to search for even better parameters\n",
    "max_depth = range(best_depth - 2, best_depth + 2)\n",
    "min_samples_split = range(best_split - 2, best_split + 2)\n",
    "min_samples_leaf = range(best_leaf - 2, best_leaf + 2)\n",
    "n_estimators = range(best_est - 2, best_est + 2)\n",
    "\n",
    "\n",
    "# Collect in dicionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators}\n",
    "\n",
    "# Set up forest\n",
    "forest = RandomForestClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv2 = RandomizedSearchCV(forest, param_dist, n_jobs = -1, cv = 5,verbose = 1, n_iter = 500, scoring = 'accuracy')\n",
    "# Fit it to the data\n",
    "forest_cv2.fit(x_train, y_train) # does it automatically use best parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8154989515233748\n",
      "Precision (Share of positives correctly specified): 0.9473684210526315\n",
      "Sensitivity (Share of actual true values found): 0.011898859692612791\n",
      "Specificity (Share of actual false values found): 0.9998483527315464\n",
      "TP: 72 FP: 4 TN: 26373 FN: 5979\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate first cv model\n",
    "y_train_pred_cv = forest_cv.predict(x_train)\n",
    "evaluate_model(y_train, y_train_pred_cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8188910817811768\n",
      "Precision (Share of positives correctly specified): 0.9540816326530612\n",
      "Sensitivity (Share of actual true values found): 0.030903982812758222\n",
      "Specificity (Share of actual false values found): 0.9996587936459794\n",
      "TP: 187 FP: 9 TN: 26368 FN: 5864\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate second cv model\n",
    "y_train_pred_cv2 = forest_cv2.predict(x_train)\n",
    "evaluate_model(y_train, y_train_pred_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Random Forest Regression Feature Importances')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importance\n",
    "fig = plt.figure()\n",
    "ax = fig.gca() #get current axis\n",
    "ax.bar(range(x_train.shape[1]), forest_cv2.best_estimator_.feature_importances_)\n",
    "ax.set_xticks(np.arange(x_train.shape[1]))\n",
    "ax.set_xticklabels([f'{col}' for col in x_train.columns])\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Feature Importance')\n",
    "ax.set_title('Random Forest Regression Feature Importances')\n",
    "\n",
    "# Ugly ass graph but its working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.175421</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.062483</td>\n",
       "      <td>numberitems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061742</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.052939</td>\n",
       "      <td>remi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.051497</td>\n",
       "      <td>w0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045734</td>\n",
       "      <td>newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.037986</td>\n",
       "      <td>w1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.027493</td>\n",
       "      <td>w2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.026186</td>\n",
       "      <td>w9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.022756</td>\n",
       "      <td>domain_others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.020822</td>\n",
       "      <td>salutation_Ms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.020406</td>\n",
       "      <td>salutation_Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.020228</td>\n",
       "      <td>domain_web.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.019472</td>\n",
       "      <td>domain_gmx.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.018713</td>\n",
       "      <td>shippingcosts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.018418</td>\n",
       "      <td>model_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018221</td>\n",
       "      <td>voucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.017817</td>\n",
       "      <td>domain_t-online.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.017519</td>\n",
       "      <td>used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.017047</td>\n",
       "      <td>paymenttype_Invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.016552</td>\n",
       "      <td>paymenttype_Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.015956</td>\n",
       "      <td>w5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.015628</td>\n",
       "      <td>paymenttype_Transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015102</td>\n",
       "      <td>deliverytype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.014704</td>\n",
       "      <td>model_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.014472</td>\n",
       "      <td>w10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013858</td>\n",
       "      <td>entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.013555</td>\n",
       "      <td>paymenttype_Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.013406</td>\n",
       "      <td>cancel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.012845</td>\n",
       "      <td>model_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.012308</td>\n",
       "      <td>salutation_Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.010637</td>\n",
       "      <td>domain_yahoo.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.009823</td>\n",
       "      <td>domain_hotmail.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.009449</td>\n",
       "      <td>domain_arcor.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.008786</td>\n",
       "      <td>w4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.008047</td>\n",
       "      <td>domain_freenet.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.007865</td>\n",
       "      <td>domain_aol.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.007100</td>\n",
       "      <td>w3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006918</td>\n",
       "      <td>w6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.005422</td>\n",
       "      <td>w7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.005042</td>\n",
       "      <td>domain_online.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.003723</td>\n",
       "      <td>domain_gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002463</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001470</td>\n",
       "      <td>domain_onlinehome.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001032</td>\n",
       "      <td>gift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000891</td>\n",
       "      <td>domain_yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>w8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>points</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Importance               Feature\n",
       "10    0.175421                weight\n",
       "5     0.062483           numberitems\n",
       "4     0.061742                  case\n",
       "11    0.052939                  remi\n",
       "14    0.051497                    w0\n",
       "1     0.045734            newsletter\n",
       "15    0.037986                    w1\n",
       "16    0.027493                    w2\n",
       "23    0.026186                    w9\n",
       "33    0.022756         domain_others\n",
       "40    0.020822        salutation_Ms.\n",
       "39    0.020406        salutation_Mr.\n",
       "35    0.020228         domain_web.de\n",
       "29    0.019472         domain_gmx.de\n",
       "9     0.018713         shippingcosts\n",
       "43    0.018418               model_3\n",
       "3     0.018221               voucher\n",
       "34    0.017817    domain_t-online.de\n",
       "13    0.017519                  used\n",
       "46    0.017047   paymenttype_Invoice\n",
       "44    0.016552      paymenttype_Cash\n",
       "19    0.015956                    w5\n",
       "47    0.015628  paymenttype_Transfer\n",
       "2     0.015102          deliverytype\n",
       "42    0.014704               model_2\n",
       "24    0.014472                   w10\n",
       "7     0.013858                 entry\n",
       "45    0.013555    paymenttype_Credit\n",
       "12    0.013406                cancel\n",
       "41    0.012845               model_1\n",
       "38    0.012308    salutation_Company\n",
       "37    0.010637       domain_yahoo.de\n",
       "30    0.009823     domain_hotmail.de\n",
       "26    0.009449       domain_arcor.de\n",
       "18    0.008786                    w4\n",
       "27    0.008047     domain_freenet.de\n",
       "25    0.007865        domain_aol.com\n",
       "17    0.007100                    w3\n",
       "20    0.006918                    w6\n",
       "21    0.005422                    w7\n",
       "31    0.005042      domain_online.de\n",
       "28    0.003723      domain_gmail.com\n",
       "0     0.002463                 title\n",
       "32    0.001470  domain_onlinehome.de\n",
       "6     0.001032                  gift\n",
       "36    0.000891      domain_yahoo.com\n",
       "22    0.000048                    w8\n",
       "8     0.000000                points"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances with names \n",
    "importance = pd.DataFrame(forest_cv2.best_estimator_.feature_importances_)\n",
    "feature_names = pd.DataFrame(x_train.columns)\n",
    "feature_importances = pd.concat([importance, feature_names], axis = 1)\n",
    "\n",
    "# Name columns accordingly\n",
    "feature_importances.columns = [\"Importance\", \"Feature\"]\n",
    "feature_importances.sort_values(by = \"Importance\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now what to we do with this? Can we just leave out the worst 10 features for example? \n",
    "# Random forest not really useful in predicting true positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(n_estimators = 500, learning_rate = 0.8)\n",
    "ada = ada.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.813987911681263\n",
      "Precision (Share of positives correctly specified): 0.5714285714285714\n",
      "Sensitivity (Share of actual true values found): 0.012559907453313502\n",
      "Specificity (Share of actual false values found): 0.9978390264245365\n",
      "TP: 76 FP: 57 TN: 26320 FN: 5975\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_ada = ada.predict(x_train)\n",
    "evaluate_model(y_train, y_train_pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 720 is smaller than n_iter=1000. Running 720 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        &#x27;n_estimators&#x27;: range(10, 50)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=AdaBoostClassifier(), n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': array([0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  ,\n",
       "       3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75]),\n",
       "                                        'n_estimators': range(10, 50)},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "max_depth = range(1,5) \n",
    "n_estimators = range(10,50)\n",
    "learning_rate = np.arange(0.5, 5, 0.25) # In Adaboost learning rate can go to infinity (weights of previous misclassifications)\n",
    "#cv = range(4,10)\n",
    "\n",
    "# What about depth of base estimator? \n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'n_estimators': n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up AdaBoost classifier\n",
    "ada = AdaBoostClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "ada_cv = RandomizedSearchCV(ada, param_dist, n_jobs = -1, verbose = 1, n_iter = 1000, scoring = 'accuracy', cv = 5)\n",
    "# Fit it to the data\n",
    "ada_cv.fit(x_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8134636733686937\n",
      "Precision (Share of positives correctly specified): 0.625\n",
      "Sensitivity (Share of actual true values found): 0.0008263097008758883\n",
      "Specificity (Share of actual false values found): 0.9998862645486598\n",
      "TP: 5 FP: 3 TN: 26374 FN: 6046\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from AdaCV model\n",
    "y_train_pred_ada_cv = ada_cv.predict(x_train)\n",
    "# Evaluate accuracy of cross-validated model\n",
    "evaluate_model(y_train, y_train_pred_ada_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.5, max_depth=10, n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.5, max_depth=10, n_estimators=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.5, max_depth=10, n_estimators=50)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(max_depth = 10, n_estimators = 50, learning_rate = 0.5)\n",
    "gbrt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbrt.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test-wise save of the model\n",
    "joblib.dump(gbrt, \"gbrt.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9439681756506723\n",
      "Precision (Share of positives correctly specified): 0.9877880184331798\n",
      "Sensitivity (Share of actual true values found): 0.7084779375309866\n",
      "Specificity (Share of actual false values found): 0.9979906736929901\n",
      "TP: 4287 FP: 53 TN: 26324 FN: 1764\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for initial values\n",
    "y_train_pred_gbrt = gbrt.predict(x_train)\n",
    "# Evaluate model predictions\n",
    "evaluate_model(y_train, y_train_pred_gbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.4, 0.5, 0.6, 0.7, 0.8]),\n",
       "                                        &#x27;max_depth&#x27;: range(8, 15),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 40)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: array([0.4, 0.5, 0.6, 0.7, 0.8]),\n",
       "                                        &#x27;max_depth&#x27;: range(8, 15),\n",
       "                                        &#x27;n_estimators&#x27;: range(30, 40)},\n",
       "                   scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': array([0.4, 0.5, 0.6, 0.7, 0.8]),\n",
       "                                        'max_depth': range(8, 15),\n",
       "                                        'n_estimators': range(30, 40)},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup parameter distributions for hyperparameter tuning\n",
    "max_depth = range(8, 15)\n",
    "n_estimators = range(30,40)\n",
    "learning_rate = np.arange(0.4, 0.9, 0.1) # so far it always outputs first value in list as best parameter\n",
    "param_dist = {\"max_depth\": max_depth, \"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier()\n",
    "# Set up RandomizedSearchCV\n",
    "gbrt_cv = RandomizedSearchCV(gbrt, param_dist, n_jobs = -1, cv = 5, verbose = 1, n_iter = 100, scoring = 'accuracy')\n",
    "# Fit it to the data\n",
    "gbrt_cv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 33, 'max_depth': 8, 'learning_rate': 0.4}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8639447391143457\n",
      "Precision (Share of positives correctly specified): 0.9739733950260266\n",
      "Sensitivity (Share of actual true values found): 0.2783011072549992\n",
      "Specificity (Share of actual false values found): 0.9982939682298972\n",
      "TP: 1684 FP: 45 TN: 26332 FN: 4367\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_gbrt_cv = gbrt_cv.predict(x_train)\n",
    "\n",
    "evaluate_model(y_train, y_train_pred_gbrt_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
