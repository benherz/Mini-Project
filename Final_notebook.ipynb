{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Notebook\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier # Binary dependent variable\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "import joblib # to save trained model \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import shap \n",
    "import dill # to save workspace\n",
    "from sklearn.inspection import permutation_importance # permutation feature importance for global interpretability\n",
    "from sklearn.inspection import PartialDependenceDisplay as pdp # partial dependence plots for global interpretability\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.tree import plot_tree\n",
    "from lime import lime_tabular # Local interpretable model agonstic explanations\n",
    "import shap # SHAP values for local interpretability\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">TBD: \n",
    "- Preprocessing of data\n",
    "    - Delivery Delay?\n",
    "    - What features to include/leave out entirely?\n",
    "    - Missing values in Delay?\n",
    "    \n",
    "- Comparison of categorical/binary/continuous variables in LIME\n",
    "\n",
    "- Normalized graphs -> maybe percentages? \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separator is ;\n",
    "data = pd.read_csv(\"train.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw distribution of target90 variable in data\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Count the occurrences of target category\n",
    "counts = data['target90'].value_counts(normalize=True).reset_index(name='count')\n",
    "\n",
    "# Plot the count plot\n",
    "sns.barplot(x='target90', y='count', data=counts, color=\"#365c8d\")\n",
    "\n",
    "plt.title(f\"Distribution of target90\")\n",
    "plt.xlabel('target90')\n",
    "plt.ylabel('Proportion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Only {np.round(data['target90'].mean()*100,2)}% of customers in the data set repurchased in the next 90 days. This makes the data set imbalanced and we have to proceed with caution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = [\"salutation\", \"title\", \"domain\", \"newsletter\", \"model\", \"paymenttype\", \"deliverytype\", \"voucher\", \"gift\", \"entry\", \"points\", \"shippingcosts\"] # target90 left out as well \n",
    "cardinal_features = [\"numberitems\", \"weight\", \"remi\", \"cancel\", \"used\", \"w0\", \"w1\", \"w2\", \"w3\", \"w4\", \"w5\", \"w6\", \"w7\", \"w8\", \"w9\", \"w10\"]\n",
    "ordinal_features = [\"case\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = \n",
    "y_train = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a 4x4 subplot layout\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "# Flatten the axes array to simplify indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each nominal feature and create bar plots\n",
    "for i, feature in enumerate(nominal_features):\n",
    "    sns.countplot(x=feature, hue='target90', data=data, palette='viridis', ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {feature} with respect to target90')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].legend(title='target90')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'cardinal_features' is the list of features\n",
    "# Update 'target90' with your actual target column name\n",
    "\n",
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a 4x4 subplot layout\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "\n",
    "# Flatten the axes array to simplify indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each nominal feature and create countplots for quartiles\n",
    "for i, feature in enumerate(cardinal_features):\n",
    "\n",
    "    # Sort data according to feature\n",
    "    data = data.sort_values(feature)\n",
    "\n",
    "    # Get data in 25% slides\n",
    "    data_25 = data.iloc[:int(0.25 * len(data))]\n",
    "    data_50 = data.iloc[int(0.25 * len(data)):int(0.5 * len(data))]\n",
    "    data_75 = data.iloc[int(0.5 * len(data)):int(0.75 * len(data))]\n",
    "    data_100 = data.iloc[int(0.75 * len(data)):]\n",
    "\n",
    "    # Compute share of target90 = 1 in each quartile\n",
    "    data_25_y_1 = data_25['target90'].mean()\n",
    "    data_50_y_1 = data_50['target90'].mean()\n",
    "    data_75_y_1 = data_75['target90'].mean()\n",
    "    data_100_y_1 = data_100['target90'].mean()\n",
    "\n",
    "    # Compute share of target90 = 0 in each quartile\n",
    "    data_25_y_0 = 1 - data_25_y_1\n",
    "    data_50_y_0 = 1 - data_50_y_1\n",
    "    data_75_y_0 = 1 - data_75_y_1\n",
    "    data_100_y_0 = 1 - data_100_y_1\n",
    "\n",
    "    # Create a DataFrame with the computed values\n",
    "    df = pd.DataFrame({'target90': ['0', '1'], 'Q1': [data_25_y_0, data_25_y_1], 'Q2': [data_50_y_0, data_50_y_1],\n",
    "                        'Q3': [data_75_y_0, data_75_y_1], 'Q4': [data_100_y_0, data_100_y_1]})\n",
    "    # Plot the results\n",
    "    sns.barplot(x='target90', y='value', hue='variable', data=pd.melt(df, ['target90']), ax=axes[i], palette = 'viridis')\n",
    "    axes[i].set_title(f'Distribution of {feature} with respect to target90')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Proportion')\n",
    "    axes[i].legend(title='Quartile')\n",
    "    \n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'cardinal_features' is the list of features\n",
    "# Update 'target90' with your actual target column name\n",
    "\n",
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a 4x4 subplot layout\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "\n",
    "# Flatten the axes array to simplify indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each nominal feature and create countplots for quartiles\n",
    "for i, feature in enumerate(cardinal_features):\n",
    "\n",
    "    # Sort data according to feature\n",
    "    data = data.sort_values(feature)\n",
    "\n",
    "    # Get data in 25% slides\n",
    "    data_25 = data.iloc[:int(0.25 * len(data))]\n",
    "    data_50 = data.iloc[int(0.25 * len(data)):int(0.5 * len(data))]\n",
    "    data_75 = data.iloc[int(0.5 * len(data)):int(0.75 * len(data))]\n",
    "    data_100 = data.iloc[int(0.75 * len(data)):]\n",
    "\n",
    "    # Compute share of target90 = 1 in each quartile\n",
    "    data_25_y_1 = data_25['target90'].mean()\n",
    "    data_50_y_1 = data_50['target90'].mean()\n",
    "    data_75_y_1 = data_75['target90'].mean()\n",
    "    data_100_y_1 = data_100['target90'].mean()\n",
    "\n",
    "    # Compute share of target90 = 0 in each quartile\n",
    "    data_25_y_0 = 1 - data_25_y_1\n",
    "    data_50_y_0 = 1 - data_50_y_1\n",
    "    data_75_y_0 = 1 - data_75_y_1\n",
    "    data_100_y_0 = 1 - data_100_y_1\n",
    "\n",
    "    # Create a DataFrame with the computed values\n",
    "    df = pd.DataFrame({'Quartile': ['Q1', 'Q2', 'Q3', 'Q4'],\n",
    "                       'target90=0': [data_25_y_0, data_50_y_0, data_75_y_0, data_100_y_0],\n",
    "                       'target90=1': [data_25_y_1, data_50_y_1, data_75_y_1, data_100_y_1]})\n",
    "\n",
    "    # Melt the DataFrame for better visualization\n",
    "    melted_df = pd.melt(df, id_vars='Quartile', var_name='target90', value_name='Proportion')\n",
    "\n",
    "    # Plot the results\n",
    "    sns.barplot(x='Quartile', y='Proportion', hue='target90', data=melted_df, ax=axes[i], palette='viridis')\n",
    "    axes[i].set_title(f'Distribution of {feature} with respect to target90')\n",
    "    axes[i].set_xlabel('Quartile')\n",
    "    axes[i].set_ylabel('Proportion')\n",
    "    axes[i].legend(title='target90')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separator is ;\n",
    "data = pd.read_csv(\"train.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_train, y_train_pred, y_test, y_test_pred):\n",
    "\n",
    "    # Convert y_train & y_test to np.array, as predictions will also be np.array\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Initialize variables for training set\n",
    "    TP_train, FP_train, TN_train, FN_train = 0, 0, 0, 0\n",
    "\n",
    "    # Initialize variables for test set\n",
    "    TP_test, FP_test, TN_test, FN_train = 0, 0, 0, 0\n",
    "\n",
    "    # Calculate training set scores\n",
    "    TP_train = np.sum((y_train == 1) & (y_train_pred == 1))\n",
    "    FP_train = np.sum((y_train == 0) & (y_train_pred == 1))\n",
    "    TN_train = np.sum((y_train == 0) & (y_train_pred == 0))\n",
    "    FN_train = np.sum((y_train == 1) & (y_train_pred == 0))\n",
    "\n",
    "    # Calculate test set scores\n",
    "    TP_test = np.sum((y_test == 1) & (y_test_pred == 1))\n",
    "    FP_test = np.sum((y_test == 0) & (y_test_pred == 1))\n",
    "    TN_test = np.sum((y_test == 0) & (y_test_pred == 0))\n",
    "    FN_test = np.sum((y_test == 1) & (y_test_pred == 0))\n",
    "    \n",
    "\n",
    "    # Calculate training set metrics\n",
    "    accuracy_train = (TP_train + TN_train) / (TP_train + TN_train + FP_train + FN_train) if (TP_train + TN_train + FP_train + FN_train) != 0 else 0\n",
    "    precision_train = TP_train / (TP_train + FP_train) if (TP_train + FP_train) != 0 else 0\n",
    "    sensitivity_train = TP_train / (TP_train + FN_train) if (TP_train + FN_train) != 0 else 0\n",
    "    specificity_train = TN_train / (TN_train + FP_train) if (TN_train + FP_train) != 0 else 0\n",
    "    f1_train = 2*TP_train / (2*TP_train + FP_train + FN_train) if (2*TP_train + FP_train + FN_train) != 0 else 0\n",
    "\n",
    "\n",
    "    # Calculate test set metrics\n",
    "    accuracy_test = (TP_test + TN_test) / (TP_test + TN_test + FP_test + FN_test) if (TP_test + TN_test + FP_test + FN_test) != 0 else 0\n",
    "    precision_test = TP_test / (TP_test + FP_test) if (TP_test + FP_test) != 0 else 0\n",
    "    sensitivity_test = TP_test / (TP_test + FN_test) if (TP_test + FN_test) != 0 else 0\n",
    "    specificity_test = TN_test / (TN_test + FP_test) if (TN_test + FP_test) != 0 else 0\n",
    "    f1_test = 2*TP_test / (2*TP_test + FP_test + FN_test) if (2*TP_test + FP_test + FN_test) != 0 else 0\n",
    "\n",
    "    # Information about distribution of classes in training and test set\n",
    "    print('Ground truth in training set: \\n')\n",
    "    # Number (and share) of returning customers in training data\n",
    "    print(f'Number of returning customers training data: {y_train.sum()} ({np.round(y_train.mean()*100,2)}%)')\n",
    "    # Number (and share) of non-returning customers in training data\n",
    "    print(f'Number of non-returning customers training data: {len(y_train) - y_train.sum()} ({np.round((1 - y_train.mean())*100,2)}%)')\n",
    "    # Number (and share) of returning customers in test data\n",
    "    print(f'Number of returning customers in test data: {y_test.sum()} ({np.round(y_test.mean()*100,2)}%)')\n",
    "    # Number (and share) of non-returning customers in test data\n",
    "    print(f'Number of non-returning customers in test data: {len(y_test) - y_test.sum()} ({np.round((1 - y_test.mean())*100,2)}%)')\n",
    "\n",
    "   # Collect results in a dataframe \n",
    "    results_df = pd.DataFrame({\n",
    "        'Set': ['Training', 'Test'],\n",
    "        'Accuracy': [accuracy_train, accuracy_test],\n",
    "        'Precision': [precision_train, precision_test], # Share of positives correctly specified among all predicted positives\n",
    "        'Sensitivity': [sensitivity_train, sensitivity_test], # Share of actual true positive values found\n",
    "        'Specificity': [specificity_train, specificity_test], # Share of actual true negative values found\n",
    "        'TP': [TP_train, TP_test],\n",
    "        'FP': [FP_train, FP_test],\n",
    "        'TN': [TN_train, TN_test],\n",
    "        'FN': [FN_train, FN_test],\n",
    "        'F1': [f1_train, f1_test]\n",
    "    })\n",
    "\n",
    "    return results_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_revenue(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the expected revenue based on target labels in y and model predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - y (numpy array or pandas Series): True labels indicating returning buyers (1) or non-returning buyers (0).\n",
    "    - y_pred (numpy array or pandas Series): Model predictions returning buyers (1) or non-returning buyers (0).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Prints the expected revenue if all customers were sent a voucher and the expected revenue according to a given model prediction.\n",
    "    \"\"\"\n",
    "    # Just in case\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    # Compute number of total customers in y\n",
    "    total_customers = len(y)\n",
    "    # Compute number of returning buyers in y\n",
    "    rep_buyers = y.sum()\n",
    "    # Compute number of non-returning buyers in y\n",
    "    non_buyers = total_customers - rep_buyers\n",
    "    # Compute expected revenue if all customers were sent a voucher\n",
    "    expected_revenue1 = non_buyers * 1.5 - rep_buyers * 5 # Revenue gain - loss\n",
    "    print(f\"Expected revenue if all customers were sent a voucher: €{expected_revenue1}\")\n",
    "\n",
    "    # Compute TN and FN for model predictions\n",
    "    TN = np.sum((y == 0) & (y_pred == 0))\n",
    "    FN = np.sum((y == 1) & (y_pred == 0))\n",
    "    # Compute revenue gain and loss \n",
    "    rev_gain = TN * 1.5\n",
    "    rev_loss = FN * 5\n",
    "    expected_revenue2 = rev_gain - rev_loss\n",
    "    percentage_gain = ((expected_revenue2 - expected_revenue1) / expected_revenue1) * 100\n",
    "    print(f\"Expected Revenue according to model: €{expected_revenue}, this is a percentage gain of: %{percentage_gain}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for NAs in every column\n",
    "def count_na(df):\n",
    "    for col in df.columns:          # Loop over all columns\n",
    "        n_na = df[col].isna().sum() # Count occurrences of missing values\n",
    "        if n_na > 0:                # Only give column and count if there actually are NAs\n",
    "            print(col, n_na)        # Print column name and number of NAs\n",
    "\n",
    "# Apply function\n",
    "count_na(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier\n",
    "\n",
    "- First hyperparameter-tuning run with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "max_depth = range(10,30) \n",
    "min_samples_split = range(10,20)\n",
    "min_samples_leaf = range(5,20)\n",
    "n_estimators = range(80,150)\n",
    "criterion = ['gini', 'log_loss', 'entropy']\n",
    "class_weight = [{1: 5, 0: 1}, 'balanced' ]\n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf,\n",
    "               'n_estimators': n_estimators, 'criterion': criterion, 'class_weight': class_weight}\n",
    "\n",
    "# Set up forest classifier\n",
    "forest = RandomForestClassifier(bootstrap = True, random_state = seed)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv = RandomizedSearchCV(forest, param_dist, n_jobs = -1, verbose = 1, n_iter = n_iterations, cv = 5, scoring = \"balanced_accuracy\", random_state = seed) # suited for imbalanced data sets \n",
    "\n",
    "# Fit it to the data\n",
    "forest_cv.fit(x_train,y_train) # does it automatically use best parameters for prediction afterwards?\n",
    "\n",
    "# Takes 100 min to run with 1000 iterations and cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions for training set\n",
    "y_train_pred = forest_cv.predict(x_train)\n",
    "# Get model predictions for test set\n",
    "y_test_pred = forest_cv.predict(x_test)\n",
    "# Evaluate performance of cross-validated model\n",
    "evaluate_model(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second hyperparameter-tuning run around best parameters from previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab optimal parameters from previous CV\n",
    "best_depth = forest_cv.best_params_[\"max_depth\"]\n",
    "best_split = forest_cv.best_params_[\"min_samples_split\"]\n",
    "best_leaf = forest_cv.best_params_[\"min_samples_leaf\"]\n",
    "best_est = forest_cv.best_params_[\"n_estimators\"]\n",
    "\n",
    "\n",
    "# Set range around previous optimal parameters to search for even better parameters\n",
    "max_depth = range(best_depth - 3, best_depth + 3)\n",
    "min_samples_split = range(best_split - 3, best_split + 3)\n",
    "min_samples_leaf = range(best_leaf - 3, best_leaf + 3)\n",
    "n_estimators = range(best_est - 5, best_est + 5)\n",
    "\n",
    "# Collect in dicionary\n",
    "param_dist = {'max_depth': max_depth,'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'n_estimators': n_estimators}\n",
    "\n",
    "# Set up forest\n",
    "forest = RandomForestClassifier(criterion = forest_cv.best_params_[\"criterion\"], class_weight = 'balanced', bootstrap = True, random_state = seed)\n",
    "# Set up RandomizedSearchCV\n",
    "forest_cv2 = RandomizedSearchCV(forest, param_dist, n_jobs = -1, cv = 5,verbose = 1, n_iter = n_iterations, scoring = \"balanced_accuracy\", random_state = seed)\n",
    "# Fit it to the data\n",
    "forest_cv2.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for training data\n",
    "y_train_pred_cv2 = forest_cv2.predict(x_train)\n",
    "# Get predictions for test data\n",
    "y_test_pred_cv2 = forest_cv2.predict(x_test)\n",
    "# Evalute performance\n",
    "evaluate_model(y_train, y_train_pred_cv2, y_test, y_test_pred_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected revenue of first RF model \n",
    "expected_revenue(y_test, forest_cv.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected revenue of second RF model \n",
    "expected_revenue(y_test, forest_cv2.predict(x_test)) # better than first RF model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of parameter sets to try\n",
    "n_iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ranges for different parameters for hyperparameter tuning\n",
    "n_estimators = range(10,50)\n",
    "learning_rate = np.arange(0.5, 10, 0.25) # In Adaboost learning rate can go to infinity (weights of previous misclassifications)\n",
    "estimator = [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3)] \n",
    "algorithm = ['SAMME', 'SAMME.R']\n",
    "# No option to set class_weight in AdaBoostClassifier\n",
    "\n",
    "# Collect in dictionary\n",
    "param_dist = {'n_estimators': n_estimators, \"learning_rate\": learning_rate, \"estimator\": estimator, \"algorithm\": algorithm}\n",
    "\n",
    "# Set up AdaBoost classifier\n",
    "ada = AdaBoostClassifier(random_state = seed)\n",
    "# Set up RandomizedSearchCV\n",
    "ada_cv = RandomizedSearchCV(ada, param_dist, n_jobs = -1, verbose = 1, n_iter = n_iterations, cv = 5, scoring = 'balanced_accuracy', random_state = seed)\n",
    "# Fit it to the data\n",
    "ada_cv.fit(x_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for training data\n",
    "y_train_pred_ada_cv = ada_cv.predict(x_train)\n",
    "\n",
    "# Get predictions for test data\n",
    "y_test_pred_ada_cv = ada_cv.predict(x_test)\n",
    "\n",
    "# Evaluate performance\n",
    "evaluate_model(y_train, y_train_pred_ada_cv, y_test, y_test_pred_ada_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second hyperparameter tuning run for AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab optimal parameters from previous CV\n",
    "best_n_estimators = ada_cv.best_params_[\"n_estimators\"]\n",
    "best_learningrate = ada_cv.best_params_[\"learning_rate\"]\n",
    "estimator = ada_cv.best_params_[\"estimator\"]\n",
    "algorithm = ada_cv.best_params_[\"algorithm\"]\n",
    "\n",
    "# Set range around previous optimal parameters to search for even better parameters\n",
    "n_estimators = range(best_n_estimators - 10, best_n_estimators + 10)\n",
    "learning_rate = np.arange(best_learningrate - 2, best_learningrate + 2, 0.1)\n",
    "\n",
    "# Collect in dicionary\n",
    "param_dist = {'n_estimators': n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up forest\n",
    "ada = AdaBoostClassifier(estimator = estimator, algorithm = algorithm, random_state = seed)\n",
    "# Set up RandomizedSearchCV\n",
    "ada_cv2 = RandomizedSearchCV(ada, param_dist, n_jobs = -1, cv = 5, verbose = 1, n_iter = n_iterations, scoring = \"balanced_accuracy\", random_state = seed)\n",
    "# Fit it to the data\n",
    "ada_cv2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for training data\n",
    "y_train_pred_ada_cv2 = ada_cv2.predict(x_train)\n",
    "# Get predictions for test data\n",
    "y_test_pred_ada_cv2 = ada_cv2.predict(x_test)\n",
    "# Evalute performance\n",
    "evaluate_model(y_train, y_train_pred_ada_cv2, y_test, y_test_pred_ada_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected revenue of second AdaBoost model \n",
    "expected_revenue(y_test, ada_cv.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected revenue of second AdaBoost model \n",
    "expected_revenue(y_test, ada_cv2.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameter distributions for hyperparameter tuning\n",
    "max_depth = range(1, 4)\n",
    "n_estimators = range(20,80)\n",
    "learning_rate = np.linspace(0.1, 1, 9)\n",
    "\n",
    "param_dist = {\"max_depth\": max_depth, \"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Set up GradientBoostingClassifier\n",
    "xgb = XGBClassifier(random_state = seed)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "xgb_cv = RandomizedSearchCV(xgb, param_dist, n_jobs = -1, cv = 5, verbose = 1, n_iter = n_iterations, scoring = 'balanced_accuracy', random_state = seed)\n",
    "\n",
    "# Fit it to the data\n",
    "xgb_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for training data\n",
    "y_train_pred_xgb_cv = xgb_cv.predict(x_train)\n",
    "# Get predictions for test data\n",
    "y_test_pred_xgb_cv = xgb_cv.predict(x_test)\n",
    "# Evaluate model performance\n",
    "evaluate_model(y_train, y_train_pred_xgb_cv, y_test, y_test_pred_xgb_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup range of parameters around previous optimal parameters\n",
    "best_n_estimators = xgb_cv.best_params_[\"n_estimators\"]\n",
    "best_learningrate = xgb_cv.best_params_[\"learning_rate\"]\n",
    "best_depth = xgb_cv.best_params_[\"max_depth\"]\n",
    "\n",
    "# Set range around previous optimal parameters to search for even better parameters\n",
    "n_estimators = range(best_n_estimators - 5, best_n_estimators + 5)\n",
    "learning_rate = np.arange(best_learningrate - 0.3, best_learningrate + 0.3, 0.05)\n",
    "max_depth = range(best_depth - 2, best_depth + 2)\n",
    "\n",
    "# Collect in dicionary\n",
    "param_dist = {'n_estimators': n_estimators, \"learning_rate\": learning_rate, \"max_depth\": max_depth}\n",
    "\n",
    "# Set up forest\n",
    "xgb = XGBClassifier(random_state = seed)\n",
    "# Set up RandomizedSearchCV\n",
    "xgb_cv2 = RandomizedSearchCV(xgb, param_dist, n_jobs = -1, cv = 5,verbose = 1, n_iter = n_iterations, scoring = \"balanced_accuracy\", random_state = seed)\n",
    "# Fit it to the data\n",
    "xgb_cv2.fit(x_train, y_train) # does it automatically use best parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for training data\n",
    "y_train_pred_xgb_cv2 = xgb_cv2.predict(x_train)\n",
    "# Get predictions for test data\n",
    "y_test_pred_xgb_cv2 = xgb_cv2.predict(x_test)\n",
    "# Evaluate model performance\n",
    "evaluate_model(y_train, y_train_pred_xgb_cv2, y_test, y_test_pred_xgb_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected revenue of first XGB model\n",
    "expected_revenue(y_test, xgb_cv.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected revenue of second XGB model\n",
    "expected_revenue(y_test, xgb_cv2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Define parameter grid for RandomizedSearchCV\n",
    "param_dist_gb = {\n",
    "    'n_estimators': range(50, 200),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': range(3, 10),\n",
    "    'min_samples_split': range(2, 20),\n",
    "    'min_samples_leaf': range(1, 20),\n",
    "    'subsample': uniform(0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Create RandomizedSearchCV instance\n",
    "# verbose = n: how many process messages are printed to console\n",
    "randSearch_gb = RandomizedSearchCV(gb, param_distributions=param_dist_gb, n_iter=50, cv=5,\n",
    "                                   verbose=0, random_state=seed)\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "randSearch_gb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model interpretations\n",
    "\n",
    "Explain model predictions of best performing model: Random Forest\n",
    "\n",
    "- Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to best estimator from CV\n",
    "model = forest_cv2.best_estimator_\n",
    "\n",
    "# Plot feature importance\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.gca() #get current axis\n",
    "ax.bar(range(x_train.shape[1]), model.feature_importances_, color = \"#0081ff\", width = 0.8)\n",
    "ax.set_xticks(np.arange(x_train.shape[1]))\n",
    "ax.set_xticklabels([f'{col}' for col in x_train.columns], rotation=45, ha='right')\n",
    "ax.set_xlabel('Feature', fontsize = 12)\n",
    "ax.set_ylabel('Feature Importance', fontsize = 12)\n",
    "ax.set_title('Overall feature importances of Random Forest Classifier')\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.legend(['Feature Importance'])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('feature_importance.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set list of metrics to compute feature importance for\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1'] # specificity not a valid scoring metric\n",
    "# Initialize empty dictionary to store results\n",
    "pfi_scores = {}\n",
    "# Loop over all metrics\n",
    "for metric in metrics: \n",
    "    print('Computing permutation importance with {0}...'.format(metric))\n",
    "    pfi_scores[metric] = permutation_importance(model, x_test, y_test, scoring = metric, n_repeats = 30, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results \n",
    "features = x_test.columns.values\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 5, figsize = (18, 4))\n",
    "\n",
    "scores = model.feature_importances_\n",
    "features = x_test.columns.to_numpy()\n",
    "srtd = np.argsort(-scores) # sort descending and get indices\n",
    "\n",
    "top = 10 # Top 10 features\n",
    "ax[0].barh(y = np.arange(0, top), width=scores[srtd[:top]], color='#0081ff', alpha = 0.6) # regular feature importance of RF \n",
    "for i in range(top):\n",
    "    ax[0].text(0.01, i-0.15, features[srtd[i]]) # add feature names to plot\n",
    "ax[0].set_yticks([])\n",
    "ax[0].set_ylabel('Top {0} features'.format(top));\n",
    "ax[0].set_xlabel('Feature Importances')\n",
    "ax[0].set_title('Computed by Random Forest')\n",
    "\n",
    "for k, metric in enumerate(metrics):\n",
    "    scores = pfi_scores[metric]['importances_mean']\n",
    "    srtd = np.argsort(-scores)\n",
    "    \n",
    "    ax[k+1].barh(y=np.arange(0, top), width = scores[srtd[:top]], color = '#0081ff', alpha = 0.6)\n",
    "    for i in range(top):\n",
    "        ax[k+1].text(0.001, i-0.15, features[srtd[i]])\n",
    "    ax[k+1].set_yticks([])\n",
    "    ax[k+1].set_ylabel('Top {0} features scored with {1}'.format(top, metric));\n",
    "    ax[k+1].set_xlabel('Permutation Feature Importances')\n",
    "    ax[k+1].set_title('Scored using {0}'.format(metric))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Global model agnostic methods\n",
    "\n",
    "- Partial dependence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [\"numberitems\", \"weight\", \"remi\", \"cancel\", \"used\", \"w0\", \"w1\", \"w2\", \"w3\", \"w4\", \"w5\", \"w6\", \"w7\", \"w8\", \"w9\", \"w10\", ]\n",
    "ordinal_features = [\"case\"]\n",
    "binary_features = [\"title\", \"newsletter\", \"deliverytype\", \"voucher\", \"domain_aol.com\", \"domain_arcor.de\", \"domain_freenet.de\", \"domain_gmail.com\", \"domain_gmx.de\",\n",
    "                    \"domain_hotmail.de\", \"domain_online.de\", \"domain_onlinehome.de\", \"domain_t-online.de\", \"domain_web.de\", \"domain_yahoo.com\", \"domain_yahoo.de\", \"domain_others\",\n",
    "                    \"salutation_Company\", \"salutation_Mr.\", \"salutation_Ms.\", \"model_1\", \"model_2\", \"model_3\", \"paymenttype_Cash\", \"paymenttype_Credit\",\n",
    "                      \"paymenttype_Invoice\", \"paymenttype_Transfer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous features\n",
    "fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(20, 10))\n",
    "\n",
    "# Iterate through both features and axes\n",
    "for feature, axis in zip(continuous_features, ax.flatten()):\n",
    "    pdp.from_estimator(forest_cv2.best_estimator_, x_train,\n",
    "                       features=[feature],  # Use only one feature at a time\n",
    "                       feature_names=list(x_train.columns),\n",
    "                       kind='average', \n",
    "                       response_method = \"predict_proba\", # Use predict_proba to get probability of class 1\n",
    "                       ax=axis)\n",
    "\n",
    "    # Set the title for each subplot\n",
    "    # axis.set_title(feature, fontsize = 12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=11, ncols=4, figsize=(20, 10))\n",
    "# Iterate through both continuous and binary features and axes\n",
    "for feature, axis in zip(continuous_features + binary_features, ax.flatten()):\n",
    "    # Check if the feature is continuous or binary\n",
    "    if feature in continuous_features:\n",
    "        pdp.from_estimator(forest_cv2, x_train,\n",
    "                           features=[feature],\n",
    "                           feature_names=list(x_train.columns),\n",
    "                           kind='average', \n",
    "                           response_method=\"predict_proba\",\n",
    "                           ax=axis)\n",
    "    else:  # Binary features\n",
    "        pdp.from_estimator(forest_cv2, x_train,\n",
    "                           features=[feature],\n",
    "                           feature_names=list(x_train.columns),\n",
    "                           kind='both',  \n",
    "                           response_method=\"predict_proba\",\n",
    "                           ax=axis)\n",
    "\n",
    "    # Set the title for each subplot\n",
    "    #axis.set_title(feature, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Global surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the model\n",
    "yb_train_pred = forest_cv2.predict(x_train)  # Training set predictions of the black-box (RF) model\n",
    "yb_test_pred = forest_cv2.predict(x_test)  # Test set predictions of the black-box (RF) model\n",
    "\n",
    "acc={}\n",
    "\n",
    "# Loop over max_depth\n",
    "depth_limits = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for max_depth in depth_limits:\n",
    "    print('Surrogate max-depth = {0}'.format(max_depth))\n",
    "    surrogate = DecisionTreeClassifier(max_depth = max_depth, criterion = 'gini', \n",
    "                                       min_samples_leaf = 20, class_weight = 'balanced', random_state = seed)\n",
    "    surrogate.fit(x_train, yb_train_pred)\n",
    "    ys_train_pred = surrogate.predict(x_train)\n",
    "    ys_test_pred = surrogate.predict(x_test)\n",
    "       \n",
    "    acc[max_depth] = {'trn': {'black-box': accuracy_score(y_train, yb_train_pred),\n",
    "                                   'surrogate': accuracy_score(y_train, ys_train_pred),\n",
    "                                   'r2': r2_score(yb_train_pred, ys_train_pred)},\n",
    "                           'tst': {'black-box': accuracy_score(y_test, yb_test_pred),\n",
    "                                   'surrogate': accuracy_score(y_test, ys_test_pred),\n",
    "                                   'r2': r2_score(yb_test_pred, ys_test_pred)}} # r_squared as in regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "fig_labels = ['Training Set', 'Testing Set']\n",
    "markers = [None, 's', 'o']\n",
    "for i, dset in enumerate(['trn', 'tst']):\n",
    "    for j, curve in enumerate(['black-box', 'surrogate', 'r2']):\n",
    "        z = [acc[mleaf][dset][curve] for mleaf in depth_limits]\n",
    "        ax[i].plot(depth_limits, z, marker=markers[j])\n",
    "    ax[i].legend(['Black-box accuracy', 'Surrogate accuracy', 'R2 Black-box vs. Surrogate'])\n",
    "    ax[i].set_title(fig_labels[i])\n",
    "    ax[i].set_xlabel('Maximum depth of decision tree')\n",
    "    ax[i].set_ylabel('accuracy / r2 score')\n",
    "    ax[i].set_xticks(depth_limits)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up surrogate model as decision tree with max_depth = 6\n",
    "surrogate = DecisionTreeClassifier(max_depth = 6, criterion = 'gini', min_samples_leaf = 20, class_weight = 'balanced', random_state = seed)\n",
    "surrogate.fit(x_train, yb_train_pred)\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(15,6), dpi=300)\n",
    "ax = fig.gca()\n",
    "plot_tree(surrogate, fontsize = 3, feature_names = x_train.columns.values, \n",
    "          rounded=True, filled=True, ax = ax, class_names = [\"No Repurchase\", \"Repurchase\"]) # in order of surrogate.classes_\n",
    "fig.savefig('Regression Tree.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Local model agnostic methods (LIME)\n",
    "\n",
    "- Explain one prediction instance of our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['title', 'newsletter', 'deliverytype', 'invoicepostcode', 'voucher',\n",
    "                'case', 'gift', 'entry', 'points', 'shippingcosts', 'paymenttype',\n",
    "                'salutation', 'delay']\n",
    "\n",
    "cat_idx = np.array([cat_features.index(f) for f in cat_features])\n",
    "\n",
    "\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer(x_train.values,\n",
    "                                              feature_names=list(x_train.columns), \n",
    "                                              class_names=['No purchase', 'Repurchase'], \n",
    "                                              categorical_features=cat_idx,\n",
    "                                              kernel_width=75.0,\n",
    "                                              categorical_names=cat_features,\n",
    "                                              discretize_continuous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a single instance using example index:\n",
    "exp = lime_explainer.explain_instance(x_test.iloc[3000], forest_cv2.predict_proba)\n",
    "exp.show_in_notebook(show_table=False, show_all=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
